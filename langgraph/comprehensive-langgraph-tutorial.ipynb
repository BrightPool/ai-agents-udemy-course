{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "main-title",
   "metadata": {},
   "source": [
    "# Comprehensive LangGraph Tutorial: Build Intelligent AI Agents\n",
    "\n",
    "Welcome to this comprehensive tutorial on LangGraph! In this notebook, you'll learn how to build increasingly sophisticated AI agents, from a basic chatbot to advanced agents with tools, memory, and complex workflows.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "This tutorial is divided into three comprehensive chapters:\n",
    "\n",
    "1. **Chapter 1: Build a Basic Chatbot** - Learn the fundamentals of LangGraph by creating a simple conversational agent\n",
    "2. **Chapter 2: Add Tools** - Extend your chatbot with web search capabilities using Tavily\n",
    "3. **Chapter 3: Advanced State Management** - Build a sophisticated agent with custom tools and state tracking\n",
    "\n",
    "By the end of this tutorial, you'll understand:\n",
    "- How to create and manage state graphs\n",
    "- How to add nodes and edges to control agent flow\n",
    "- How to integrate external tools\n",
    "- How to implement conditional logic\n",
    "- How to track and manage complex state\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install all the required packages. We'll need:\n",
    "- `langgraph`: The core library for building stateful agents\n",
    "- `langsmith`: For tracing and debugging (optional but highly recommended)\n",
    "- `langchain-openai`: For OpenAI integration\n",
    "- `langchain-anthropic`: For Anthropic integration (alternative)\n",
    "- `langchain-tavily`: For web search capabilities\n",
    "- `langchain-core`: Core utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith langchain-openai langchain-anthropic langchain-tavily langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-keys-section",
   "metadata": {},
   "source": [
    "### Configure API Keys\n",
    "\n",
    "Now let's set up your API keys. This secure approach ensures your keys aren't hardcoded in the notebook.\n",
    "\n",
    "You'll need:\n",
    "- An **OpenAI API key** (get one at https://platform.openai.com/api-keys)\n",
    "- A **LangSmith API key** (optional, get one at https://smith.langchain.com)\n",
    "- A **Tavily API key** for Chapter 2 (get one at https://tavily.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"Helper function to securely set environment variables\"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# Set OpenAI API key\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langsmith-section",
   "metadata": {},
   "source": [
    "### Optional: Enable LangSmith Tracing\n",
    "\n",
    "LangSmith is a powerful tool for debugging and monitoring your LangGraph applications. It lets you:\n",
    "- Visualize the execution flow of your agents\n",
    "- Debug issues by examining traces\n",
    "- Monitor performance and token usage\n",
    "- Test and evaluate your agents\n",
    "\n",
    "If you have a LangSmith account, run the cell below to enable tracing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "setup-langsmith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Enable LangSmith tracing\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Comprehensive Tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter1-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Chapter 1: Build a Basic Chatbot\n",
    "\n",
    "In this chapter, you'll build your first LangGraph agent - a simple chatbot that can hold conversations. This will introduce you to the core concepts of LangGraph.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. State\n",
    "State is the information that flows through your graph. It's defined as a TypedDict and can contain any data your agent needs. In our case, we'll track messages.\n",
    "\n",
    "### 2. StateGraph\n",
    "A StateGraph is a state machine that defines how your agent processes information. It consists of:\n",
    "- **Nodes**: Units of work (functions that process the state)\n",
    "- **Edges**: Connections between nodes that define the flow\n",
    "\n",
    "### 3. Reducers\n",
    "Reducers control how state updates are applied. The `add_messages` reducer appends new messages instead of overwriting them.\n",
    "\n",
    "Let's build our chatbot step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-state",
   "metadata": {},
   "source": [
    "## Step 1: Define the State\n",
    "\n",
    "First, we need to define what information our chatbot will track. For a basic chatbot, we'll track a list of messages.\n",
    "\n",
    "Notice the `add_messages` annotation - this tells LangGraph to append new messages to the list rather than replacing the entire list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter1-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì State defined successfully!\n",
      "\n",
      "Our state tracks:\n",
      "  - messages: list of conversation messages (with add_messages reducer)\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    The State of our chatbot.\n",
    "\n",
    "    Attributes:\n",
    "        messages: A list of messages in the conversation.\n",
    "                  The add_messages reducer appends new messages instead of overwriting.\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    test: str\n",
    "\n",
    "print(\"‚úì State defined successfully!\")\n",
    "print(\"\\nOur state tracks:\")\n",
    "print(\"  - messages: list of conversation messages (with add_messages reducer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-graph",
   "metadata": {},
   "source": [
    "## Step 2: Create the StateGraph\n",
    "\n",
    "Now we'll create a StateGraph object. This is the foundation of our chatbot - it defines the structure of our agent as a state machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chapter1-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì StateGraph created!\n",
      "\n",
      "The graph builder is ready to:\n",
      "  1. Accept nodes (units of work)\n",
      "  2. Connect nodes with edges (define the flow)\n",
      "  3. Compile into a runnable graph\n"
     ]
    }
   ],
   "source": [
    "# Create the graph builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "print(\"‚úì StateGraph created!\")\n",
    "print(\"\\nThe graph builder is ready to:\")\n",
    "print(\"  1. Accept nodes (units of work)\")\n",
    "print(\"  2. Connect nodes with edges (define the flow)\")\n",
    "print(\"  3. Compile into a runnable graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-llm",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Language Model\n",
    "\n",
    "We'll use OpenAI's GPT-4 for our chatbot. The `init_chat_model` function provides a unified interface for different LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chapter1-llm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Language model initialized!\n",
      "\n",
      "Using model: GPT-4o\n",
      "Temperature: 0 (deterministic responses)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Initialize the language model\n",
    "# You can also use \"anthropic:claude-3-5-sonnet-latest\" or other models\n",
    "llm = init_chat_model(\"openai:gpt-5\", temperature=0)\n",
    "\n",
    "print(\"‚úì Language model initialized!\")\n",
    "print(f\"\\nUsing model: GPT-4o\")\n",
    "print(\"Temperature: 0 (deterministic responses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-node",
   "metadata": {},
   "source": [
    "## Step 4: Create the Chatbot Node\n",
    "\n",
    "Nodes are functions that do the actual work. Our chatbot node will:\n",
    "1. Receive the current state (with all messages)\n",
    "2. Send the messages to the LLM\n",
    "3. Return the LLM's response as a state update\n",
    "\n",
    "Notice the pattern: the function receives `state` and returns a dictionary with updates to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter1-node",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chatbot node created and added to graph!\n",
      "\n",
      "Node function:\n",
      "  Input: Current state with message history\n",
      "  Process: Send messages to LLM\n",
      "  Output: LLM response as new message\n"
     ]
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    The chatbot node that processes messages.\n",
    "\n",
    "    Args:\n",
    "        state: The current state containing the message history\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the new message to add to the state\n",
    "    \"\"\"\n",
    "    # Invoke the LLM with the current message history\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # 1. First copy the state:\n",
    "    # state_copy_test = state['test']\n",
    "    # 2. Then update the copy:#\n",
    "    # new_state_test = state_copy_test + ' test'\n",
    "    #\n",
    "    # Return the response as a state update\n",
    "    # The add_messages reducer will append this to the message list\n",
    "    #  3. Then return the updated copy:\n",
    "    return {\"messages\": [response]} #'test': new_state_test}\n",
    "\n",
    "# Add the node to our graph\n",
    "# First argument: unique node name\n",
    "# Second argument: the function to call\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "print(\"‚úì Chatbot node created and added to graph!\")\n",
    "print(\"\\nNode function:\")\n",
    "print(\"  Input: Current state with message history\")\n",
    "print(\"  Process: Send messages to LLM\")\n",
    "print(\"  Output: LLM response as new message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-edges",
   "metadata": {},
   "source": [
    "## Step 5: Define the Flow with Edges\n",
    "\n",
    "Now we need to tell the graph:\n",
    "1. Where to start (entry point)\n",
    "2. Where to end (exit point)\n",
    "\n",
    "Edges connect nodes and define the execution flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chapter1-edges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Graph flow defined!\n",
      "\n",
      "Execution flow:\n",
      "  START ‚Üí chatbot ‚Üí END\n",
      "\n",
      "This creates a simple linear flow where:\n",
      "  1. Execution starts\n",
      "  2. Chatbot processes the input\n",
      "  3. Execution ends\n"
     ]
    }
   ],
   "source": [
    "# Define the entry point: start at the chatbot node\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Define the exit point: end after the chatbot responds\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "print(\"‚úì Graph flow defined!\")\n",
    "print(\"\\nExecution flow:\")\n",
    "print(\"  START ‚Üí chatbot ‚Üí END\")\n",
    "print(\"\\nThis creates a simple linear flow where:\")\n",
    "print(\"  1. Execution starts\")\n",
    "print(\"  2. Chatbot processes the input\")\n",
    "print(\"  3. Execution ends\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6-compile",
   "metadata": {},
   "source": [
    "## Step 6: Compile the Graph\n",
    "\n",
    "Before we can use our graph, we need to compile it. This creates a `CompiledGraph` that we can invoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chapter1-compile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Graph compiled successfully!\n",
      "\n",
      "The graph is now ready to use!\n",
      "You can:\n",
      "  - invoke() for single responses\n",
      "  - stream() for streaming responses\n",
      "  - visualize it with draw_mermaid_png()\n"
     ]
    }
   ],
   "source": [
    "# Compile the graph into a runnable object\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"‚úì Graph compiled successfully!\")\n",
    "print(\"\\nThe graph is now ready to use!\")\n",
    "print(\"You can:\")\n",
    "print(\"  - invoke() for single responses\")\n",
    "print(\"  - stream() for streaming responses\")\n",
    "print(\"  - visualize it with draw_mermaid_png()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7-visualize",
   "metadata": {},
   "source": [
    "## Step 7: Visualize the Graph (Optional)\n",
    "\n",
    "LangGraph allows you to visualize your agent's structure. This is incredibly helpful for understanding and debugging complex workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chapter1-visualize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Graph visualization displayed above!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"\\n‚úì Graph visualization displayed above!\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph visualization: {e}\")\n",
    "    print(\"This is optional and requires additional dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8-test",
   "metadata": {},
   "source": [
    "## Step 8: Test the Chatbot\n",
    "\n",
    "Now let's test our chatbot! We'll create a simple streaming function that displays the chatbot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter1-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the chatbot with: 'What is LangGraph?'\n",
      "\n",
      "Assistant: LangGraph is an open‚Äësource library (Python and JavaScript) from LangChain for building stateful, multi‚Äëstep AI agents and workflows as graphs/state machines. It‚Äôs designed for agentic apps that need loops, memory, tool use, and human‚Äëin‚Äëthe‚Äëloop control‚Äîcapabilities that go beyond simple DAG pipelines.\n",
      "\n",
      "Key ideas\n",
      "- State: A typed, shared state object (with merge/reducer semantics) that persists across steps.\n",
      "- Nodes: Functions/LLM calls/tools/subgraphs that read/update state.\n",
      "- Edges: Deterministic or conditional transitions between nodes; supports cycles (loops) and branching.\n",
      "- Persistence: Built‚Äëin checkpointing so you can pause/resume, recover from errors, and maintain per‚Äësession memory (e.g., SQLite, Postgres, Redis, LangSmith).\n",
      "- Streaming and events: Stream state deltas/tokens and observe fine‚Äëgrained events.\n",
      "- Interrupts: Add breakpoints for human approval or external input mid‚Äërun.\n",
      "- Multi‚Äëagent patterns: Compose planner/solver/critic, tool‚Äëusing agents, or specialist teams.\n",
      "- Integrations: Works with LangChain‚Äôs ecosystem (OpenAI, Anthropic, Google, Bedrock, local LLMs, vector stores, tools).\n",
      "\n",
      "Typical uses\n",
      "- Tool‚Äëusing chat agents with memory\n",
      "- Iterative RAG (retrieve ‚Üí grade ‚Üí reformulate ‚Üí answer, with loops)\n",
      "- Planner/executor/critic agent teams\n",
      "- Long‚Äërunning workflows that must be resumable and observable\n",
      "\n",
      "Deployment\n",
      "- Run locally or on your own infra.\n",
      "- LangGraph Cloud (managed service) lets you deploy graphs as stateful APIs with built‚Äëin persistence, scaling, streaming, and auth, with minimal code changes.\n",
      "\n",
      "In short: LangGraph gives you precise, reliable control over agent workflows by modeling them as stateful graphs with persistence, streaming, and human‚Äëin‚Äëthe‚Äëloop capabilities.\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    \"\"\"\n",
    "    Stream graph updates and display the chatbot's response.\n",
    "\n",
    "    Args:\n",
    "        user_input: The user's message\n",
    "    \"\"\"\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "# Test with a simple message\n",
    "print(\"Testing the chatbot with: 'What is LangGraph?'\\n\")\n",
    "stream_graph_updates(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter1-interactive",
   "metadata": {},
   "source": [
    "## Interactive Chat Loop\n",
    "\n",
    "Now let's create an interactive chat loop so you can have a real conversation with your chatbot!\n",
    "\n",
    "**Tip:** Type 'quit', 'exit', or 'q' to exit the chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter1-interactive-loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Interactive Chatbot - Chapter 1\n",
      "==================================================\n",
      "Type 'quit', 'exit', or 'q' to exit\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=701c23c2-a54f-41b9-9d19-d43c45394a3d,id=db236d80-0205-45fd-810f-b88e4991b59e; trace=701c23c2-a54f-41b9-9d19-d43c45394a3d,id=ccf7c089-4f3a-4080-8e4c-e9858adcaff8; trace=701c23c2-a54f-41b9-9d19-d43c45394a3d,id=701c23c2-a54f-41b9-9d19-d43c45394a3d\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=96eb84b4-64f9-4fee-8b96-af5caefb3841,id=96eb84b4-64f9-4fee-8b96-af5caefb3841; trace=96eb84b4-64f9-4fee-8b96-af5caefb3841,id=1eb2d3fc-a3b8-42c4-bf5b-fc2fa5bee48d; trace=96eb84b4-64f9-4fee-8b96-af5caefb3841,id=e93e474f-f27a-4e50-8442-b674799252e6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: It looks like your message didn‚Äôt come through. How can I help today?\n",
      "\n",
      "If it helps, you can tell me:\n",
      "- What you‚Äôre trying to do (e.g., explain a concept, draft an email, fix code, plan a trip)\n",
      "- Any text or data to work with (paste it here)\n",
      "- Goals, audience, tone, and length\n",
      "- Deadlines or constraints (tools, format, word count)\n",
      "\n",
      "Feel free to paste the content or describe the task, and I‚Äôll jump in.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Interactive Chatbot - Chapter 1\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Type 'quit', 'exit', or 'q' to exit\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "        print()  # Add a blank line for readability\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nGoodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter1-summary",
   "metadata": {},
   "source": [
    "## Chapter 1 Summary\n",
    "\n",
    "Congratulations! You've built your first LangGraph agent! üéâ\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **State Management**: How to define state with TypedDict and use reducers\n",
    "2. **StateGraph**: How to create a state machine for your agent\n",
    "3. **Nodes**: How to define units of work as functions\n",
    "4. **Edges**: How to control the flow of execution\n",
    "5. **Compilation**: How to compile and run your graph\n",
    "\n",
    "### Limitations:\n",
    "\n",
    "Our current chatbot has some limitations:\n",
    "- It can only answer from its training data\n",
    "- It can't search the web for current information\n",
    "- It doesn't remember conversations between runs\n",
    "\n",
    "In the next chapter, we'll address the first limitation by adding web search capabilities! üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Chapter 2: Add Tools to Your Chatbot\n",
    "\n",
    "In this chapter, we'll enhance our chatbot by adding tool-calling capabilities. Specifically, we'll integrate web search so the chatbot can find current information.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. Tool Calling\n",
    "Modern LLMs can decide when to use tools. They output structured tool calls that we can execute and feed the results back to the LLM.\n",
    "\n",
    "### 2. Conditional Edges\n",
    "Unlike fixed edges, conditional edges use functions to decide where to route the execution based on the current state.\n",
    "\n",
    "### 3. Tool Node\n",
    "A special node that executes tool calls made by the LLM.\n",
    "\n",
    "### 4. Loops\n",
    "Our graph will now have a loop: chatbot ‚Üí tools ‚Üí chatbot ‚Üí END\n",
    "\n",
    "Let's build it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-setup",
   "metadata": {},
   "source": [
    "## Step 1: Set Up Tavily Search\n",
    "\n",
    "Tavily is a search engine optimized for LLMs. Let's set up our API key and create a search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chapter2-tavily-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Tavily API key configured!\n"
     ]
    }
   ],
   "source": [
    "# Set up Tavily API key\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"‚úì Tavily API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-tool-def",
   "metadata": {},
   "source": [
    "## Step 2: Define the Search Tool\n",
    "\n",
    "We'll create a TavilySearch tool that can search the web. The `max_results=2` parameter limits the number of results to keep responses concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chapter2-tool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Tavily search tool created!\n",
      "\n",
      "Tool capabilities:\n",
      "  - Name: tavily_search\n",
      "  - Description: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.\n",
      "  - Max results: 2\n",
      "\n",
      "Testing the tool with query: 'What is LangGraph?'\n",
      "\n",
      "Got 2 results!\n",
      "First result title: What is LangGraph?\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# Create the search tool\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "print(\"‚úì Tavily search tool created!\")\n",
    "print(\"\\nTool capabilities:\")\n",
    "print(f\"  - Name: {tool.name}\")\n",
    "print(f\"  - Description: {tool.description}\")\n",
    "print(\"  - Max results: 2\")\n",
    "\n",
    "# Test the tool\n",
    "print(\"\\nTesting the tool with query: 'What is LangGraph?'\")\n",
    "result = tool.invoke(\"What is LangGraph?\")\n",
    "print(f\"\\nGot {len(result.get('results', []))} results!\")\n",
    "if result.get('results'):\n",
    "    print(f\"First result title: {result['results'][0]['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-state",
   "metadata": {},
   "source": [
    "## Step 3: Create the State and Graph\n",
    "\n",
    "We'll use the same State definition as Chapter 1, but now we'll bind tools to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chapter2-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì State and graph builder created!\n",
      "‚úì Tools bound to LLM!\n",
      "\n",
      "The LLM can now:\n",
      "  - Decide when to use tools\n",
      "  - Format tool calls correctly\n",
      "  - Incorporate tool results into responses\n"
     ]
    }
   ],
   "source": [
    "# Reuse the State definition from Chapter 1\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Create a new graph builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Bind tools to the LLM\n",
    "# This tells the LLM about available tools and how to call them\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úì State and graph builder created!\")\n",
    "print(\"‚úì Tools bound to LLM!\")\n",
    "print(\"\\nThe LLM can now:\")\n",
    "print(\"  - Decide when to use tools\")\n",
    "print(\"  - Format tool calls correctly\")\n",
    "print(\"  - Incorporate tool results into responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-chatbot-node",
   "metadata": {},
   "source": [
    "## Step 4: Create the Enhanced Chatbot Node\n",
    "\n",
    "Our chatbot node now uses the LLM with tools. The LLM can choose to:\n",
    "1. Respond directly to the user\n",
    "2. Call a tool to get more information first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter2-chatbot-node",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Enhanced chatbot node added!\n"
     ]
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    Enhanced chatbot node that can call tools.\n",
    "\n",
    "    The LLM will decide whether to:\n",
    "    1. Respond directly to the user\n",
    "    2. Call a tool to gather information first\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "print(\"‚úì Enhanced chatbot node added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-tool-node",
   "metadata": {},
   "source": [
    "## Step 5: Create the Tool Node\n",
    "\n",
    "The tool node executes any tool calls made by the LLM. LangGraph provides a prebuilt `ToolNode` for this!\n",
    "\n",
    "Here's what happens:\n",
    "1. The LLM makes a tool call (structured output)\n",
    "2. The tool node extracts the tool name and arguments\n",
    "3. It executes the tool\n",
    "4. It packages the result as a ToolMessage\n",
    "5. The result goes back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chapter2-tool-node",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Tool node created and added!\n",
      "\n",
      "Tool node will:\n",
      "  1. Extract tool calls from the LLM's response\n",
      "  2. Execute the requested tools\n",
      "  3. Format results as ToolMessages\n",
      "  4. Return results to be added to the state\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Create a tool node using LangGraph's prebuilt ToolNode\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "# Add it to the graph\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "print(\"‚úì Tool node created and added!\")\n",
    "print(\"\\nTool node will:\")\n",
    "print(\"  1. Extract tool calls from the LLM's response\")\n",
    "print(\"  2. Execute the requested tools\")\n",
    "print(\"  3. Format results as ToolMessages\")\n",
    "print(\"  4. Return results to be added to the state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-routing",
   "metadata": {},
   "source": [
    "## Step 6: Define Conditional Routing\n",
    "\n",
    "Now comes the interesting part! We need conditional logic to decide:\n",
    "- If the LLM made tool calls ‚Üí route to the tool node\n",
    "- If the LLM responded directly ‚Üí end the conversation\n",
    "\n",
    "LangGraph provides a prebuilt `tools_condition` function for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chapter2-routing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Conditional routing configured!\n",
      "\n",
      "Execution flow:\n",
      "  START ‚Üí chatbot\n",
      "           ‚Üì\n",
      "       [Decision]\n",
      "      ‚Üô         ‚Üò\n",
      "   tools        END\n",
      "     ‚Üì\n",
      "  chatbot\n",
      "     ‚Üì\n",
      "    END\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Add conditional edges from the chatbot\n",
    "# The tools_condition function checks if tool calls were made\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",  # Source node\n",
    "    tools_condition,  # Condition function\n",
    ")\n",
    "\n",
    "# After tools are executed, always go back to the chatbot\n",
    "# This allows the LLM to use tool results in its response\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Define the entry point\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "print(\"‚úì Conditional routing configured!\")\n",
    "print(\"\\nExecution flow:\")\n",
    "print(\"  START ‚Üí chatbot\")\n",
    "print(\"           ‚Üì\")\n",
    "print(\"       [Decision]\")\n",
    "print(\"      ‚Üô         ‚Üò\")\n",
    "print(\"   tools        END\")\n",
    "print(\"     ‚Üì\")\n",
    "print(\"  chatbot\")\n",
    "print(\"     ‚Üì\")\n",
    "print(\"    END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-compile",
   "metadata": {},
   "source": [
    "## Step 7: Compile and Visualize\n",
    "\n",
    "Let's compile our enhanced graph and visualize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chapter2-compile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Enhanced graph compiled!\n",
      "\n",
      "The graph now supports:\n",
      "  - Tool calling\n",
      "  - Conditional routing\n",
      "  - Loops (tool ‚Üí chatbot ‚Üí tool)\n",
      "\n",
      "Could not display visualization: name 'Image' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"‚úì Enhanced graph compiled!\")\n",
    "print(\"\\nThe graph now supports:\")\n",
    "print(\"  - Tool calling\")\n",
    "print(\"  - Conditional routing\")\n",
    "print(\"  - Loops (tool ‚Üí chatbot ‚Üí tool)\")\n",
    "\n",
    "# Visualize the graph\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"\\n‚úì Graph visualization displayed above!\")\n",
    "    print(\"Notice the loop between 'chatbot' and 'tools'!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not display visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-test",
   "metadata": {},
   "source": [
    "## Step 8: Test the Enhanced Chatbot\n",
    "\n",
    "Let's test our chatbot with questions that require web search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chapter2-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: 'What are the latest features in LangGraph?'\n",
      "\n",
      "Assistant: \n",
      "Assistant: {\"query\": \"LangGraph platform updates 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://datahub.io/@donbr/langgraph-unleashed/agent-platform-ecosystem\", \"title\": \"Platform Ecosystem: LangGraph alternatives (May 2025)\", \"content\": \"The following diagram illustrates the current landscape of LangGraph alternatives, organized by platform type and updated with the latest 2025 developments:\\n\\n## 1. Open Source Frameworks (Updated)\\n\\n### üÜï Google ADK (Agent Development Kit) [...] ## 2. Enterprise Cloud Platforms (2025 Updates)\\n\\n### üî• Azure AI Foundry Agent Service (GA)\\n\\n Launch: May 19, 2025 - General Availability\\n Unified Experience: AutoGen + Semantic Kernel in single SDK\\n Security: Microsoft Entra Agent ID for enterprise identity management\\n Protocols: Native A2A and MCP support\\n Observability: Built-in performance, quality, cost, and safety metrics\\n Best For: Enterprise Microsoft environments\\n\\n### üîÑ Google Vertex AI (Enhanced) [...] Launch: \\\"Today, we're launching a new, open protocol called Agent2Agent (A2A)\\\" in April 2025\\n Partners: \\\"with support and contributions from more than 50 technology partners like Atlassian, Box, Cohere, Intuit, Langchain, MongoDB, PayPal, Salesforce, SAP, ServiceNow, UKG and Workday\\\"\\n Technology: \\\"JSON-RPC 2.0 over HTTP(S) for request/response interactions\\\" with \\\"Server-Sent Events (SSE) for streaming real-time updates\\\"\", \"score\": 0.85567063, \"raw_content\": null}, {\"url\": \"https://changelog.langchain.com/\", \"title\": \"LangChain - Changelog\", \"content\": \"August 27, 2025\\n\\nLangSmith Self-Hosted\\n\\n## LangSmith Self-Hosted v0.11\\n\\nThis release brings customizable LangGraph Platform deployments, streamlined evaluation via Align Evals, running evals directly from Studio, and operational...\\n\\nAugust 18, 2025\\n\\nLangGraph Platform\\n\\n## Trace Mode in LangGraph Studio\\n\\nDebugging and improving agents just got a lot smoother. With Trace Mode , you can now view your LangSmith traces directly in Studio ‚Äîno more jumping between...\\n\\nAugust 15, 2025\\n\\nLangGraph [...] v0.11.31\\n\\nLangSmith\\n\\n## Create org-scoped API keys with granular permissions\\n\\nYou can now create org-scoped service keys and optionally, assign roles for created keys. These updates give you more control, allowing you to: Learn more...\\n\\nSeptember 9, 2025\\n\\nAugust 2025\\n\\nLangGraph Platform\\n\\n## Revision queueing in LangGraph Platform\\n\\nKeep your deployments smooth and predictable. With Revision Queueing , any new revisions are automatically lined up and processed only after the current one... [...] ## Dynamic tool calling in LangGraph agents\\n\\nAgents don‚Äôt always need the same tools at every step. With dynamic tool calling , you can now control which tools are available at different points in a...\\n\\nAugust 6, 2025\\n\\nJuly 2025\\n\\nLangGraph Platform\\n\\n## Connect traces in LangSmith to server logs in LangGraph Platform\\n\\nWe‚Äôve made agentic observability even easier ‚Äî you can now connect traces in LangSmith to server logs within the LangGraph Platform. When viewing a trace...\\n\\nJuly 31, 2025\", \"score\": 0.8539252, \"raw_content\": null}], \"response_time\": 2.41, \"request_id\": \"91e3bc7d-7761-4369-9b2a-78ee8842e847\"}\n",
      "Assistant: Here‚Äôs a quick roundup of the most recent LangGraph updates (as of Sep 2025), split by open-source core, JS SDK, and Platform/Studio.\n",
      "\n",
      "Open-source LangGraph (Python/JS)\n",
      "- v1.0 alpha releases: New API/docs direction aimed at production-grade agent orchestration with durable execution and finer control. Upgrade paths:\n",
      "  - Python: pip install langgraph==1.0.0a1\n",
      "  - JavaScript: npm install @langchain/langgraph@alpha\n",
      "  - Ref: blog.langchain.com/langchain-langchain-1-0-alpha-releases\n",
      "- Architecture focus: durability/checkpointing, resumability, and precise control over agent graphs (context from ‚ÄúBuilding LangGraph‚Äù). Ref: blog.langchain.com/building-langgraph\n",
      "\n",
      "LangGraph JS SDK (selected recent features from releases)\n",
      "- Stream modes for ‚Äútasks‚Äù and ‚Äúcheckpoints‚Äù: richer, structured streaming for live UIs and observability.\n",
      "- Task result population: easier to consume results from streamed task outputs.\n",
      "- Stream behavior fixes: respect streamMode when invoking subgraphs; better propagation of recursionLimit and signals.\n",
      "- createReactAgent improvements: optional checkpointer support.\n",
      "- Ref: github.com/langchain-ai/langgraphjs/releases\n",
      "\n",
      "LangGraph Platform and Studio\n",
      "- Dynamic tool calling for agents: control which tools are available at different points in a workflow. Ref: changelog.langchain.com (Aug 6, 2025)\n",
      "- Trace Mode in Studio: view LangSmith traces directly in Studio for faster debugging. Ref: changelog.langchain.com (Aug 15, 2025)\n",
      "- Revision queueing: safer, predictable rollout of new revisions to deployments. Ref: changelog.langchain.com (Aug 27, 2025)\n",
      "- Connect LangSmith traces to Platform server logs: tighter observability loop. Ref: changelog.langchain.com (Jul 31, 2025)\n",
      "- LangGraph Server API (docs): assistants/threads/runs with built‚Äëin persistence, task queue, cron jobs, webhooks; designed for deploying and managing agent apps. Ref: docs.langchain.com/langgraph-platform/langgraph-server\n",
      "\n",
      "Sources\n",
      "- 1.0 Alpha announcement: https://blog.langchain.com/langchain-langchain-1-0-alpha-releases/\n",
      "- Building LangGraph (design/feature context): https://blog.langchain.com/building-langgraph/\n",
      "- LangChain/LangGraph Changelog (Platform/Studio): https://changelog.langchain.com/\n",
      "- LangGraph JS releases: https://github.com/langchain-ai/langgraphjs/releases\n",
      "- LangGraph Server docs: https://docs.langchain.com/langgraph-platform/langgraph-server\n",
      "\n",
      "If you tell me your stack (Python or JS) and whether you‚Äôre on open-source only or using Studio/Platform, I can point you to the exact features and code snippets to try.\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    \"\"\"Stream and display graph updates\"\"\"\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "# Test with a question requiring current information\n",
    "print(\"Testing with: 'What are the latest features in LangGraph?'\\n\")\n",
    "stream_graph_updates(\"What are the latest features in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-interactive",
   "metadata": {},
   "source": [
    "## Interactive Chat with Tools\n",
    "\n",
    "Now let's chat with our enhanced bot! Try asking questions that require current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter2-interactive-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Interactive Chatbot with Tools - Chapter 2\")\n",
    "print(\"=\" * 50)\n",
    "print(\"The bot can now search the web for information!\")\n",
    "print(\"Type 'quit', 'exit', or 'q' to exit\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "        print()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nGoodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter2-summary",
   "metadata": {},
   "source": [
    "## Chapter 2 Summary\n",
    "\n",
    "Excellent work! You've now built a tool-augmented AI agent! üéâ\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **Tool Integration**: How to add external tools to your agent\n",
    "2. **Tool Binding**: How to tell the LLM about available tools\n",
    "3. **Tool Nodes**: How to execute tool calls\n",
    "4. **Conditional Edges**: How to add decision points to your graph\n",
    "5. **Loops**: How to create iterative workflows\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Tool Calling**: The LLM decides when to use tools\n",
    "- **Conditional Routing**: The graph flow depends on the LLM's decision\n",
    "- **Tool Node**: Prebuilt node for executing tool calls\n",
    "- **Loops**: The agent can use multiple tools before responding\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In Chapter 3, we'll build an even more sophisticated agent with:\n",
    "- Custom mathematical tools\n",
    "- Advanced state management\n",
    "- State tracking (counting LLM calls)\n",
    "- More complex workflows\n",
    "\n",
    "Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-title",
   "metadata": {},
   "source": [
    "---\n",
    "# Chapter 3: Advanced State Management and Custom Tools\n",
    "\n",
    "In this final chapter, we'll build a sophisticated agent that performs arithmetic operations. This will demonstrate:\n",
    "- Creating custom tools with the `@tool` decorator\n",
    "- Advanced state management (tracking multiple state keys)\n",
    "- Manual tool execution (building our own tool node)\n",
    "- Complex conditional logic\n",
    "\n",
    "## The Agent We'll Build\n",
    "\n",
    "Our agent will:\n",
    "1. Accept arithmetic problems\n",
    "2. Use tools to perform calculations (add, multiply, divide)\n",
    "3. Track how many times the LLM is called\n",
    "4. Show the full reasoning process\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. Custom Tools\n",
    "We'll create our own tools using the `@tool` decorator\n",
    "\n",
    "### 2. Extended State\n",
    "Our state will track both messages and LLM call count\n",
    "\n",
    "### 3. Custom Tool Node\n",
    "We'll build our own tool execution logic\n",
    "\n",
    "### 4. Advanced Routing\n",
    "Custom routing function to decide the next step\n",
    "\n",
    "Let's build it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-tools",
   "metadata": {},
   "source": [
    "## Step 1: Define Custom Tools\n",
    "\n",
    "We'll create three mathematical tools. Notice how we use the `@tool` decorator and provide detailed docstrings - these help the LLM understand when and how to use each tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chapter3-tools-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Custom tools created!\n",
      "\n",
      "Available tools:\n",
      "  - add: Adds a and b.\n",
      "\n",
      "    Args:\n",
      "        a: first int\n",
      "        b: second int\n",
      "  - multiply: Multiply a and b.\n",
      "\n",
      "    Args:\n",
      "        a: first int\n",
      "        b: second int\n",
      "  - divide: Divide a by b.\n",
      "\n",
      "    Args:\n",
      "        a: first int\n",
      "        b: second int\n",
      "\n",
      "Testing tools:\n",
      "  add(3, 4) = 7\n",
      "  multiply(3, 4) = 12\n",
      "  divide(12, 3) = 4.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "# Collect tools\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(\"‚úì Custom tools created!\\n\")\n",
    "print(\"Available tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "# Test the tools\n",
    "print(\"\\nTesting tools:\")\n",
    "print(f\"  add(3, 4) = {add.invoke({'a': 3, 'b': 4})}\")\n",
    "print(f\"  multiply(3, 4) = {multiply.invoke({'a': 3, 'b': 4})}\")\n",
    "print(f\"  divide(12, 3) = {divide.invoke({'a': 12, 'b': 3})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-llm",
   "metadata": {},
   "source": [
    "## Step 2: Set Up the Language Model\n",
    "\n",
    "We'll use Anthropic's Claude for this example. Claude is excellent at tool calling and mathematical reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "chapter3-llm-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Language model initialized!\n",
      "\n",
      "Model: Claude 3.7 Sonnet\n",
      "Temperature: 0 (deterministic)\n",
      "Tools bound: 3\n"
     ]
    }
   ],
   "source": [
    "# Set Anthropic API key if needed\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize Claude\n",
    "llm = init_chat_model(\n",
    "    \"anthropic:claude-3-7-sonnet-latest\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úì Language model initialized!\")\n",
    "print(\"\\nModel: Claude 3.7 Sonnet\")\n",
    "print(\"Temperature: 0 (deterministic)\")\n",
    "print(f\"Tools bound: {len(tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-state",
   "metadata": {},
   "source": [
    "## Step 3: Define Advanced State\n",
    "\n",
    "Our state now tracks two things:\n",
    "1. **messages**: The conversation history (with `add` reducer)\n",
    "2. **llm_calls**: A counter for how many times we call the LLM\n",
    "\n",
    "Notice that `llm_calls` doesn't have a reducer, so it will be overwritten each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-state-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Advanced state defined!\n",
      "\n",
      "State keys:\n",
      "  - messages: list[AnyMessage] (with operator.add reducer)\n",
      "  - llm_calls: int (no reducer - will be replaced)\n",
      "\n",
      "The add reducer will append messages to the list.\n",
      "The llm_calls will be replaced with each update.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "import operator\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    \"\"\"\n",
    "    Advanced state with multiple keys.\n",
    "\n",
    "    Attributes:\n",
    "        messages: List of conversation messages (with add reducer)\n",
    "        llm_calls: Counter for LLM invocations (no reducer - gets replaced)\n",
    "    \"\"\"\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int\n",
    "\n",
    "print(\"‚úì Advanced state defined!\\n\")\n",
    "print(\"State keys:\")\n",
    "print(\"  - messages: list[AnyMessage] (with operator.add reducer)\")\n",
    "print(\"  - llm_calls: int (no reducer - will be replaced)\")\n",
    "print(\"\\nThe add reducer will append messages to the list.\")\n",
    "print(\"The llm_calls will be replaced with each update.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-llm-node",
   "metadata": {},
   "source": [
    "## Step 4: Create the LLM Node\n",
    "\n",
    "Our LLM node now:\n",
    "1. Adds a system message to guide the LLM's behavior\n",
    "2. Calls the LLM with the conversation history\n",
    "3. Increments the LLM call counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-llm-node",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì LLM node created!\n",
      "\n",
      "Node behavior:\n",
      "  1. Adds system message to guide the LLM\n",
      "  2. Sends conversation to LLM with tools\n",
      "  3. Increments llm_calls counter\n",
      "  4. Returns LLM response (may include tool calls)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def llm_call(state: dict):\n",
    "    \"\"\"\n",
    "    LLM node that decides whether to call a tool or respond.\n",
    "\n",
    "    This node:\n",
    "    1. Adds a system message to guide the LLM\n",
    "    2. Invokes the LLM with conversation history\n",
    "    3. Tracks the number of LLM calls\n",
    "\n",
    "    Args:\n",
    "        state: Current state with messages and llm_calls counter\n",
    "\n",
    "    Returns:\n",
    "        State update with new message and incremented counter\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ],\n",
    "        \"llm_calls\": state.get('llm_calls', 0) + 1\n",
    "    }\n",
    "\n",
    "print(\"‚úì LLM node created!\\n\")\n",
    "print(\"Node behavior:\")\n",
    "print(\"  1. Adds system message to guide the LLM\")\n",
    "print(\"  2. Sends conversation to LLM with tools\")\n",
    "print(\"  3. Increments llm_calls counter\")\n",
    "print(\"  4. Returns LLM response (may include tool calls)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-tool-node",
   "metadata": {},
   "source": [
    "## Step 5: Create Custom Tool Node\n",
    "\n",
    "Instead of using the prebuilt ToolNode, we'll build our own to see how it works under the hood.\n",
    "\n",
    "This node:\n",
    "1. Extracts tool calls from the last message\n",
    "2. Executes each tool call\n",
    "3. Packages results as ToolMessages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-tool-node-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Custom tool node created!\n",
      "\n",
      "Tool node process:\n",
      "  1. Extract tool calls from last message\n",
      "  2. For each tool call:\n",
      "     a. Look up the tool by name\n",
      "     b. Invoke with provided arguments\n",
      "     c. Wrap result in ToolMessage\n",
      "  3. Return all tool results\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"\n",
    "    Custom tool node that executes tool calls.\n",
    "\n",
    "    This shows how to manually implement tool execution:\n",
    "    1. Extract tool calls from the last AI message\n",
    "    2. Look up and invoke each tool\n",
    "    3. Format results as ToolMessages\n",
    "\n",
    "    Args:\n",
    "        state: Current state with messages\n",
    "\n",
    "    Returns:\n",
    "        State update with tool result messages\n",
    "    \"\"\"\n",
    "    # Get the last message (should contain tool calls)\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(\"No message found in input\")\n",
    "\n",
    "    # Execute each tool call\n",
    "    outputs = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        # Look up the tool by name\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "\n",
    "        # Invoke the tool with the provided arguments\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "        # Create a ToolMessage with the result\n",
    "        outputs.append(\n",
    "            ToolMessage(\n",
    "                content=str(observation),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "print(\"‚úì Custom tool node created!\\n\")\n",
    "print(\"Tool node process:\")\n",
    "print(\"  1. Extract tool calls from last message\")\n",
    "print(\"  2. For each tool call:\")\n",
    "print(\"     a. Look up the tool by name\")\n",
    "print(\"     b. Invoke with provided arguments\")\n",
    "print(\"     c. Wrap result in ToolMessage\")\n",
    "print(\"  3. Return all tool results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-routing",
   "metadata": {},
   "source": [
    "## Step 6: Define Conditional Routing\n",
    "\n",
    "We need a function to decide what to do after the LLM responds:\n",
    "- If it made tool calls ‚Üí go to tool_node\n",
    "- If it responded directly ‚Üí END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-routing-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Routing function defined!\n",
      "\n",
      "Routing logic:\n",
      "  - If last message has tool_calls ‚Üí route to 'tool_node'\n",
      "  - Otherwise ‚Üí route to END\n",
      "\n",
      "This allows the agent to:\n",
      "  1. Call multiple tools if needed\n",
      "  2. Loop back to think after tool results\n",
      "  3. End when ready to respond to user\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"\n",
    "    Conditional routing function.\n",
    "\n",
    "    Decides whether to:\n",
    "    - Continue to tool_node (if LLM made tool calls)\n",
    "    - End execution (if LLM provided a final answer)\n",
    "\n",
    "    Args:\n",
    "        state: Current state with messages\n",
    "\n",
    "    Returns:\n",
    "        \"tool_node\" if tools should be called, END otherwise\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # If the LLM makes a tool call, perform the action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "print(\"‚úì Routing function defined!\\n\")\n",
    "print(\"Routing logic:\")\n",
    "print(\"  - If last message has tool_calls ‚Üí route to 'tool_node'\")\n",
    "print(\"  - Otherwise ‚Üí route to END\")\n",
    "print(\"\\nThis allows the agent to:\")\n",
    "print(\"  1. Call multiple tools if needed\")\n",
    "print(\"  2. Loop back to think after tool results\")\n",
    "print(\"  3. End when ready to respond to user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-build",
   "metadata": {},
   "source": [
    "## Step 7: Build the Complete Agent\n",
    "\n",
    "Now let's assemble all the pieces into a complete agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-build-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent built and compiled!\n",
      "\n",
      "Agent structure:\n",
      "  Nodes:\n",
      "    - llm_call: Reasons about the problem\n",
      "    - tool_node: Executes calculations\n",
      "\n",
      "  Flow:\n",
      "    START ‚Üí llm_call ‚Üí [decision]\n",
      "                          ‚Üì         ‚Üò\n",
      "                      tool_node     END\n",
      "                          ‚Üì\n",
      "                      llm_call ‚Üí ...\n"
     ]
    }
   ],
   "source": [
    "# Create the graph builder\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call) # type: ignore\n",
    "agent_builder.add_node(\"tool_node\", tool_node) # type: ignore\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    [\"tool_node\", END]\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "print(\"‚úì Agent built and compiled!\\n\")\n",
    "print(\"Agent structure:\")\n",
    "print(\"  Nodes:\")\n",
    "print(\"    - llm_call: Reasons about the problem\")\n",
    "print(\"    - tool_node: Executes calculations\")\n",
    "print(\"\\n  Flow:\")\n",
    "print(\"    START ‚Üí llm_call ‚Üí [decision]\")\n",
    "print(\"                          ‚Üì         ‚Üò\")\n",
    "print(\"                      tool_node     END\")\n",
    "print(\"                          ‚Üì\")\n",
    "print(\"                      llm_call ‚Üí ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-visualize",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Agent\n",
    "\n",
    "Let's see the structure of our agent! Notice the loop and conditional routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "chapter3-visualize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Agent visualization displayed!\n",
      "\n",
      "Key features to notice:\n",
      "  - Conditional edge from llm_call\n",
      "  - Loop from tool_node back to llm_call\n",
      "  - Two possible endpoints: tool_node or END\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Use xray=True to see internal structure\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "    print(\"\\n‚úì Agent visualization displayed!\")\n",
    "    print(\"\\nKey features to notice:\")\n",
    "    print(\"  - Conditional edge from llm_call\")\n",
    "    print(\"  - Loop from tool_node back to llm_call\")\n",
    "    print(\"  - Two possible endpoints: tool_node or END\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not display visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-test",
   "metadata": {},
   "source": [
    "## Step 9: Test the Agent\n",
    "\n",
    "Let's test our agent with a mathematical problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "chapter3-test-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent with: 'Add 3 and 4.'\n",
      "\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "\n",
      "Full conversation:\n",
      "==================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you add 3 and 4 using the add function.\", 'type': 'text'}, {'id': 'toolu_015uwtEPz647UtCSkL6PGVVc', 'input': {'a': 3, 'b': 4}, 'name': 'add', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  add (toolu_015uwtEPz647UtCSkL6PGVVc)\n",
      " Call ID: toolu_015uwtEPz647UtCSkL6PGVVc\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n",
      "==================================================\n",
      "\n",
      "Total LLM calls: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a test message\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "\n",
    "print(\"Testing agent with: 'Add 3 and 4.'\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Invoke the agent\n",
    "result = agent.invoke({\"messages\": messages, \"llm_calls\": 0})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\nFull conversation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display all messages\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTotal LLM calls: {result['llm_calls']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-complex-test",
   "metadata": {},
   "source": [
    "## Step 10: Test with Complex Operations\n",
    "\n",
    "Let's try a more complex problem that requires multiple tool calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-complex-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a complex operation\n",
    "messages = [HumanMessage(content=\"Multiply 3 and 4, then add 10 to the result.\")]\n",
    "\n",
    "print(\"Testing with: 'Multiply 3 and 4, then add 10 to the result.'\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent.invoke({\"messages\": messages, \"llm_calls\": 0})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\nFull conversation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTotal LLM calls: {result['llm_calls']}\")\n",
    "print(\"\\nNote: The agent might need multiple LLM calls to:\")\n",
    "print(\"  1. First call: Decide to multiply 3 and 4\")\n",
    "print(\"  2. Second call: Use the result (12) to add 10\")\n",
    "print(\"  3. Third call: Provide the final answer to the user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-interactive",
   "metadata": {},
   "source": [
    "## Interactive Calculator Agent\n",
    "\n",
    "Now let's create an interactive session with our calculator agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chapter3-interactive",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Interactive Calculator Agent - Chapter 3\")\n",
    "print(\"=\" * 50)\n",
    "print(\"This agent can perform arithmetic operations!\")\n",
    "print(\"Try asking it to add, multiply, or divide numbers.\")\n",
    "print(\"Type 'quit', 'exit', or 'q' to exit\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Invoke the agent\n",
    "        messages = [HumanMessage(content=user_input)]\n",
    "        result = agent.invoke({\"messages\": messages, \"llm_calls\": 0})\n",
    "\n",
    "        # Display only the final response\n",
    "        final_message = result[\"messages\"][-1]\n",
    "        print(f\"\\nAssistant: {final_message.content}\")\n",
    "        print(f\"(Used {result['llm_calls']} LLM calls)\\n\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nGoodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter3-summary",
   "metadata": {},
   "source": [
    "## Chapter 3 Summary\n",
    "\n",
    "Congratulations! You've built a sophisticated AI agent with advanced capabilities! üéâ\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **Custom Tools**: How to create tools with the `@tool` decorator\n",
    "2. **Advanced State**: How to track multiple state keys\n",
    "3. **Custom Tool Nodes**: How tool execution works under the hood\n",
    "4. **State Tracking**: How to monitor agent behavior (LLM calls)\n",
    "5. **Complex Workflows**: How agents can loop and make multiple decisions\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Custom Tools**: Define domain-specific operations\n",
    "- **Extended State**: Track multiple pieces of information\n",
    "- **Manual Tool Execution**: Full control over tool calling\n",
    "- **State Monitoring**: Track and optimize agent behavior\n",
    "- **Iterative Problem Solving**: Agents can use tools multiple times\n",
    "\n",
    "### Differences from Chapter 2:\n",
    "\n",
    "| Aspect | Chapter 2 | Chapter 3 |\n",
    "|--------|-----------|----------|\n",
    "| Tools | Prebuilt (Tavily) | Custom (@tool) |\n",
    "| State | Messages only | Messages + counter |\n",
    "| Tool Node | Prebuilt ToolNode | Custom implementation |\n",
    "| Routing | Prebuilt tools_condition | Custom should_continue |\n",
    "| Purpose | Web search | Arithmetic operations |\n",
    "\n",
    "### What You Can Build Now:\n",
    "\n",
    "With these skills, you can create:\n",
    "- **Research Agents**: Agents that search and synthesize information\n",
    "- **Data Processing Agents**: Agents that manipulate and analyze data\n",
    "- **Workflow Automation**: Agents that orchestrate complex processes\n",
    "- **Interactive Assistants**: Conversational agents with specialized skills\n",
    "- **Multi-Tool Agents**: Agents that combine multiple capabilities\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "To continue your LangGraph journey:\n",
    "\n",
    "1. **Add Memory**: Make agents remember across sessions\n",
    "2. **Human-in-the-Loop**: Add approval workflows\n",
    "3. **Parallel Execution**: Run multiple tools simultaneously\n",
    "4. **Error Handling**: Make agents robust to failures\n",
    "5. **Multi-Agent Systems**: Coordinate multiple specialized agents\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- üìö [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- üéì [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n",
    "- üí¨ [LangChain Discord](https://discord.gg/langchain)\n",
    "- üì∫ [YouTube Tutorials](https://www.youtube.com/@LangChain)\n",
    "\n",
    "Thank you for completing this comprehensive tutorial! üöÄ\n",
    "\n",
    "Happy building! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-notes",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Complete Code Snippets\n",
    "\n",
    "Here are complete, runnable code snippets for each chapter that you can copy and use:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appendix-chapter1",
   "metadata": {},
   "source": [
    "### Chapter 1: Basic Chatbot (Complete Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appendix-chapter1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Chapter 1 code\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# LLM\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0)\n",
    "\n",
    "# Graph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Use it\n",
    "# result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n",
    "# print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appendix-chapter2",
   "metadata": {},
   "source": [
    "### Chapter 2: Chatbot with Tools (Complete Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appendix-chapter2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Chapter 2 code\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# State\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Tools\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "# LLM with tools\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Graph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Use it\n",
    "# result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What's new in AI?\"}]})\n",
    "# print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appendix-chapter3",
   "metadata": {},
   "source": [
    "### Chapter 3: Advanced Agent (Complete Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appendix-chapter3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Chapter 3 code\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, ToolMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "import operator\n",
    "\n",
    "# Tools\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# LLM\n",
    "llm = init_chat_model(\"anthropic:claude-3-7-sonnet-latest\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# State\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int\n",
    "\n",
    "# Nodes\n",
    "def llm_call(state: dict):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ],\n",
    "        \"llm_calls\": state.get('llm_calls', 0) + 1\n",
    "    }\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(\"No message found in input\")\n",
    "\n",
    "    outputs = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        outputs.append(\n",
    "            ToolMessage(\n",
    "                content=str(observation),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    return END\n",
    "\n",
    "# Graph\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\"llm_call\", should_continue, [\"tool_node\", END])\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Use it\n",
    "# from langchain_core.messages import HumanMessage\n",
    "# result = agent.invoke({\"messages\": [HumanMessage(content=\"Add 3 and 4.\")], \"llm_calls\": 0})\n",
    "# print(result[\"messages\"][-1].content)\n",
    "# print(f\"LLM calls: {result['llm_calls']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
