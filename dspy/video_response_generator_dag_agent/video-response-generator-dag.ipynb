{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once per environment)\n",
        "%pip install -q dspy python-dotenv google-genai fal-client pillow ffmpeg-python\n",
        "print(\"Note: restart the kernel if packages were freshly installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic imports and environment setup\n",
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from dspy import History\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Configure LM (Anthropic or OpenAI OK; using OpenAI mini for text-only here)\n",
        "lm = dspy.LM(\"openai/gpt-5-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=0.3, max_tokens=16000)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"DSPy configured for Video Response Generator DAG.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pydantic models equivalent to LangGraph `models.py`\n",
        "from typing import Dict\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class BuyingSituation(BaseModel):\n",
        "    situation: str\n",
        "    location: str\n",
        "    trigger: str\n",
        "    evaluation: str\n",
        "    conclusion: str\n",
        "\n",
        "class BuyingSituationsOutput(BaseModel):\n",
        "    persona: str = Field(..., description=\"Name or identifier for the persona\")\n",
        "    buying_situations: Dict[str, BuyingSituation]\n",
        "\n",
        "class SceneDescription(BaseModel):\n",
        "    persona: str\n",
        "    appearance: str\n",
        "\n",
        "class PromptModel(BaseModel):\n",
        "    scene_description: SceneDescription\n",
        "    quote: str\n",
        "    prompt_string: str\n",
        "\n",
        "class PromptOutput(BaseModel):\n",
        "    prompt: PromptModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core tools ported from LangGraph DAG (plain Python functions)\n",
        "import time\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing import Any, List, Dict, Optional, cast\n",
        "\n",
        "import httpx\n",
        "\n",
        "# Phase 0: init and persona catalog\n",
        "\n",
        "def init_and_create_directory() -> Dict[str, str]:\n",
        "    execution_id = uuid.uuid4().hex\n",
        "    work_dir = Path(f\"/tmp/n8n/{execution_id}\")\n",
        "    work_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for f in [\"videos.txt\", \"final_output.mp4\"]:\n",
        "        try:\n",
        "            (work_dir / f).unlink(missing_ok=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {\"execution_id\": execution_id, \"work_dir\": str(work_dir)}\n",
        "\n",
        "\n",
        "def define_personas() -> Dict[str, Dict[str, Dict[str, str]]]:\n",
        "    personas: Dict[str, Dict[str, str]] = {\n",
        "        \"Omar US Developer\": {\n",
        "            \"name\": \"Omar Ali\",\n",
        "            \"age\": \"32\",\n",
        "            \"gender\": \"Male\",\n",
        "            \"location\": \"San Francisco\",\n",
        "            \"occupation\": \"Software Engineer\",\n",
        "            \"income\": \"$200,000\",\n",
        "            \"background\": (\n",
        "                \"This individual's life revolves around exploration and understanding. They are deeply curious about the world, people, and how things work, often delving into complex topics such as philosophy, history, and the human psyche. Their online presence is a reflection of their inner world - an active, thoughtful space where they seek to make connections, exchange ideas, and learn from others. They love the act of learning and self-improvement. They have a strong desire to make things better for themselves and the world around them, expressed through their writing and interactions. This person is committed to their craft, valuing beauty and truth, and finds joy in the small, everyday aspects of life. They are fascinated by the power of human connection and the potential for growth within communities. They are known for their inquisitive nature, often posing questions and seeking different perspectives to broaden their understanding of the world. They have an open mind and are constantly seeking a deeper understanding of complex concepts and human behavior. Their curiosity is a constant source of inspiration, driving them to explore new ideas, challenge their beliefs, and make meaningful connections with others.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Sarah UK Nurse\": {\n",
        "            \"name\": \"Sarah Thomspon\",\n",
        "            \"age\": \"55\",\n",
        "            \"gender\": \"Woman\",\n",
        "            \"location\": \"Manchester, UK\",\n",
        "            \"occupation\": \"Nurse\",\n",
        "            \"income\": \"GBP 55k\",\n",
        "            \"background\": (\n",
        "                \"Sarah is a dedicated Registered Nurse with over thirty years of experience in the NHS. Raised in a working-class family, she was inspired to pursue nursing by her strong desire to help others and provide compassionate care. She is married, owns her home, and is a devout Christian, finding strength in her faith and family. Sarah is a strong advocate for her patients and believes healthcare is a fundamental right. She enjoys reading, gardening, and spending time outdoors, which helps her manage the stress that comes with her demanding job. Throughout her career, she has consistently strived to improve her skills and provide the best possible care to her patients.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Emily US Foodie\": {\n",
        "            \"name\": \"Emily Carter\",\n",
        "            \"age\": \"21\",\n",
        "            \"gender\": \"Female\",\n",
        "            \"location\": \"Los Angeles, CA\",\n",
        "            \"occupation\": \"Student\",\n",
        "            \"income\": \"NA\",\n",
        "            \"background\": (\n",
        "                \"Emily Carter is a 21-year-old college student at UCLA, majoring in Digital Marketing. Originally from a small town in Oregon, she moved to Los Angeles to pursue her passion for marketing and content creation. She's an avid foodie, constantly exploring LA's diverse culinary landscape and documenting her experiences on TikTok and Instagram. Her content focuses on restaurant reviews, food trends, and lifestyle content, and she hopes to work in social media marketing after graduation.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Clara US Health Coach\": {\n",
        "            \"name\": \"Clara Johnson\",\n",
        "            \"age\": \"35\",\n",
        "            \"gender\": \"Female\",\n",
        "            \"location\": \"New York City, NY\",\n",
        "            \"occupation\": \"Health Coach\",\n",
        "            \"income\": \"$70k\",\n",
        "            \"background\": (\n",
        "                \"Clara, a certified holistic health coach, was raised in a culturally diverse household where natural wellness was a way of life. Inspired by her family's practices, she pursued a certification in holistic health and launched her coaching business in NYC. Through her work at NaturalHealth Inc., Clara focuses on promoting holistic beauty methods, integrating wellness with skincare, and educating others on the benefits of natural products. She is passionate about community workshops and uses her platform to share DIY beauty techniques, encouraging others to embrace natural wellness. She is a Buddhist who believes beauty comes from within and enjoys meditation, nature walks, and creating healthy meals.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Jordan US Tattoo Artist\": {\n",
        "            \"name\": \"Jordan McCulloch\",\n",
        "            \"age\": \"Age 5\",\n",
        "            \"gender\": \"Male\",\n",
        "            \"location\": \"Portland, OR, USA\",\n",
        "            \"occupation\": \"Tattoo Artist\",\n",
        "            \"income\": \"$48k\",\n",
        "            \"background\": (\n",
        "                \"Jordan grew up in a small coastal town in Oregon before moving to Portland to embrace the city’s alternative scene and vibrant art community. With a talent for visual storytelling and a welcoming demeanor, Jordan found a calling in tattoo artistry, channeling creativity into meaningful body art for friends and clients. Passionate about authentic self-expression and forging real connections, Jordan has built a loyal client base and a network of close friends who share a love of indie music, art shows, and late-night philosophical discussions. Jordan values openness in relationships and tends to express themselves candidly, both in art and conversation. When not at the tattoo studio, Jordan spends time volunteering for LGBTQ+ causes, making zines, and exploring the city’s eclectic food scene.\"\n",
        "            ),\n",
        "        },\n",
        "    }\n",
        "    return {\"personas\": personas}\n",
        "\n",
        "\n",
        "def set_persona(personas: Dict[str, Dict[str, str]], persona_selection: str) -> Dict[str, str]:\n",
        "    if not persona_selection or persona_selection not in personas:\n",
        "        raise ValueError(\"persona_selection is missing or invalid\")\n",
        "    return personas[persona_selection]\n",
        "\n",
        "\n",
        "# Phase 1: Buying situations via LM\n",
        "\n",
        "def _get_llm_predict():\n",
        "    return dspy.Predict(\"question -> answer\")\n",
        "\n",
        "\n",
        "def generate_buying_situations(persona: Dict[str, str]) -> Dict[str, Any]:\n",
        "    if not persona:\n",
        "        raise KeyError(\"persona missing; ensure set_persona ran first\")\n",
        "    system = (\n",
        "        \"Role play as {name}, a {age} {gender} from {location}, works as a {occupation} \"\n",
        "        \"earning {income}. {background}. You have been invited to review a new product \"\n",
        "        \"concept and reveal deep, personal insights into when you would buy this offer. \"\n",
        "        \"Return only valid JSON with fields persona (string) and buying_situations (object with exactly 3 keys).\"\n",
        "    ).format(**persona)\n",
        "    example = '{\"persona\":\"Rhys UK Entrepreneur\",\"buying_situations\":{\"celebrating_milestone\":{\"situation\":\"Celebrating a business milestone\",\"location\":\"Private members\\' club in London\",\"trigger\":\"Closed a major deal\",\"evaluation\":\"Considered champagne and cocktails, but wanted tradition\",\"conclusion\":\"Chose premium whisky\"},\"hosting_partners\":{\"situation\":\"Hosting international partners\",\"location\":\"Home office in Manchester\",\"trigger\":\"Inviting overseas investors\",\"evaluation\":\"Compared various spirits; whisky is distinctly British\",\"conclusion\":\"Bought respected Scottish whisky\"},\"relaxing_weekend\":{\"situation\":\"Relaxing after a long week\",\"location\":\"Apartment balcony overlooking the city\",\"trigger\":\"Needed a way to unwind\",\"evaluation\":\"Looked at beer, gin, wine; whisky appealed\",\"conclusion\":\"Chose whisky as a ritual drink\"}}}'\n",
        "    prompt = (\n",
        "        \"Respond only with raw JSON (no markdown). Use this schema and ensure 3 buying_situations. Example: \"\n",
        "        f\"{example}\"\n",
        "    )\n",
        "    predictor = _get_llm_predict()\n",
        "    raw = predictor(question=f\"{system}\\n\\n{prompt}\")\n",
        "    text = getattr(raw, \"answer\", \"\")\n",
        "    data = None\n",
        "    for _ in range(2):\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "            break\n",
        "        except Exception:\n",
        "            repair = predictor(question=\"Repair to valid JSON with the same schema: \" + text)\n",
        "            text = getattr(repair, \"answer\", \"\")\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to parse buying situations JSON\")\n",
        "    validated = BuyingSituationsOutput.model_validate(data)\n",
        "    situations_list = list(validated.buying_situations.values())\n",
        "    return {\n",
        "        \"buying_situations\": validated.buying_situations,\n",
        "        \"situations_list\": situations_list,\n",
        "        \"situation_index\": 0,\n",
        "        \"prompts_json\": [],\n",
        "        \"prompt_strings\": [],\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_prompt_for_current(persona: Dict[str, str], situations_list: List[BuyingSituation], situation_index: int) -> Dict[str, Any]:\n",
        "    if not (0 <= situation_index < len(situations_list)):\n",
        "        raise IndexError(\"situation_index out of range\")\n",
        "    situation = situations_list[situation_index]\n",
        "    template = (\n",
        "        \"You are a director of a qualitative research agency that specialises in creating realistic simulated testimonials that capture buying situations for new product concepts.\\n\\n\"\n",
        "        \"Your tasks are to: 1) Craft persona description, 2) scene appearance, 3) a short 6–8s quote, 4) assemble final prompt string.\\n\"\n",
        "        \"Return a structured object strictly matching this Pydantic schema: PromptOutput(prompt: PromptModel(scene_description: SceneDescription(persona, appearance), quote, prompt_string)). No markdown.\\n\\n\"\n",
        "        \"Persona\\n\"\n",
        "        f\"Name: {persona['name']}\\n\"\n",
        "        f\"Age: {persona['age']}\\n\"\n",
        "        f\"Gender: {persona['gender']}\\n\"\n",
        "        f\"Location: {persona['location']}\\n\"\n",
        "        f\"Occupation: {persona['occupation']}\\n\"\n",
        "        f\"Income: {persona['income']}\\n\"\n",
        "        f\"Background: {persona['background']}\\n\\n\"\n",
        "        \"Buying Situation\\n\"\n",
        "        f\"Situation: {situation.situation}\\n\"\n",
        "        f\"Location: {situation.location}\\n\"\n",
        "        f\"Trigger: {situation.trigger}\\n\"\n",
        "        f\"Evaluation: {situation.evaluation}\\n\"\n",
        "        f\"Conclusion: {situation.conclusion}\"\n",
        "    )\n",
        "    predictor = dspy.Predict(\"instruction -> json_text\")\n",
        "    raw = predictor(instruction=template)\n",
        "    text = getattr(raw, \"json_text\", \"\")\n",
        "    data = None\n",
        "    for _ in range(2):\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "            break\n",
        "        except Exception:\n",
        "            repair = dspy.Predict(\"text -> json_text\")(text=\"Repair and return valid JSON only, same schema.\\n\\n\" + text)\n",
        "            text = getattr(repair, \"json_text\", \"\")\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to parse prompt JSON\")\n",
        "    validated = PromptOutput.model_validate(data)\n",
        "    return {\"prompt_json\": validated, \"prompt_string\": validated.prompt.prompt_string}\n",
        "\n",
        "\n",
        "# Phase 3: FAL queue and video merging\n",
        "\n",
        "def _fal_headers() -> Dict[str, str]:\n",
        "    name = os.getenv(\"FAL_AUTH_HEADER_NAME\", \"Authorization\")\n",
        "    value = os.getenv(\"FAL_AUTH_HEADER_VALUE\")\n",
        "    if not value:\n",
        "        api_key = os.getenv(\"FAL_API_KEY\") or os.getenv(\"FAL_KEY\")\n",
        "        if api_key:\n",
        "            value = f\"Key {api_key}\"\n",
        "    return {name: value} if value else {}\n",
        "\n",
        "\n",
        "def submit_fal_requests(prompt_strings: List[str]) -> List[Dict[str, str]]:\n",
        "    base_url = os.getenv(\"FAL_QUEUE_URL\", \"https://queue.fal.run/fal-ai/veo3\")\n",
        "    headers = _fal_headers()\n",
        "    requests_info: List[Dict[str, str]] = []\n",
        "    with httpx.Client(timeout=60) as client:\n",
        "        for prompt in prompt_strings:\n",
        "            resp = client.post(base_url, headers=headers, json={\"prompt\": prompt})\n",
        "            resp.raise_for_status()\n",
        "            data = resp.json()\n",
        "            request_id = data.get(\"request_id\") or data.get(\"id\")\n",
        "            status_url = data.get(\"status_url\") or data.get(\"status\")\n",
        "            if not request_id or not status_url:\n",
        "                raise ValueError(f\"Unexpected FAL response: {data}\")\n",
        "            requests_info.append({\"request_id\": request_id, \"status_url\": status_url})\n",
        "    return requests_info\n",
        "\n",
        "\n",
        "def poll_statuses(fal_requests: List[Dict[str, str]]) -> Dict[str, Any]:\n",
        "    headers = _fal_headers()\n",
        "    statuses: List[str] = []\n",
        "    with httpx.Client(timeout=30) as client:\n",
        "        for req in fal_requests:\n",
        "            url = req[\"status_url\"]\n",
        "            resp = client.get(url, headers=headers)\n",
        "            resp.raise_for_status()\n",
        "            data = resp.json()\n",
        "            statuses.append(str(data.get(\"status\", \"\")).upper())\n",
        "    all_complete = all(s == \"COMPLETED\" for s in statuses) if statuses else False\n",
        "    return {\"statuses\": statuses, \"all_complete\": all_complete}\n",
        "\n",
        "\n",
        "def fetch_video_urls(fal_requests: List[Dict[str, str]]) -> List[str]:\n",
        "    base_url = os.getenv(\"FAL_REQUEST_URL_BASE\", \"https://queue.fal.run/fal-ai/veo3/requests\")\n",
        "    headers = _fal_headers()\n",
        "    video_urls: List[str] = []\n",
        "    with httpx.Client(timeout=60) as client:\n",
        "        for req in fal_requests:\n",
        "            rid = req[\"request_id\"]\n",
        "            url = f\"{base_url}/{rid}\"\n",
        "            resp = client.get(url, headers=headers)\n",
        "            resp.raise_for_status()\n",
        "            data = resp.json()\n",
        "            video_url = (\n",
        "                data.get(\"video\", {}).get(\"url\") if isinstance(data.get(\"video\"), dict)\n",
        "                else data.get(\"video_url\") or data.get(\"url\")\n",
        "            )\n",
        "            if not video_url:\n",
        "                raise ValueError(f\"No video URL in response: {data}\")\n",
        "            video_urls.append(str(video_url))\n",
        "    return video_urls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download + ffmpeg helpers\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def download_videos(video_urls: List[str], work_dir: str) -> List[str]:\n",
        "    Path(work_dir).mkdir(parents=True, exist_ok=True)\n",
        "    files: List[str] = []\n",
        "    with httpx.Client(timeout=None, follow_redirects=True) as client:\n",
        "        for i, url in enumerate(video_urls):\n",
        "            file_name = f\"{i:02d}.mp4\"\n",
        "            file_path = Path(work_dir) / file_name\n",
        "            with client.stream(\"GET\", url) as resp:\n",
        "                resp.raise_for_status()\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    for chunk in resp.iter_bytes():\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "            files.append(str(file_path))\n",
        "    return files\n",
        "\n",
        "\n",
        "def prepare_concat_file(work_dir: str) -> None:\n",
        "    list_path = Path(work_dir) / \"videos.txt\"\n",
        "    lines = []\n",
        "    for p in sorted(Path(work_dir).glob(\"*.mp4\")):\n",
        "        lines.append(f\"file '{p.name}'\\n\")\n",
        "    list_path.write_text(\"\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def _which(cmd: str) -> Optional[str]:\n",
        "    return shutil.which(cmd)\n",
        "\n",
        "\n",
        "def merge_videos_ffmpeg(work_dir: str) -> str:\n",
        "    if not _which(\"ffmpeg\"):\n",
        "        raise RuntimeError(\"ffmpeg not found in PATH. Please install ffmpeg.\")\n",
        "    videos_txt = Path(work_dir) / \"videos.txt\"\n",
        "    if not videos_txt.exists():\n",
        "        raise FileNotFoundError(f\"Missing {videos_txt}\")\n",
        "    final_path = Path(work_dir) / \"final_output.mp4\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", str(videos_txt), \"-c\", \"copy\", \"-y\", str(final_path)\n",
        "    ]\n",
        "    subprocess.run(cmd, cwd=str(work_dir), check=True, capture_output=True)\n",
        "    return str(final_path)\n",
        "\n",
        "\n",
        "def finalize_result(execution_id: str) -> Dict[str, str]:\n",
        "    video_url = f\"http://localhost:3001/video/{execution_id}/final_output.mp4\"\n",
        "    return {\n",
        "        \"videoUrl\": video_url,\n",
        "        \"executionId\": execution_id,\n",
        "        \"message\": \"Video processing complete\",\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sequential orchestrator that mirrors the LangGraph DAG happy path\n",
        "\n",
        "def run_video_response_agent(persona_selection: str, wait_seconds: int = 1) -> Dict[str, Any]:\n",
        "    # Phase 0: init + personas\n",
        "    init = init_and_create_directory()\n",
        "    execution_id = init[\"execution_id\"]\n",
        "    work_dir = init[\"work_dir\"]\n",
        "    personas = define_personas()[\"personas\"]\n",
        "    persona = set_persona(personas, persona_selection)\n",
        "\n",
        "    # Phase 1: generate buying situations\n",
        "    bs = generate_buying_situations(persona)\n",
        "    situations_list: List[BuyingSituation] = bs[\"situations_list\"]\n",
        "\n",
        "    # Phase 2: loop prompts for each situation\n",
        "    prompts_json: List[PromptOutput] = []\n",
        "    prompt_strings: List[str] = []\n",
        "    for idx in range(len(situations_list)):\n",
        "        out = generate_prompt_for_current(persona, situations_list, idx)\n",
        "        pj = cast(PromptOutput, out[\"prompt_json\"])  # type: ignore\n",
        "        prompts_json.append(pj)\n",
        "        prompt_strings.append(str(out[\"prompt_string\"]))\n",
        "\n",
        "    # Phase 3: FAL queue\n",
        "    fal_requests = submit_fal_requests(prompt_strings)\n",
        "\n",
        "    # Wait and poll until complete (simplified)\n",
        "    time.sleep(max(0, int(wait_seconds)))\n",
        "    for _ in range(10):\n",
        "        status_info = poll_statuses(fal_requests)\n",
        "        if status_info[\"all_complete\"]:\n",
        "            break\n",
        "        time.sleep(max(0, int(wait_seconds)))\n",
        "\n",
        "    video_urls = fetch_video_urls(fal_requests)\n",
        "\n",
        "    # Download and merge\n",
        "    _ = download_videos(video_urls, work_dir)\n",
        "    prepare_concat_file(work_dir)\n",
        "    final_path = merge_videos_ffmpeg(work_dir)\n",
        "\n",
        "    # Final payload\n",
        "    result = finalize_result(execution_id)\n",
        "    return {\n",
        "        \"execution_id\": execution_id,\n",
        "        \"work_dir\": work_dir,\n",
        "        \"prompts\": [p.model_dump() for p in prompts_json],\n",
        "        \"video_urls\": video_urls,\n",
        "        \"final_path\": final_path,\n",
        "        \"result\": result,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage (smoke test)\n",
        "try:\n",
        "    demo = run_video_response_agent(persona_selection=\"Omar US Developer\", wait_seconds=1)\n",
        "    print({\n",
        "        \"execution_id\": demo.get(\"execution_id\"),\n",
        "        \"work_dir\": demo.get(\"work_dir\"),\n",
        "        \"video_urls_count\": len(demo.get(\"video_urls\", [])),\n",
        "        \"final_path\": demo.get(\"final_path\"),\n",
        "        \"result\": demo.get(\"result\"),\n",
        "    })\n",
        "except Exception as e:\n",
        "    print({\"error\": str(e)})\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
