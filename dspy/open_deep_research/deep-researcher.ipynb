{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once per environment)\n",
        "%pip install -q dspy python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy configured for Deep Research agent.\n"
          ]
        }
      ],
      "source": [
        "# Basic imports and environment setup\n",
        "import os\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from dspy import History\n",
        "\n",
        "# Load API keys from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Configure model provider (OpenAI-only, per LangGraph agent)\n",
        "lm = dspy.LM(\"openai/gpt-5-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1, max_tokens=16000)\n",
        "\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "# Conversation memory\n",
        "conversation_history = History(messages=[])\n",
        "\n",
        "print(\"DSPy configured for Deep Research agent.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utils: helpers\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_today_str() -> str:\n",
        "    now = datetime.now()\n",
        "    return f\"{now:%a} {now:%b} {now.day}, {now:%Y}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tools: OpenAI-only research + think tool\n",
        "from typing import List, Literal\n",
        "\n",
        "\n",
        "def openai_search(queries: List[str], max_results: int = 5, topic: Literal[\"general\", \"news\"] = \"general\") -> str:\n",
        "    \"\"\"Generate comprehensive research responses using the model's knowledge base.\n",
        "\n",
        "    Mirrors the LangGraph `openai_search` tool behavior at a high level.\n",
        "    We keep a simple sequential loop for clarity in DSPy.\n",
        "    \"\"\"\n",
        "    if not isinstance(queries, list) or not queries:\n",
        "        return \"No research results could be generated. Please provide queries.\"\n",
        "\n",
        "    results = []\n",
        "    for q in queries[:max_results]:\n",
        "        if topic == \"news\":\n",
        "            prompt = f\"\"\"Please provide a comprehensive research summary for the following current events query: \"{q}\"\n",
        "\n",
        "Focus on recent developments and provide:\n",
        "1. Key facts and developments\n",
        "2. Timeline of important events\n",
        "3. Current status and implications\n",
        "4. Sources and references you know of\n",
        "\n",
        "Be thorough and objective. Include dates where relevant.\"\"\"\n",
        "        else:\n",
        "            prompt = f\"\"\"Please provide comprehensive information for the following research query: \"{q}\"\n",
        "\n",
        "Structure your response to include:\n",
        "1. Key facts and background information\n",
        "2. Important details and context\n",
        "3. Current understanding and implications\n",
        "4. Any relevant examples or case studies\n",
        "\n",
        "Be thorough and provide detailed, accurate information based on your knowledge.\"\"\"\n",
        "        # Single-turn call\n",
        "        resp = dspy.Predict(\"answer\")(question=prompt)  # lightweight call\n",
        "        content = getattr(resp, \"answer\", \"\") if isinstance(resp, dspy.Prediction) else str(resp)\n",
        "        results.append(f\"--- RESEARCH RESULT: {q} ---\\n{content}\\n\")\n",
        "\n",
        "    if not results:\n",
        "        return \"No research results could be generated.\"\n",
        "    return (f\"OpenAI Research Results ({topic} focus):\\n\\n\" + \"\\n\\n\".join(results)).strip()\n",
        "\n",
        "\n",
        "def think_tool(reflection: str) -> str:\n",
        "    \"\"\"Strategic reflection tool for research planning.\n",
        "\n",
        "    Use after searches to analyze results and plan next steps.\n",
        "    \"\"\"\n",
        "    return f\"Reflection recorded: {reflection}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ReAct Signature for Deep Research\n",
        "\n",
        "class ResearchReActSignature(dspy.Signature):\n",
        "    \"\"\"\n",
        "    You are a deep research assistant. Use tools to gather information (openai_search for research, think_tool for reflection).\n",
        "    Keep searches focused, reflect after searches, and finish with a concise, well-structured research answer.\n",
        "\n",
        "    You can call tools: openai_search, think_tool.\n",
        "    When finished, produce:\n",
        "    - `action`: the primary tool used (one of: openai_search, think_tool, answer_direct)\n",
        "    - `tool_result`: the most relevant tool output you used (may be empty for answer_direct)\n",
        "    - `answer`: the final research answer/report\n",
        "    Keep responses clear and professional.\n",
        "    \"\"\"\n",
        "    user_message: str = dspy.InputField(description=\"The user's research request\")\n",
        "    history: dspy.History = dspy.InputField(description=\"Conversation history\")\n",
        "\n",
        "    reasoning: str = dspy.OutputField(description=\"Brief plan and justification\")\n",
        "    action: str = dspy.OutputField(description=\"Chosen action/tool\")\n",
        "    tool_result: str = dspy.OutputField(description=\"Tool output used to answer\")\n",
        "    answer: str = dspy.OutputField(description=\"Final research answer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ReAct agent with research tools\n",
        "\n",
        "react_agent = dspy.ReAct(\n",
        "    ResearchReActSignature,\n",
        "    tools=[openai_search, think_tool],\n",
        "    max_iters=5,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entry point using ReAct agent\n",
        "\n",
        "def run_deep_research(user_message: str) -> dict:\n",
        "    if not isinstance(user_message, str) or not user_message.strip():\n",
        "        return {\"answer\": \"\", \"action\": \"reject\", \"tool_result\": \"\"}\n",
        "\n",
        "    conversation_history.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    result = react_agent(\n",
        "        user_message=user_message,\n",
        "        history=conversation_history,\n",
        "    )\n",
        "\n",
        "    answer = getattr(result, \"answer\", \"\")\n",
        "    action = getattr(result, \"action\", \"\")\n",
        "    tool_result = getattr(result, \"tool_result\", \"\")\n",
        "\n",
        "    if isinstance(answer, str) and answer.strip():\n",
        "        conversation_history.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "    return {\"answer\": answer, \"action\": action, \"tool_result\": tool_result}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example 1 ---\n",
            "{'answer': 'Overview (short)\\n- Ownership: Each value has one owner (a variable). When the owner goes out of scope, the value is dropped.\\n- Move vs Copy: Non-primitive types (e.g., String, Vec) are moved by default. Types that implement Copy (integers, bools, char, simple tuples) are copied on assignment.\\n- Borrowing: You can create references: &T (immutable borrow) or &mut T (mutable borrow). The borrow checker enforces safety rules at compile time.\\n- Key borrow rules:\\n  1. At any time, you may have either:\\n     - any number of immutable (&T) references, or\\n     - exactly one mutable (&mut T) reference.\\n  2. References must always be valid (no dangling refs).\\n- Lifetimes: The compiler tracks how long references live. You annotate explicit lifetimes when necessary for function signatures.\\n\\nExamples\\n\\n1) Move (ownership transfer) and Clone\\nlet s1 = String::from(\"hello\");\\nlet s2 = s1; // s1 is moved into s2 and becomes invalid\\n// println!(\"{}\", s1); // error: use of moved value\\nlet s3 = s2.clone(); // deep copy; s2 and s3 both valid afterwards\\n\\n2) Copy types\\nlet x = 5;\\nlet y = x; // x is still usable because i32 implements Copy\\nprintln!(\"{}\", x); // OK\\n\\n3) Immutable borrow\\nlet s = String::from(\"hello\");\\nlet r1 = &s;\\nlet r2 = &s; // many immutable borrows allowed\\nprintln!(\"{} and {}\", r1, r2);\\n\\n4) Mutable borrow\\nlet mut s = String::from(\"hello\");\\nlet r = &mut s; // only one mutable borrow allowed\\nr.push_str(\" world\");\\n// println!(\"{}\", s); // error while r is still in scope borrowing s\\n// drop r or end its scope before using s again\\n\\n5) Borrow rules example (error + fix)\\nfn main() {\\n    let mut s = String::from(\"hello\");\\n    let r1 = &s;\\n    let r2 = &mut s; // error: cannot borrow `s` as mutable because it is also borrowed as immutable\\n    println!(\"{}, {}\", r1, r2);\\n}\\n// Fix: ensure immutable borrows end before the mutable borrow:\\nfn fixed() {\\n    let mut s = String::from(\"hello\");\\n    {\\n        let r1 = &s;\\n        println!(\"{}\", r1);\\n    } // r1 scope ends here\\n    let r2 = &mut s; // OK\\n    r2.push_str(\" world\");\\n}\\n\\n6) Lifetimes — preventing dangling references\\n// Error: returning reference to local variable\\nfn bad() -> &String {\\n    let s = String::from(\"hello\");\\n    &s // error: `s` does not live long enough\\n}\\n// Fix: return owned value or accept and return a reference with appropriate lifetime:\\nfn good_owned() -> String {\\n    let s = String::from(\"hello\");\\n    s // move out; owner returned\\n}\\nfn longest<\\'a>(x: &\\'a str, y: &\\'a str) -> &\\'a str {\\n    if x.len() >= y.len() { x } else { y }\\n}\\n\\nCommon compiler errors & fixes\\n- \"use of moved value\": either stop using the moved variable, borrow instead (&String), or clone() if you need a duplicate.\\n- \"cannot borrow `x` as mutable because it is also borrowed as immutable\": ensure immutable borrows are out of scope before creating a mutable borrow, or avoid simultaneous borrows.\\n- \"returns a reference to data owned by the current function\": return an owned value, or use lifetime parameters to tie the return reference to an input reference\\'s lifetime.\\n\\nOther notes (brief)\\n- Slices (&[T], &str) are borrows of part of a collection; they follow the borrowing rules.\\n- Interior mutability (RefCell, Mutex, Cell) and Rc/Arc allow patterns that relax the default rules but come with runtime checks or concurrency semantics.\\n- The borrow checker enforces memory safety without a garbage collector.\\n\\nConcise takeaway\\nOwnership + the borrow checker enforce single ownership, prevent data races, and ensure references are always valid. Learning the three core ideas—moves vs Copy, immutable vs mutable borrows (one mut or many immutables), and lifetimes—covers most everyday Rust borrowing issues.', 'action': 'answer_direct', 'tool_result': ''}\n",
            "\n",
            "--- Example 2 ---\n",
            "{'answer': 'Summary of the latest approaches to structured reasoning in LLMs (synthesized to 2024‑06)\\n\\nHigh-level framing\\n- “Structured reasoning” here means methods that force or elicit multi-step, decomposed, verifiable, or search-like reasoning from LLMs rather than single-shot answers.\\n- Main strategies: eliciting explicit chains of thought, sampling and aggregating multiple reasoning traces, decomposing tasks, using search over intermediate states, using program execution or tools, and verifying/refining outputs. Many practical systems combine several ideas.\\n\\nKey approaches (what they are, key strengths, limitations, when to use)\\n\\n1) Chain-of-Thought (CoT) prompting and scratchpads\\n- What: Prompt the model to produce step-by-step reasoning (a “chain of thought” or scratchpad) before the final answer.\\n- Strengths: Dramatically improves performance on many multi-step benchmarks; easy to apply via few-shot or instruction prompts.\\n- Limits: Can be verbose and hallucinate; sensitive to prompt design; not guaranteed to be correct even if plausible-sounding.\\n- When to use: Quick wins for math, logic puzzles, multi-hop QA where explanations help; good baseline in most tasks.\\n\\n2) Self-Consistency (sampling multiple chains + voting)\\n- What: Sample many reasoning chains at higher temperature, collect candidate final answers, and select the most frequent (or score-vote) answer.\\n- Strengths: Robustly improves accuracy over a single chain by aggregating diverse reasoning traces.\\n- Limits: Costly (many samples), effectiveness depends on diversity and calibration; can still converge on common but wrong answers.\\n- When to use: When CoT helps but single-output reliability is low and budget allows multiple passes.\\n\\n3) Scratchpad / stepwise internal state (token-level supervision)\\n- What: Encourage models to maintain and use explicit intermediate variables/state across steps (e.g., in-program variables or calculation lines).\\n- Strengths: Makes reasoning trace more structured and verifiable; easier to programmatically parse and verify.\\n- Limits: Requires careful prompt engineering or fine-tuning; not all models maintain faithful internal state.\\n- When to use: Tasks requiring arithmetic precision, intermediate numeric state, or deterministic tracking.\\n\\n4) Tree of Thoughts (ToT) and search over reasoning states\\n- What: Treat reasoning as a search problem over partial “thought” states; expand multiple branches, evaluate them with heuristics or the model, and search (DFS/BFS/beam) for high-value final states.\\n- Strengths: Can solve problems where backtracking or exploring alternatives is necessary; outperforms linear CoT in hard planning/search tasks.\\n- Limits: Computationally expensive; needs good heuristics for pruning/evaluation; implementation complexity higher.\\n- When to use: Hard combinatorial puzzle-solving, creative planning, tasks where exploring alternatives is crucial.\\n\\n5) Program-Aided / Program-as-Intermediate (PAL and program-execution hybrids)\\n- What: Prompt the model to output executable code (python, pseudocode) that implements the reasoning; run the code and return results (optionally re-prompt with errors).\\n- Strengths: Deterministic execution, precise arithmetic, debugging via runtime errors, often higher factual/arithmetical accuracy.\\n- Limits: Requires a safe execution environment; code-generation errors and prompt mapping trade-offs; not all problems are easily coded.\\n- When to use: Math, algorithms, structured data manipulation, and tasks where precise computation is needed.\\n\\n6) Least-to-Most / stepwise decomposition\\n- What: Decompose a complex problem into a sequence of simpler subproblems, solve them in order, and combine answers.\\n- Strengths: Mirrors human decomposition strategies; reduces solution complexity and localizes errors.\\n- Limits: Decomposition quality is critical; can propagate early subproblem errors.\\n- When to use: Multi-part problems, stepwise reasoning tasks, multi-hop QA where intermediate facts can be isolated.\\n\\n7) ReAct (Reasoning + Acting)\\n- What: Interleave reasoning tokens with external actions (calls to tools, APIs, environment interactions), letting the model both think and act.\\n- Strengths: Powerful when external knowledge or computation is required; enables grounded, up-to-date, or tool-backed reasoning.\\n- Limits: Requires reliable tool interfaces and careful action specification; increases system complexity and attack surface.\\n- When to use: Search/email/calendar/code tools, retrieval over knowledge bases, tool-augmented decision-making.\\n\\n8) Verifier / refinement / debate and criticism loops\\n- What: Use separate verifier models, critics, or iterative refinement steps to check, re-score, or improve a candidate solution (including debate-style or self-critique).\\n- Strengths: Catches and corrects errors, filters hallucinations, can use specialized models for verification.\\n- Limits: Verifier can share biases and may not always detect subtle errors; iterative loops add latency/cost.\\n- When to use: High-stakes outputs, fact-checking, when correctness matters more than latency.\\n\\n9) Retrieval- and tool-augmented structured reasoning\\n- What: Combine the LLM’s reasoning traces with retrieved factual sources or external tools (search, databases, calculators) mid-reasoning.\\n- Strengths: Grounds reasoning in evidence, reduces hallucination, allows using up-to-date information.\\n- Limits: Retrieval quality matters; integrating retrieved content into reasoning can be nontrivial.\\n- When to use: Knowledge-heavy reasoning, multi-hop QA requiring facts beyond model context window.\\n\\n10) Neuro-symbolic hybrids and latent program search\\n- What: Combine neural LLM generation with symbolic solvers, SAT/ILP solvers, or program synthesis and verification; sometimes search for latent programs.\\n- Strengths: Offers formal guarantees from symbolic solvers, better correctness for combinatorial tasks.\\n- Limits: Complexity of integration; need mappings between natural-language and formal representations.\\n- When to use: Tasks needing provable properties or combinatorial optimization.\\n\\nComparative guidance and practical tips\\n- Start simple: Use CoT + self-consistency for many multi-step tasks; it’s the lowest-friction improvement.\\n- Use PAL / program execution when you need arithmetic precision or deterministic steps. Keep execution sandboxed and log outputs.\\n- Use Tree of Thoughts when problems require searching over alternatives/backtracking or creative planning; combine ToT with value heuristics (learned or model-based).\\n- Combine methods: e.g., use CoT to produce decomposition, generate candidate programs (PAL) to execute subproblems, and then verify outputs with a separate verifier or retrieval.\\n- Sampling & temperature: Higher temperature (0.7–1.2) increases diversity for self-consistency/ToT exploration; use more samples for majority-vote aggregation. Lower temperature for deterministic code generation or final answer consolidation.\\n- Verification: Always validate critical arithmetic/proofs by executing or re-checking steps (e.g., rerun arithmetic in a calculator tool). Use a verifier model with different seeds or a specialist small model to reduce correlated errors.\\n- Budgeting: Search-based strategies (ToT, large self-consistency runs) are costly—trade off number of branches/samples vs. depth/resolution of search.\\n- Prompt engineering: Provide clear decomposition templates, variable naming, and explicit instructions to “show your work.” For program approaches, give a short skeleton and I/O examples.\\n- Safety and alignment: Be cautious with tool-enabled agents—restrict tool capabilities and sanitize outputs.\\n\\nEvaluation and research gaps\\n- Benchmarks: Newer benchmarks emphasize multi-step reasoning, planning, and compositional tasks; evaluate both outcome accuracy and fidelity of intermediate steps.\\n- Open problems: Guaranteeing correctness, scalable search/pruning methods, robust verifiers that aren’t easily fooled, grounding/hallucination reduction, and evaluation metrics for reasoning traces.\\n- Future directions: Learned heuristics for ToT pruning, combining retrieval with explicit program synthesis, modular verifiers, and joint training to better align chains-of-thought with verifiable reasoning.\\n\\nShort practical recipe (starter configurations)\\n- Low-cost / exploratory: CoT few-shot prompts + 10–20 samples + majority vote (self-consistency).\\n- Precision / computation: Prompt for code (PAL), run in sandboxed interpreter, return verified output.\\n- Hard search problems: Tree of Thoughts with shallow beam/DFS, evaluate branches with a scoring prompt, prune aggressively.\\n- Knowledge-grounded: Retrieval-augmented CoT + verifier to cross-check sources.\\n\\nIf you want, I can:\\n- Draft a set of prompt templates for CoT, PAL, ToT, and verifier loops.\\n- Show an example pipeline combining CoT -> PAL execution -> verifier + retrieval for a sample problem.\\n- Provide references and key papers (I attempted web searches but they failed; I can fetch exact citations if you’d like me to try again).', 'action': 'think_tool', 'tool_result': 'Reflection recorded: openai_search failed repeatedly. Proceed using internal knowledge (cutoff 2024-06). Plan: produce a concise, structured summary covering: chain-of-thought (CoT) prompting and variants (self-consistency, scratchpad), Tree of Thoughts, program-aided approaches (PAL), least-to-most decomposition, ReAct (reasoning + acting), verifier/refinement and iterative re-ranking, retrieval- and tool-augmented structured reasoning, and neuro-symbolic or program-execution hybrids. For each: describe the idea, key strengths, limitations, and practical guidance on when to use. Conclude with recommended combinations and implementation tips (temperature, sampling, verification, tool use).'}\n"
          ]
        }
      ],
      "source": [
        "# Examples / smoke tests (ReAct)\n",
        "\n",
        "print(\"\\n--- Example 1 ---\")\n",
        "resp = run_deep_research(\"Give me a concise overview of Rust ownership vs borrow checker with examples.\")\n",
        "print(resp)\n",
        "\n",
        "print(\"\\n--- Example 2 ---\")\n",
        "resp2 = run_deep_research(\"Summarize the latest approaches to structured reasoning in LLMs.\")\n",
        "print(resp2)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
