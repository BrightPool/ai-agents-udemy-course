{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: restart the kernel if packages were freshly installed.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once per environment)\n",
        "%pip install -q dspy python-dotenv google-genai fal-client pillow ffmpeg-python\n",
        "print(\"Note: restart the kernel if packages were freshly installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy configured (Gemini) for Video Generation agent.\n"
          ]
        }
      ],
      "source": [
        "# Basic imports and environment setup\n",
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from dspy import History, Image\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Configure LM (Gemini recommended for images/video tool use)\n",
        "lm = dspy.LM(\"gemini/gemini-2.0-flash\", api_key=os.getenv(\"GOOGLE_API_KEY\"), temperature=0.6, max_tokens=16000)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"DSPy configured (Gemini) for Video Generation agent.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DSPy Video BaseType (for Gemini video inputs)\n",
        "import base64\n",
        "import mimetypes\n",
        "import os\n",
        "from typing import Any, Union\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import requests\n",
        "from dspy.adapters.types.base_type import Type\n",
        "\n",
        "\n",
        "class Video(Type):\n",
        "    url: str\n",
        "\n",
        "    model_config = {\n",
        "        \"frozen\": True,\n",
        "        \"str_strip_whitespace\": True,\n",
        "        \"validate_assignment\": True,\n",
        "        \"extra\": \"forbid\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, url_or_dict=None, **kwargs):\n",
        "        if url_or_dict is None and \"url\" in kwargs:\n",
        "            super().__init__(**kwargs)\n",
        "        elif isinstance(url_or_dict, str):\n",
        "            super().__init__(url=url_or_dict)\n",
        "        elif isinstance(url_or_dict, dict):\n",
        "            super().__init__(**url_or_dict)\n",
        "        elif url_or_dict is None:\n",
        "            super().__init__(**kwargs)\n",
        "        else:\n",
        "            raise TypeError(\"Expected a string URL or a dictionary with a key 'url'.\")\n",
        "\n",
        "    def format(self) -> list[dict[str, Any]] | str:\n",
        "        import dspy\n",
        "        current_lm = dspy.settings.lm\n",
        "        if current_lm and hasattr(current_lm, 'model'):\n",
        "            model_name = current_lm.model.lower()\n",
        "            if 'gemini' not in model_name and 'vertex' not in model_name:\n",
        "                raise ValueError(\n",
        "                    f\"Video input is supported only on Gemini models. Current model: {current_lm.model}.\"\n",
        "                )\n",
        "        try:\n",
        "            if self.url.startswith(\"http\"):\n",
        "                video_url = encode_video(self.url, download_videos=False)\n",
        "            else:\n",
        "                video_url = encode_video(self.url)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to format video for DSPy: {e}\")\n",
        "        return [{\"type\": \"image_url\", \"image_url\": {\"url\": video_url}}]\n",
        "\n",
        "    @classmethod\n",
        "    def from_url(cls, url: str, download: bool = False):\n",
        "        return cls(url=encode_video(url, download=download))\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, file_path: str):\n",
        "        abs_path = os.path.abspath(file_path)\n",
        "        return cls(url=encode_video(abs_path))\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.serialize_model()\n",
        "\n",
        "    def __repr__(self):\n",
        "        if \"base64\" in self.url:\n",
        "            len_base64 = len(self.url.split(\"base64,\")[1])\n",
        "            video_type = self.url.split(\";\")[0].split(\"/\")[-1]\n",
        "            return f\"Video(url=data:video/{video_type};base64,<VIDEO_BASE_64_ENCODED({len_base64!s})>)\"\n",
        "        return f\"Video(url='{self.url}')\"\n",
        "\n",
        "\n",
        "def is_url(string: str) -> bool:\n",
        "    try:\n",
        "        result = urlparse(string)\n",
        "        return all([result.scheme in (\"http\", \"https\", \"gs\"), result.netloc])\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def encode_video(video: Union[str, bytes, dict], download_videos: bool = False) -> str:\n",
        "    if isinstance(video, dict) and \"url\" in video:\n",
        "        return video[\"url\"]\n",
        "    elif isinstance(video, str):\n",
        "        if video.startswith(\"data:\"):\n",
        "            return video\n",
        "        elif os.path.isfile(video):\n",
        "            return _encode_video_from_file(video)\n",
        "        elif is_url(video):\n",
        "            if download_videos:\n",
        "                return _encode_video_from_url(video)\n",
        "            else:\n",
        "                return video\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported video string: {video}\")\n",
        "    elif isinstance(video, bytes):\n",
        "        raise ValueError(\"Direct byte encoding for videos is not supported. Provide a file path or URL.\")\n",
        "    elif isinstance(video, Video):\n",
        "        return video.url\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported video type: {type(video)}\")\n",
        "\n",
        "\n",
        "def _encode_video_from_file(file_path: str) -> str:\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Video file not found: {file_path}\")\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise ValueError(f\"Path is not a file: {file_path}\")\n",
        "    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "    if file_size_mb > 2000:\n",
        "        raise ValueError(f\"Video file size ({file_size_mb:.1f}MB) exceeds Gemini's 2GB limit\")\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        file_data = file.read()\n",
        "    mime_type, _ = mimetypes.guess_type(file_path)\n",
        "    if mime_type is None:\n",
        "        mime_type = \"video/mp4\"\n",
        "    if not mime_type.startswith(\"video/\"):\n",
        "        raise ValueError(f\"File does not appear to be a video. MIME type: {mime_type}\")\n",
        "    encoded_data = base64.b64encode(file_data).decode(\"utf-8\")\n",
        "    return f\"data:{mime_type};base64,{encoded_data}\"\n",
        "\n",
        "\n",
        "def _encode_video_from_url(video_url: str) -> str:\n",
        "    response = requests.get(video_url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    content_length = response.headers.get('Content-Length')\n",
        "    if content_length:\n",
        "        size_mb = int(content_length) / (1024 * 1024)\n",
        "        if size_mb > 2000:\n",
        "            raise ValueError(f\"Video file size ({size_mb:.1f}MB) exceeds Gemini's 2GB limit\")\n",
        "    content_type = response.headers.get(\"Content-Type\", \"\")\n",
        "    if content_type:\n",
        "        mime_type = content_type\n",
        "    else:\n",
        "        mime_type, _ = mimetypes.guess_type(video_url)\n",
        "        if mime_type is None:\n",
        "            mime_type = \"video/mp4\"\n",
        "    if not mime_type.startswith(\"video/\"):\n",
        "        raise ValueError(f\"URL does not appear to point to a video. MIME type: {mime_type}\")\n",
        "    content_chunks = []\n",
        "    total_size = 0\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "        content_chunks.append(chunk)\n",
        "        total_size += len(chunk)\n",
        "        if total_size > 2000 * 1024 * 1024:\n",
        "            raise ValueError(\"Video file size exceeds Gemini's 2GB limit\")\n",
        "    content = b''.join(content_chunks)\n",
        "    encoded_data = base64.b64encode(content).decode(\"utf-8\")\n",
        "    return f\"data:{mime_type};base64,{encoded_data}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tools and utilities (plain Python functions)\n",
        "import re\n",
        "import shlex\n",
        "import shutil\n",
        "import subprocess\n",
        "from typing import Any, Dict, List, Optional\n",
        "from io import BytesIO\n",
        "\n",
        "import ffmpeg  # type: ignore\n",
        "from PIL import Image\n",
        "\n",
        "# Helper: temp directories\n",
        "\n",
        "def initialize_tmp_directories() -> None:\n",
        "    directories = [\n",
        "        \"/tmp/assets\",\n",
        "        \"/tmp/audio\",\n",
        "        \"/tmp/unsplash\",\n",
        "        \"/tmp/subtitles\",\n",
        "        \"/tmp/videos\",\n",
        "        \"/tmp/images\",\n",
        "    ]\n",
        "    for d in directories:\n",
        "        os.makedirs(d, exist_ok=True)\n",
        "\n",
        "\n",
        "def _safe_remove_path(path: str) -> tuple[bool, Optional[str]]:\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            return True, None\n",
        "        if os.path.isdir(path) and not os.path.islink(path):\n",
        "            shutil.rmtree(path, ignore_errors=False)\n",
        "        else:\n",
        "            os.remove(path)\n",
        "        return True, None\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "\n",
        "def cleanup_tmp_directories(preserve_paths: Optional[List[str]] = None) -> Dict[str, Any]:\n",
        "    preserved = set(preserve_paths or [])\n",
        "    target_directories = [\n",
        "        \"/tmp/unsplash\",\n",
        "        \"/tmp/unsplash_photos\",\n",
        "        \"/tmp/audio\",\n",
        "        \"/tmp/subtitles\",\n",
        "        \"/tmp/videos\",\n",
        "        \"/tmp/images\",\n",
        "    ]\n",
        "    removed: List[str] = []\n",
        "    errors: List[str] = []\n",
        "    processed: List[str] = []\n",
        "\n",
        "    for directory in target_directories:\n",
        "        if not os.path.isdir(directory):\n",
        "            continue\n",
        "        processed.append(directory)\n",
        "        try:\n",
        "            for name in os.listdir(directory):\n",
        "                candidate = os.path.join(directory, name)\n",
        "                if candidate in preserved:\n",
        "                    continue\n",
        "                ok, err = _safe_remove_path(candidate)\n",
        "                if ok:\n",
        "                    removed.append(candidate)\n",
        "                elif err:\n",
        "                    errors.append(f\"{candidate}: {err}\")\n",
        "        except Exception as e:\n",
        "            errors.append(f\"{directory}: {e}\")\n",
        "        try:\n",
        "            if directory != \"/tmp/videos\" and not os.listdir(directory):\n",
        "                os.rmdir(directory)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return {\n",
        "        \"removed_files\": removed,\n",
        "        \"errors\": errors,\n",
        "        \"preserved\": sorted(list(preserved)),\n",
        "        \"directories_processed\": processed,\n",
        "    }\n",
        "\n",
        "\n",
        "# Tool: create_story_board\n",
        "\n",
        "def create_story_board(\n",
        "    product_name: str,\n",
        "    brand: str,\n",
        "    target_audience: str,\n",
        "    key_message: str,\n",
        "    tone: str,\n",
        "    scenes_count: int = 3,\n",
        "    default_scene_duration_seconds: float = 6.0,\n",
        ") -> str:\n",
        "    \"\"\"Create a simple 3-scene storyboard (beginning, middle, end).\n",
        "\n",
        "    Returns JSON string with a `scenes` array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        initialize_tmp_directories()\n",
        "        scene_names = [\"beginning\", \"middle\", \"end\"]\n",
        "        scenes: List[Dict[str, Any]] = []\n",
        "        for idx, sid in enumerate(scene_names[: max(1, min(10, int(scenes_count))) ]):\n",
        "            title = sid.capitalize()\n",
        "            desc = (\n",
        "                f\"{brand} {product_name} ad for {target_audience}. {sid} of story, tone: {tone}. \"\n",
        "                f\"Key message: {key_message}. Visual focus: product + person.\"\n",
        "            )\n",
        "            prompt = (\n",
        "                f\"Photorealistic {product_name} with a person interacting, cinematic lighting, \"\n",
        "                f\"brand aesthetic for {brand}, clean composition, ad-ready. Scene: {sid}.\"\n",
        "            )\n",
        "            scenes.append(\n",
        "                {\n",
        "                    \"id\": sid,\n",
        "                    \"title\": title,\n",
        "                    \"description\": desc,\n",
        "                    \"prompt\": prompt,\n",
        "                    \"duration_seconds\": float(max(1.0, min(60.0, default_scene_duration_seconds))),\n",
        "                }\n",
        "            )\n",
        "        return json.dumps({\"scenes\": scenes}, ensure_ascii=False)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"scenes\": [], \"error\": f\"create_story_board failed: {e}\"})\n",
        "\n",
        "\n",
        "# Tool: update_story_board\n",
        "\n",
        "def update_story_board(storyboard_json: str, instructions: str) -> str:\n",
        "    \"\"\"Apply lightweight edits (e.g., `duration=8`). Accepts and returns JSON string.\"\"\"\n",
        "    try:\n",
        "        data = json.loads(storyboard_json) if isinstance(storyboard_json, str) else storyboard_json\n",
        "        scenes = data.get(\"scenes\", []) if isinstance(data, dict) else []\n",
        "        m = re.search(r\"duration\\s*=\\s*(\\d+(?:\\.\\d+)?)\", instructions.lower())\n",
        "        if m:\n",
        "            new_dur = float(m.group(1))\n",
        "            for sc in scenes:\n",
        "                if isinstance(sc, dict):\n",
        "                    sc[\"duration_seconds\"] = float(max(1.0, min(60.0, new_dur)))\n",
        "        return json.dumps({\"scenes\": scenes}, ensure_ascii=False)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"update_story_board failed: {e}\", \"scenes\": []})\n",
        "\n",
        "\n",
        "# Tool: generate_image via Google Gemini Images\n",
        "\n",
        "def _extract_text_from_genai(resp: Any) -> str:\n",
        "    # Best-effort extraction of text from google-genai response without touching resp.text\n",
        "    # to avoid warnings about non-text parts (e.g., inline_data, function_calls).\n",
        "    try:\n",
        "        # Prefer structured candidates → parts → text\n",
        "        cands = getattr(resp, \"candidates\", None) or []\n",
        "        for c in cands:\n",
        "            content = getattr(c, \"content\", None)\n",
        "            parts = getattr(content, \"parts\", None) or []\n",
        "            for p in parts:\n",
        "                txt = getattr(p, \"text\", None)\n",
        "                if isinstance(txt, str) and txt.strip():\n",
        "                    return txt\n",
        "        # Fallback: check top-level candidates' aggregated text if present\n",
        "        agg_text = getattr(resp, \"text\", None)\n",
        "        if isinstance(agg_text, str):\n",
        "            return agg_text\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def generate_image(prompt: str, num_images: int = 1, output_basename: str = \"product_ad_image\") -> str:\n",
        "    \"\"\"Generate one or more images using Google Gemini and save PNG files under /tmp/images.\n",
        "\n",
        "    Returns JSON: {\"images\": [paths...], \"error\"?: str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google import genai  # lazy import\n",
        "        api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
        "        if not api_key:\n",
        "            return json.dumps({\"images\": [], \"error\": \"GOOGLE_API_KEY not set\"})\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-image-preview\",\n",
        "            contents=[prompt],\n",
        "        )\n",
        "        os.makedirs(\"/tmp/images\", exist_ok=True)\n",
        "        saved: List[str] = []\n",
        "        idx = 0\n",
        "        # Extract images from interleaved parts\n",
        "        try:\n",
        "            cands = getattr(resp, \"candidates\", None) or []\n",
        "            for c in cands:\n",
        "                content = getattr(c, \"content\", None)\n",
        "                parts = getattr(content, \"parts\", None) or []\n",
        "                for part in parts:\n",
        "                    inline_data = getattr(part, \"inline_data\", None)\n",
        "                    if inline_data is None:\n",
        "                        continue\n",
        "                    data = getattr(inline_data, \"data\", None)\n",
        "                    if not isinstance(data, (bytes, bytearray, memoryview)):\n",
        "                        continue\n",
        "                    try:\n",
        "                        image = Image.open(BytesIO(bytes(data)))\n",
        "                        out_path = f\"/tmp/images/{output_basename}_{idx}.png\"\n",
        "                        image.save(out_path)\n",
        "                        saved.append(out_path)\n",
        "                        idx += 1\n",
        "                        if len(saved) >= max(1, min(4, int(num_images))):\n",
        "                            break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if len(saved) >= max(1, min(4, int(num_images))):\n",
        "                    break\n",
        "        except Exception:\n",
        "            pass\n",
        "        if not saved:\n",
        "            # Try to pull any text error\n",
        "            txt = _extract_text_from_genai(resp)\n",
        "            return json.dumps({\"images\": [], \"error\": txt or \"No images in response\"})\n",
        "        return json.dumps({\"images\": saved})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"images\": [], \"error\": f\"generate_image error: {e}\"})\n",
        "\n",
        "\n",
        "# Tool: kling video from image via fal.ai\n",
        "\n",
        "def kling_generate_video_from_image(\n",
        "    prompt: str,\n",
        "    image_path: str = \"\",\n",
        "    image_url: str = \"\",\n",
        "    duration_seconds: float = 6.0,\n",
        "    endpoint: str = \"kwaivgi/kling-v2.1-master\",\n",
        "    seed: Optional[int] = None,\n",
        ") -> str:\n",
        "    \"\"\"Generate short video (<=10s typical) from image via fal.ai Kling endpoint.\n",
        "\n",
        "    Returns JSON with keys: request_id?, video_url?, logs?\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import fal_client  # type: ignore\n",
        "        # configure key from env if present\n",
        "        fal_api_key = os.getenv(\"FAL_KEY\") or os.getenv(\"FAL_API_KEY\")\n",
        "        if fal_api_key:\n",
        "            os.environ.setdefault(\"FAL_KEY\", fal_api_key)\n",
        "\n",
        "        # prefer env override for endpoint\n",
        "        endpoint_to_use = os.getenv(\"KLING_FAL_ENDPOINT\", endpoint)\n",
        "\n",
        "        # upload image if local path provided\n",
        "        start_image_url = None\n",
        "        if image_path and os.path.exists(image_path):\n",
        "            try:\n",
        "                start_image_url = fal_client.upload_file(image_path)\n",
        "            except Exception:\n",
        "                start_image_url = None\n",
        "        if not start_image_url and image_url:\n",
        "            start_image_url = image_url\n",
        "\n",
        "        arguments: Dict[str, Any] = {\n",
        "            \"prompt\": prompt,\n",
        "            \"duration\": float(duration_seconds),\n",
        "        }\n",
        "        if start_image_url:\n",
        "            # Common arg name on this fal app\n",
        "            arguments[\"start_image\"] = start_image_url\n",
        "        if seed is not None:\n",
        "            arguments[\"seed\"] = int(seed)\n",
        "\n",
        "        # Synchronous run is simpler and reliable for this endpoint\n",
        "        result = fal_client.run(endpoint_to_use, arguments=arguments)\n",
        "\n",
        "        # Normalize output URL\n",
        "        video_url = None\n",
        "        try:\n",
        "            if isinstance(result, dict):\n",
        "                video_url = (\n",
        "                    result.get(\"video\")\n",
        "                    or result.get(\"url\")\n",
        "                    or result.get(\"output\")\n",
        "                    or result.get(\"video_url\")\n",
        "                    or result.get(\"output_url\")\n",
        "                )\n",
        "        except Exception:\n",
        "            video_url = None\n",
        "\n",
        "        out = {\n",
        "            \"request_id\": getattr(result, \"request_id\", None) if result else None,\n",
        "            \"video_url\": video_url,\n",
        "            \"logs\": None,\n",
        "        }\n",
        "        return json.dumps(out)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"video_url\": None, \"logs\": [f\"error: {e}\"]})\n",
        "\n",
        "\n",
        "# Tool: run ffmpeg binary\n",
        "\n",
        "def run_ffmpeg_binary(command: str, output_path: str = \"\", timeout_seconds: int = 180) -> str:\n",
        "    \"\"\"Execute ffmpeg command safely. Returns JSON summary including stdout/stderr tails.\"\"\"\n",
        "    try:\n",
        "        if not isinstance(command, str) or not command.strip():\n",
        "            return json.dumps({\"error\": \"Command must be a non-empty string\"})\n",
        "        if not shutil.which(\"ffmpeg\"):\n",
        "            return json.dumps({\"error\": \"ffmpeg not found on PATH. Please install ffmpeg.\"})\n",
        "        if output_path:\n",
        "            out_dir = os.path.dirname(output_path) or \".\"\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        planned = command.strip()\n",
        "        if not planned.lower().startswith(\"ffmpeg\"):\n",
        "            planned = f\"ffmpeg {planned}\"\n",
        "        if \" -y \" not in f\" {planned} \":\n",
        "            parts = planned.split()\n",
        "            if parts and parts[0].lower() == \"ffmpeg\":\n",
        "                parts.insert(1, \"-y\")\n",
        "                planned = \" \".join(parts)\n",
        "        try:\n",
        "            cmd_list = shlex.split(planned)\n",
        "        except Exception as e:\n",
        "            return json.dumps({\"error\": f\"Invalid command: {e}\", \"ffmpeg_command\": planned})\n",
        "\n",
        "        try:\n",
        "            completed = subprocess.run(\n",
        "                cmd_list,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False,\n",
        "                timeout=max(10, int(timeout_seconds)),\n",
        "            )\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return json.dumps({\"error\": f\"FFmpeg timed out after {timeout_seconds}s\", \"ffmpeg_command\": planned})\n",
        "        except OSError as e:\n",
        "            return json.dumps({\"error\": f\"Failed to run ffmpeg: {e}\", \"ffmpeg_command\": planned})\n",
        "\n",
        "        stdout_tail = (completed.stdout or \"\")[-2000:]\n",
        "        stderr_tail = (completed.stderr or \"\")[-4000:]\n",
        "\n",
        "        if completed.returncode != 0:\n",
        "            return json.dumps({\n",
        "                \"error\": f\"FFmpeg failed with code {completed.returncode}: {stderr_tail[-800:]}\",\n",
        "                \"ffmpeg_command\": planned,\n",
        "                \"stdout_tail\": stdout_tail,\n",
        "                \"stderr_tail\": stderr_tail,\n",
        "                \"output_path\": output_path,\n",
        "            })\n",
        "\n",
        "        return json.dumps({\n",
        "            \"output_path\": output_path,\n",
        "            \"ffmpeg_command\": planned,\n",
        "            \"stdout_tail\": stdout_tail,\n",
        "            \"stderr_tail\": stderr_tail,\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"run_ffmpeg_binary error: {e}\"})\n",
        "\n",
        "\n",
        "# Tool: score video with metadata + LLM rubric\n",
        "\n",
        "def score_video(video_path: str, target_quality_score: Optional[float] = None) -> str:\n",
        "    \"\"\"Score a video using ffmpeg metadata and a Gemini text rubric. Returns JSON.\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(video_path):\n",
        "            return json.dumps({\"error\": f\"Video not found: {video_path}\"})\n",
        "        meta: Dict[str, Any] = {}\n",
        "        try:\n",
        "            probe = ffmpeg.probe(video_path)  # type: ignore\n",
        "            streams = probe.get(\"streams\", [])\n",
        "            vstreams = [s for s in streams if s.get(\"codec_type\") == \"video\"]\n",
        "            astreams = [s for s in streams if s.get(\"codec_type\") == \"audio\"]\n",
        "            fmt = probe.get(\"format\", {})\n",
        "            if vstreams:\n",
        "                v0 = vstreams[0]\n",
        "                meta[\"width\"] = v0.get(\"width\")\n",
        "                meta[\"height\"] = v0.get(\"height\")\n",
        "                meta[\"avg_frame_rate\"] = v0.get(\"avg_frame_rate\")\n",
        "            if astreams:\n",
        "                a0 = astreams[0]\n",
        "                meta[\"audio_channels\"] = a0.get(\"channels\")\n",
        "            meta[\"duration\"] = fmt.get(\"duration\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
        "        if not api_key:\n",
        "            return json.dumps({\"error\": \"GOOGLE_API_KEY not set for scoring\"})\n",
        "\n",
        "        from google import genai\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        target = (f\"Target quality score: {float(target_quality_score)}\" if target_quality_score is not None else \"\")\n",
        "        prompt = (\n",
        "            \"You are a strict video quality evaluator. Return ONLY a JSON object with keys \"\n",
        "            \"visual_quality (0-10 int), audio_quality (0-10 int), narrative_coherence (0-10 int), feedback (string).\\n\" \\\n",
        "            + f\"Video Path: {video_path}\\nMetadata: {json.dumps(meta)}\\n{target}\\n\"\n",
        "        )\n",
        "        resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=[prompt])\n",
        "        content_text = _extract_text_from_genai(resp)\n",
        "        # Best-effort JSON extraction\n",
        "        try:\n",
        "            start = content_text.find(\"{\")\n",
        "            end = content_text.rfind(\"}\")\n",
        "            payload = content_text[start : end + 1] if start != -1 and end != -1 else content_text\n",
        "            data = json.loads(payload)\n",
        "        except Exception:\n",
        "            return json.dumps({\"error\": \"Failed to parse JSON from model\", \"raw\": content_text})\n",
        "\n",
        "        def _clamp_int(x: Any) -> int:\n",
        "            try:\n",
        "                return max(0, min(10, int(x)))\n",
        "            except Exception:\n",
        "                return 0\n",
        "\n",
        "        v = _clamp_int(data.get(\"visual_quality\"))\n",
        "        a = _clamp_int(data.get(\"audio_quality\"))\n",
        "        n = _clamp_int(data.get(\"narrative_coherence\"))\n",
        "        score = round((v + a + n) / 3.0, 2)\n",
        "        out = {\n",
        "            \"quality_score\": score,\n",
        "            \"breakdown\": {\"visual_quality\": v, \"audio_quality\": a, \"narrative_coherence\": n},\n",
        "            \"feedback\": data.get(\"feedback\", \"\"),\n",
        "        }\n",
        "        return json.dumps(out)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"scoring failed: {e}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VideoGenerationAgent ready.\n"
          ]
        }
      ],
      "source": [
        "# ReAct Signature and Agent\n",
        "\n",
        "class VideoReActSignature(dspy.Signature):\n",
        "    \"\"\"\n",
        "    You are a product advertisement creative agent.\n",
        "    Tools:\n",
        "    - create_story_board(product_name, brand, target_audience, key_message, tone, scenes_count=3, default_scene_duration_seconds=6.0)\n",
        "    - update_story_board(storyboard_json, instructions)\n",
        "    - generate_image(prompt, num_images=1, output_basename=\"product_ad_image\")\n",
        "    - kling_generate_video_from_image(prompt, image_path=\"\", image_url=\"\", duration_seconds=6.0, endpoint=\"fal-ai/kling/v1\", seed=None)\n",
        "    - run_ffmpeg_binary(command, output_path=\"\", timeout_seconds=180)\n",
        "    - score_video(video_path, target_quality_score=None)\n",
        "\n",
        "    Workflow: Create storyboard → update storyboard (if needed) → generate image → generate video → (optional) ffmpeg postprocess → score video.\n",
        "    Kling videos are limited to ~10 seconds; for longer videos, generate multiple clips and stitch with ffmpeg.\n",
        "\n",
        "    Produce outputs:\n",
        "    - `action`: one of {create_story_board, update_story_board, generate_image, kling_generate_video_from_image, run_ffmpeg_binary, score_video, answer_direct}\n",
        "    - `tool_result`: JSON string from the tool call (may be empty for answer_direct)\n",
        "    - `answer`: concise user-facing update or the final summary\n",
        "    \"\"\"\n",
        "    user_message: str = dspy.InputField(description=\"User request for the advertisement video\")\n",
        "    history: dspy.History = dspy.InputField(description=\"Conversation history\")\n",
        "\n",
        "    reasoning: str = dspy.OutputField(description=\"Brief plan and justification\")\n",
        "    action: str = dspy.OutputField(description=\"Chosen action/tool\")\n",
        "    tool_result: str = dspy.OutputField(description=\"Tool output used to answer\")\n",
        "    answer: str = dspy.OutputField(description=\"Final answer or progress update\")\n",
        "\n",
        "\n",
        "class VideoGenerationAgent(dspy.Module):\n",
        "    def __init__(self, max_iters: int = 5):\n",
        "        super().__init__()\n",
        "        self.conversation_history = dspy.History(messages=[])\n",
        "        self.react = dspy.ReAct(\n",
        "            VideoReActSignature,\n",
        "            tools=[\n",
        "                create_story_board,\n",
        "                update_story_board,\n",
        "                generate_image,\n",
        "                kling_generate_video_from_image,\n",
        "                run_ffmpeg_binary,\n",
        "                score_video,\n",
        "            ],\n",
        "            max_iters=max_iters,\n",
        "        )\n",
        "\n",
        "    def forward(self, user_message: str):\n",
        "        initialize_tmp_directories()\n",
        "        self.conversation_history.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        result = self.react(user_message=user_message, history=self.conversation_history)\n",
        "        answer = getattr(result, \"answer\", \"\")\n",
        "        if isinstance(answer, str) and answer.strip():\n",
        "            self.conversation_history.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "        return result\n",
        "\n",
        "\n",
        "agent = VideoGenerationAgent(max_iters=5)\n",
        "print(\"VideoGenerationAgent ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': 'answer_direct', 'answer': 'I have created the storyboard and generated an image for the first scene. However, I am encountering issues with the video generation tool. I will provide the storyboard and the generated image as a progress update. I will look into the video generation issue and try again.'}\n"
          ]
        }
      ],
      "source": [
        "# Example usage / smoke tests\n",
        "\n",
        "# 1) Create storyboard\n",
        "payload = {\n",
        "    \"product_name\": \"EcoBottle\",\n",
        "    \"brand\": \"GreenLife\",\n",
        "    \"target_audience\": \"health-conscious young adults\",\n",
        "    \"key_message\": \"Reusable, stylish, and sustainable\",\n",
        "    \"tone\": \"inspiring\",\n",
        "}\n",
        "resp = agent(user_message=(\n",
        "    \"Create a 3-scene product ad storyboard for EcoBottle by GreenLife aimed at \"\n",
        "    \"health-conscious young adults with an inspiring tone; key message: Reusable, stylish, sustainable.\"\n",
        "))\n",
        "print({\n",
        "    \"action\": getattr(resp, \"action\", \"\"),\n",
        "    \"answer\": getattr(resp, \"answer\", \"\"),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storyboard: {\"scenes\": [{\"id\": \"beginning\", \"title\": \"Beginning\", \"description\": \"GreenLife EcoBottle ad for health-conscious young  ...\n",
            "Image result: {\"images\": [\"/tmp/images/product_ad_image_0.png\"]}\n"
          ]
        }
      ],
      "source": [
        "# 2) (Optional) Generate image for the first scene — direct tool call for demo\n",
        "storyboard = create_story_board(**payload)\n",
        "print(\"Storyboard:\", storyboard[:120], \"...\")\n",
        "\n",
        "img_result = generate_image(\n",
        "    prompt=\"Photorealistic water bottle with person at gym, cinematic lighting, brand aesthetic\", num_images=1\n",
        ")\n",
        "print(\"Image result:\", img_result)\n",
        "\n",
        "# Show image to the model via DSPy Image primitive (first image if any)\n",
        "try:\n",
        "    img_paths = json.loads(img_result).get(\"images\", [])\n",
        "    if img_paths:\n",
        "        _ = Image.from_url(img_paths[0])\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kling result: {\"video_url\": null, \"logs\": [\"error: User 'kwaivgi' not found\"]}\n"
          ]
        }
      ],
      "source": [
        "# 3) (Optional) Attempt Kling video generation (requires FAL_KEY/FAL_API_KEY)\n",
        "vid_result = kling_generate_video_from_image(\n",
        "    prompt=\"Dynamic pan of athlete lifting EcoBottle, energetic mood\",\n",
        "    image_path=img_paths[0] if 'img_paths' in locals() and img_paths else \"\",\n",
        "    image_url=\"\",\n",
        "    duration_seconds=6.0,\n",
        ")\n",
        "print(\"Kling result:\", vid_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scoring example video...\n",
            "{\"quality_score\": 0.0, \"breakdown\": {\"visual_quality\": 0, \"audio_quality\": 0, \"narrative_coherence\": 0}, \"feedback\": \"Evaluation is impossible without access to the actual video content. The provided metadata (1920x1080 resolution, 60fps, 10-second duration) indicates a standard high-definition source, which is technically adequate. However, specific visual fidelity, audio integrity, and narrative coherence cannot be assessed from metadata alone. The assigned scores reflect the inability to perform a proper content-based quality evaluation due to the absence of the video itself.\"}\n"
          ]
        }
      ],
      "source": [
        "# 4) (Optional) If a local video is available, score it\n",
        "# Example: score a sample video if present\n",
        "sample_path = \"example_video.mp4\"\n",
        "if os.path.exists(sample_path):\n",
        "    print(\"Scoring example video...\")\n",
        "    print(score_video(sample_path))\n",
        "else:\n",
        "    print(\"No local sample video found to score.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
