{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: restart the kernel if packages were freshly installed.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once per environment)\n",
        "%pip install -q dspy python-dotenv google-genai fal-client pillow ffmpeg-python\n",
        "print(\"Note: restart the kernel if packages were freshly installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy configured for Video Generation agent.\n"
          ]
        }
      ],
      "source": [
        "# Basic imports and environment setup\n",
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from dspy import History\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Configure LM (Google Gemini to mirror LangGraph usage; adjust if needed)\n",
        "lm = dspy.LM(\"openai/gpt-5-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1, max_tokens=16000)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"DSPy configured for Video Generation agent.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tools and utilities (ported from LangGraph as plain Python functions)\n",
        "import re\n",
        "import shlex\n",
        "import shutil\n",
        "import subprocess\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import ffmpeg  # type: ignore\n",
        "from PIL import Image\n",
        "\n",
        "# Helper: temp directories\n",
        "\n",
        "def initialize_tmp_directories() -> None:\n",
        "    directories = [\n",
        "        \"/tmp/assets\",\n",
        "        \"/tmp/audio\",\n",
        "        \"/tmp/unsplash\",\n",
        "        \"/tmp/subtitles\",\n",
        "        \"/tmp/videos\",\n",
        "        \"/tmp/images\",\n",
        "    ]\n",
        "    for d in directories:\n",
        "        os.makedirs(d, exist_ok=True)\n",
        "\n",
        "\n",
        "def _safe_remove_path(path: str) -> tuple[bool, Optional[str]]:\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            return True, None\n",
        "        if os.path.isdir(path) and not os.path.islink(path):\n",
        "            shutil.rmtree(path, ignore_errors=False)\n",
        "        else:\n",
        "            os.remove(path)\n",
        "        return True, None\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "\n",
        "def cleanup_tmp_directories(preserve_paths: Optional[List[str]] = None) -> Dict[str, Any]:\n",
        "    preserved = set(preserve_paths or [])\n",
        "    target_directories = [\n",
        "        \"/tmp/unsplash\",\n",
        "        \"/tmp/unsplash_photos\",\n",
        "        \"/tmp/audio\",\n",
        "        \"/tmp/subtitles\",\n",
        "        \"/tmp/videos\",\n",
        "        \"/tmp/images\",\n",
        "    ]\n",
        "    removed: List[str] = []\n",
        "    errors: List[str] = []\n",
        "    processed: List[str] = []\n",
        "\n",
        "    for directory in target_directories:\n",
        "        if not os.path.isdir(directory):\n",
        "            continue\n",
        "        processed.append(directory)\n",
        "        try:\n",
        "            for name in os.listdir(directory):\n",
        "                candidate = os.path.join(directory, name)\n",
        "                if candidate in preserved:\n",
        "                    continue\n",
        "                ok, err = _safe_remove_path(candidate)\n",
        "                if ok:\n",
        "                    removed.append(candidate)\n",
        "                elif err:\n",
        "                    errors.append(f\"{candidate}: {err}\")\n",
        "        except Exception as e:\n",
        "            errors.append(f\"{directory}: {e}\")\n",
        "        try:\n",
        "            if directory != \"/tmp/videos\" and not os.listdir(directory):\n",
        "                os.rmdir(directory)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return {\n",
        "        \"removed_files\": removed,\n",
        "        \"errors\": errors,\n",
        "        \"preserved\": sorted(list(preserved)),\n",
        "        \"directories_processed\": processed,\n",
        "    }\n",
        "\n",
        "\n",
        "# Tool: create_story_board\n",
        "\n",
        "def create_story_board(\n",
        "    product_name: str,\n",
        "    brand: str,\n",
        "    target_audience: str,\n",
        "    key_message: str,\n",
        "    tone: str,\n",
        "    scenes_count: int = 3,\n",
        "    default_scene_duration_seconds: float = 6.0,\n",
        ") -> str:\n",
        "    \"\"\"Create a simple 3-scene storyboard (beginning, middle, end).\n",
        "\n",
        "    Returns JSON string with a `scenes` array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        initialize_tmp_directories()\n",
        "        scene_names = [\"beginning\", \"middle\", \"end\"]\n",
        "        scenes: List[Dict[str, Any]] = []\n",
        "        for idx, sid in enumerate(scene_names[: max(1, min(10, int(scenes_count))) ]):\n",
        "            title = sid.capitalize()\n",
        "            desc = (\n",
        "                f\"{brand} {product_name} ad for {target_audience}. {sid} of story, tone: {tone}. \"\n",
        "                f\"Key message: {key_message}. Visual focus: product + person.\"\n",
        "            )\n",
        "            prompt = (\n",
        "                f\"Photorealistic {product_name} with a person interacting, cinematic lighting, \"\n",
        "                f\"brand aesthetic for {brand}, clean composition, ad-ready. Scene: {sid}.\"\n",
        "            )\n",
        "            scenes.append(\n",
        "                {\n",
        "                    \"id\": sid,\n",
        "                    \"title\": title,\n",
        "                    \"description\": desc,\n",
        "                    \"prompt\": prompt,\n",
        "                    \"duration_seconds\": float(max(1.0, min(60.0, default_scene_duration_seconds))),\n",
        "                }\n",
        "            )\n",
        "        return json.dumps({\"scenes\": scenes}, ensure_ascii=False)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"scenes\": [], \"error\": f\"create_story_board failed: {e}\"})\n",
        "\n",
        "\n",
        "# Tool: update_story_board\n",
        "\n",
        "def update_story_board(storyboard_json: str, instructions: str) -> str:\n",
        "    \"\"\"Apply lightweight edits (e.g., `duration=8`). Accepts and returns JSON string.\"\"\"\n",
        "    try:\n",
        "        data = json.loads(storyboard_json) if isinstance(storyboard_json, str) else storyboard_json\n",
        "        scenes = data.get(\"scenes\", []) if isinstance(data, dict) else []\n",
        "        m = re.search(r\"duration\\s*=\\s*(\\d+(?:\\.\\d+)?)\", instructions.lower())\n",
        "        if m:\n",
        "            new_dur = float(m.group(1))\n",
        "            for sc in scenes:\n",
        "                if isinstance(sc, dict):\n",
        "                    sc[\"duration_seconds\"] = float(max(1.0, min(60.0, new_dur)))\n",
        "        return json.dumps({\"scenes\": scenes}, ensure_ascii=False)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"update_story_board failed: {e}\", \"scenes\": []})\n",
        "\n",
        "\n",
        "# Tool: generate_image via Google Gemini Images\n",
        "\n",
        "def _extract_text_from_genai(resp: Any) -> str:\n",
        "    # Best-effort extraction of text from google-genai response\n",
        "    try:\n",
        "        t = getattr(resp, \"text\", None)\n",
        "        if isinstance(t, str):\n",
        "            return t\n",
        "        # candidates → parts → text\n",
        "        cands = getattr(resp, \"candidates\", None) or []\n",
        "        for c in cands:\n",
        "            content = getattr(c, \"content\", None)\n",
        "            parts = getattr(content, \"parts\", None) or []\n",
        "            for p in parts:\n",
        "                txt = getattr(p, \"text\", None)\n",
        "                if isinstance(txt, str):\n",
        "                    return txt\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def generate_image(prompt: str, num_images: int = 1, output_basename: str = \"product_ad_image\") -> str:\n",
        "    \"\"\"Generate one or more images using Google Gemini and save PNG files under /tmp/images.\n",
        "\n",
        "    Returns JSON: {\"images\": [paths...], \"error\"?: str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google import genai  # lazy import\n",
        "        api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
        "        if not api_key:\n",
        "            return json.dumps({\"images\": [], \"error\": \"GOOGLE_API_KEY not set\"})\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-image-preview\",\n",
        "            contents=[prompt],\n",
        "        )\n",
        "        os.makedirs(\"/tmp/images\", exist_ok=True)\n",
        "        saved: List[str] = []\n",
        "        idx = 0\n",
        "        # Extract images from interleaved parts\n",
        "        try:\n",
        "            cands = getattr(resp, \"candidates\", None) or []\n",
        "            for c in cands:\n",
        "                content = getattr(c, \"content\", None)\n",
        "                parts = getattr(content, \"parts\", None) or []\n",
        "                for part in parts:\n",
        "                    inline_data = getattr(part, \"inline_data\", None)\n",
        "                    if inline_data is None:\n",
        "                        continue\n",
        "                    data = getattr(inline_data, \"data\", None)\n",
        "                    if not isinstance(data, (bytes, bytearray, memoryview)):\n",
        "                        continue\n",
        "                    try:\n",
        "                        image = Image.open(BytesIO(bytes(data)))\n",
        "                        out_path = f\"/tmp/images/{output_basename}_{idx}.png\"\n",
        "                        image.save(out_path)\n",
        "                        saved.append(out_path)\n",
        "                        idx += 1\n",
        "                        if len(saved) >= max(1, min(4, int(num_images))):\n",
        "                            break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if len(saved) >= max(1, min(4, int(num_images))):\n",
        "                    break\n",
        "        except Exception:\n",
        "            pass\n",
        "        if not saved:\n",
        "            # Try to pull any text error\n",
        "            txt = _extract_text_from_genai(resp)\n",
        "            return json.dumps({\"images\": [], \"error\": txt or \"No images in response\"})\n",
        "        return json.dumps({\"images\": saved})\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"images\": [], \"error\": f\"generate_image error: {e}\"})\n",
        "\n",
        "\n",
        "# Tool: kling video from image via fal.ai\n",
        "\n",
        "def kling_generate_video_from_image(\n",
        "    prompt: str,\n",
        "    image_path: str = \"\",\n",
        "    image_url: str = \"\",\n",
        "    duration_seconds: float = 6.0,\n",
        "    endpoint: str = \"fal-ai/kling/v1\",\n",
        "    seed: Optional[int] = None,\n",
        ") -> str:\n",
        "    \"\"\"Generate short video (<=10s typical) from image via fal.ai Kling endpoint.\n",
        "\n",
        "    Returns JSON with keys: request_id?, video_url?, logs?\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import fal_client  # type: ignore\n",
        "        # configure key from env if present\n",
        "        fal_api_key = os.getenv(\"FAL_KEY\") or os.getenv(\"FAL_API_KEY\")\n",
        "        if fal_api_key:\n",
        "            os.environ.setdefault(\"FAL_KEY\", fal_api_key)\n",
        "\n",
        "        # upload image if local path provided\n",
        "        img_url = image_url\n",
        "        if image_path and os.path.exists(image_path):\n",
        "            try:\n",
        "                img_url = fal_client.upload_file(image_path)\n",
        "            except Exception:\n",
        "                img_url = image_url\n",
        "\n",
        "        logs: List[str] = []\n",
        "\n",
        "        def on_queue_update(update: Any):\n",
        "            try:\n",
        "                if isinstance(update, fal_client.InProgress):\n",
        "                    for log in update.logs:\n",
        "                        msg = log.get(\"message\")\n",
        "                        if isinstance(msg, str):\n",
        "                            logs.append(msg)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        args: Dict[str, Any] = {\n",
        "            \"prompt\": prompt,\n",
        "            \"duration\": float(duration_seconds),\n",
        "        }\n",
        "        if img_url:\n",
        "            args[\"image_url\"] = img_url\n",
        "        if seed is not None:\n",
        "            args[\"seed\"] = int(seed)\n",
        "\n",
        "        result = fal_client.subscribe(endpoint, arguments=args, with_logs=True, on_queue_update=on_queue_update)\n",
        "        video_url = None\n",
        "        try:\n",
        "            if isinstance(result, dict):\n",
        "                video_url = result.get(\"video_url\") or result.get(\"url\") or result.get(\"output_url\")\n",
        "        except Exception:\n",
        "            video_url = None\n",
        "\n",
        "        out = {\n",
        "            \"request_id\": getattr(result, \"request_id\", None) if result else None,\n",
        "            \"video_url\": video_url,\n",
        "            \"logs\": logs or None,\n",
        "        }\n",
        "        return json.dumps(out)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"video_url\": None, \"logs\": [f\"error: {e}\"]})\n",
        "\n",
        "\n",
        "# Tool: run ffmpeg binary\n",
        "\n",
        "def run_ffmpeg_binary(command: str, output_path: str = \"\", timeout_seconds: int = 180) -> str:\n",
        "    \"\"\"Execute ffmpeg command safely. Returns JSON summary including stdout/stderr tails.\"\"\"\n",
        "    try:\n",
        "        if not isinstance(command, str) or not command.strip():\n",
        "            return json.dumps({\"error\": \"Command must be a non-empty string\"})\n",
        "        if not shutil.which(\"ffmpeg\"):\n",
        "            return json.dumps({\"error\": \"ffmpeg not found on PATH. Please install ffmpeg.\"})\n",
        "        if output_path:\n",
        "            out_dir = os.path.dirname(output_path) or \".\"\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        planned = command.strip()\n",
        "        if not planned.lower().startswith(\"ffmpeg\"):\n",
        "            planned = f\"ffmpeg {planned}\"\n",
        "        if \" -y \" not in f\" {planned} \":\n",
        "            parts = planned.split()\n",
        "            if parts and parts[0].lower() == \"ffmpeg\":\n",
        "                parts.insert(1, \"-y\")\n",
        "                planned = \" \".join(parts)\n",
        "        try:\n",
        "            cmd_list = shlex.split(planned)\n",
        "        except Exception as e:\n",
        "            return json.dumps({\"error\": f\"Invalid command: {e}\", \"ffmpeg_command\": planned})\n",
        "\n",
        "        try:\n",
        "            completed = subprocess.run(\n",
        "                cmd_list,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False,\n",
        "                timeout=max(10, int(timeout_seconds)),\n",
        "            )\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return json.dumps({\"error\": f\"FFmpeg timed out after {timeout_seconds}s\", \"ffmpeg_command\": planned})\n",
        "        except OSError as e:\n",
        "            return json.dumps({\"error\": f\"Failed to run ffmpeg: {e}\", \"ffmpeg_command\": planned})\n",
        "\n",
        "        stdout_tail = (completed.stdout or \"\")[-2000:]\n",
        "        stderr_tail = (completed.stderr or \"\")[-4000:]\n",
        "\n",
        "        if completed.returncode != 0:\n",
        "            return json.dumps({\n",
        "                \"error\": f\"FFmpeg failed with code {completed.returncode}: {stderr_tail[-800:]}\",\n",
        "                \"ffmpeg_command\": planned,\n",
        "                \"stdout_tail\": stdout_tail,\n",
        "                \"stderr_tail\": stderr_tail,\n",
        "                \"output_path\": output_path,\n",
        "            })\n",
        "\n",
        "        return json.dumps({\n",
        "            \"output_path\": output_path,\n",
        "            \"ffmpeg_command\": planned,\n",
        "            \"stdout_tail\": stdout_tail,\n",
        "            \"stderr_tail\": stderr_tail,\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"run_ffmpeg_binary error: {e}\"})\n",
        "\n",
        "\n",
        "# Tool: score video with metadata + LLM rubric\n",
        "\n",
        "def score_video(video_path: str, target_quality_score: Optional[float] = None) -> str:\n",
        "    \"\"\"Score a video using ffmpeg metadata and a Gemini text rubric. Returns JSON.\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(video_path):\n",
        "            return json.dumps({\"error\": f\"Video not found: {video_path}\"})\n",
        "        meta: Dict[str, Any] = {}\n",
        "        try:\n",
        "            probe = ffmpeg.probe(video_path)  # type: ignore\n",
        "            streams = probe.get(\"streams\", [])\n",
        "            vstreams = [s for s in streams if s.get(\"codec_type\") == \"video\"]\n",
        "            astreams = [s for s in streams if s.get(\"codec_type\") == \"audio\"]\n",
        "            fmt = probe.get(\"format\", {})\n",
        "            if vstreams:\n",
        "                v0 = vstreams[0]\n",
        "                meta[\"width\"] = v0.get(\"width\")\n",
        "                meta[\"height\"] = v0.get(\"height\")\n",
        "                meta[\"avg_frame_rate\"] = v0.get(\"avg_frame_rate\")\n",
        "            if astreams:\n",
        "                a0 = astreams[0]\n",
        "                meta[\"audio_channels\"] = a0.get(\"channels\")\n",
        "            meta[\"duration\"] = fmt.get(\"duration\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
        "        if not api_key:\n",
        "            return json.dumps({\"error\": \"GOOGLE_API_KEY not set for scoring\"})\n",
        "\n",
        "        from google import genai\n",
        "        client = genai.Client(api_key=api_key)\n",
        "        target = (f\"Target quality score: {float(target_quality_score)}\" if target_quality_score is not None else \"\")\n",
        "        prompt = (\n",
        "            \"You are a strict video quality evaluator. Return ONLY a JSON object with keys \"\n",
        "            \"visual_quality (0-10 int), audio_quality (0-10 int), narrative_coherence (0-10 int), feedback (string).\\n\" \\\n",
        "            + f\"Video Path: {video_path}\\nMetadata: {json.dumps(meta)}\\n{target}\\n\"\n",
        "        )\n",
        "        resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=[prompt])\n",
        "        content_text = _extract_text_from_genai(resp)\n",
        "        # Best-effort JSON extraction\n",
        "        try:\n",
        "            start = content_text.find(\"{\")\n",
        "            end = content_text.rfind(\"}\")\n",
        "            payload = content_text[start : end + 1] if start != -1 and end != -1 else content_text\n",
        "            data = json.loads(payload)\n",
        "        except Exception:\n",
        "            return json.dumps({\"error\": \"Failed to parse JSON from model\", \"raw\": content_text})\n",
        "\n",
        "        def _clamp_int(x: Any) -> int:\n",
        "            try:\n",
        "                return max(0, min(10, int(x)))\n",
        "            except Exception:\n",
        "                return 0\n",
        "\n",
        "        v = _clamp_int(data.get(\"visual_quality\"))\n",
        "        a = _clamp_int(data.get(\"audio_quality\"))\n",
        "        n = _clamp_int(data.get(\"narrative_coherence\"))\n",
        "        score = round((v + a + n) / 3.0, 2)\n",
        "        out = {\n",
        "            \"quality_score\": score,\n",
        "            \"breakdown\": {\"visual_quality\": v, \"audio_quality\": a, \"narrative_coherence\": n},\n",
        "            \"feedback\": data.get(\"feedback\", \"\"),\n",
        "        }\n",
        "        return json.dumps(out)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": f\"scoring failed: {e}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VideoGenerationAgent ready.\n"
          ]
        }
      ],
      "source": [
        "# ReAct Signature and Agent\n",
        "\n",
        "class VideoReActSignature(dspy.Signature):\n",
        "    \"\"\"\n",
        "    You are a product advertisement creative agent.\n",
        "    Tools:\n",
        "    - create_story_board(product_name, brand, target_audience, key_message, tone, scenes_count=3, default_scene_duration_seconds=6.0)\n",
        "    - update_story_board(storyboard_json, instructions)\n",
        "    - generate_image(prompt, num_images=1, output_basename=\"product_ad_image\")\n",
        "    - kling_generate_video_from_image(prompt, image_path=\"\", image_url=\"\", duration_seconds=6.0, endpoint=\"fal-ai/kling/v1\", seed=None)\n",
        "    - run_ffmpeg_binary(command, output_path=\"\", timeout_seconds=180)\n",
        "    - score_video(video_path, target_quality_score=None)\n",
        "\n",
        "    Workflow: Create storyboard → update storyboard (if needed) → generate image → generate video → (optional) ffmpeg postprocess → score video.\n",
        "    Kling videos are limited to ~10 seconds; for longer videos, generate multiple clips and stitch with ffmpeg.\n",
        "\n",
        "    Produce outputs:\n",
        "    - `action`: one of {create_story_board, update_story_board, generate_image, kling_generate_video_from_image, run_ffmpeg_binary, score_video, answer_direct}\n",
        "    - `tool_result`: JSON string from the tool call (may be empty for answer_direct)\n",
        "    - `answer`: concise user-facing update or the final summary\n",
        "    \"\"\"\n",
        "    user_message: str = dspy.InputField(description=\"User request for the advertisement video\")\n",
        "    history: dspy.History = dspy.InputField(description=\"Conversation history\")\n",
        "\n",
        "    reasoning: str = dspy.OutputField(description=\"Brief plan and justification\")\n",
        "    action: str = dspy.OutputField(description=\"Chosen action/tool\")\n",
        "    tool_result: str = dspy.OutputField(description=\"Tool output used to answer\")\n",
        "    answer: str = dspy.OutputField(description=\"Final answer or progress update\")\n",
        "\n",
        "\n",
        "class VideoGenerationAgent(dspy.Module):\n",
        "    def __init__(self, max_iters: int = 5):\n",
        "        super().__init__()\n",
        "        self.conversation_history = dspy.History(messages=[])\n",
        "        self.react = dspy.ReAct(\n",
        "            VideoReActSignature,\n",
        "            tools=[\n",
        "                create_story_board,\n",
        "                update_story_board,\n",
        "                generate_image,\n",
        "                kling_generate_video_from_image,\n",
        "                run_ffmpeg_binary,\n",
        "                score_video,\n",
        "            ],\n",
        "            max_iters=max_iters,\n",
        "        )\n",
        "\n",
        "    def forward(self, user_message: str):\n",
        "        initialize_tmp_directories()\n",
        "        self.conversation_history.messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "        result = self.react(user_message=user_message, history=self.conversation_history)\n",
        "        answer = getattr(result, \"answer\", \"\")\n",
        "        if isinstance(answer, str) and answer.strip():\n",
        "            self.conversation_history.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "        return result\n",
        "\n",
        "\n",
        "agent = VideoGenerationAgent(max_iters=5)\n",
        "print(\"VideoGenerationAgent ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: there are non-text parts in the response: ['inline_data'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "Warning: there are non-text parts in the response: ['inline_data'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': 'answer_direct', 'answer': 'Storyboard for EcoBottle — GreenLife\\nTarget audience: health-conscious young adults\\nTone: inspiring\\nKey message: Reusable, stylish, sustainable.\\nScene duration: 6.0s each\\n\\nScenes:\\n1) id: beginning\\n   title: Beginning\\n   duration_seconds: 6.0\\n   description: Close-up introduction of the EcoBottle in active use — establishes product, design and the “Reusable” message.\\n   output_path: /tmp/images/ecobottle_scene_1.png\\n   prompt (image-generation-ready):\\n   \"Scene 1 - Beginning (save as /tmp/images/ecobottle_scene_1.png): Photorealistic high-resolution PNG. Close-up of a health-conscious young adult jogging in a sunlit park, taking a confident sip from a sleek EcoBottle by GreenLife. Golden-hour cinematic lighting, shallow depth of field, strong emphasis on bottle design and visible GreenLife logo, natural skin tones, minimal background clutter, 3:2 crop, high detail. Text overlay placeholder: \\'Reusable.\\' Ensure consistent EcoBottle appearance across all scenes.\"\\n\\n2) id: middle\\n   title: Middle\\n   duration_seconds: 6.0\\n   description: Everyday stylish use — shows refillability and fashionable design, reinforcing “Stylish.”\\n   output_path: /tmp/images/ecobottle_scene_2.png\\n   prompt (image-generation-ready):\\n   \"Scene 2 - Middle (save as /tmp/images/ecobottle_scene_2.png): Photorealistic high-resolution PNG. Lifestyle shot in a modern café / coworking space: a stylish young adult refilling the EcoBottle at a sleek water station and placing it on a wooden table. Natural daylight, crisp composition, clear view of bottle texture and logo, fashionable outfit, consistent product look, 3:2 crop, high detail. Text overlay placeholder: \\'Stylish.\\' Ensure consistent EcoBottle appearance across all scenes.\"\\n\\n3) id: end\\n   title: End\\n   duration_seconds: 6.0\\n   description: Community & sustainability payoff — group moment that ties the product to values, delivering “Sustainable.”\\n   output_path: /tmp/images/ecobottle_scene_3.png\\n   prompt (image-generation-ready):\\n   \"Scene 3 - End (save as /tmp/images/ecobottle_scene_3.png): Photorealistic high-resolution PNG. Sunset outdoor scene with a small diverse group of young adults laughing and toasting with their EcoBottles in a park. Warm cinematic tones, wide composition showing trees and sky, subtle celebratory vibe emphasizing community and sustainability, consistent bottle appearance and visible GreenLife logo, 16:9 crop, high detail. Text overlay placeholder: \\'Sustainable.\\' Ensure consistent EcoBottle appearance across all scenes.\"\\n\\nNext recommended steps:\\n- Generate the three images at the specified paths using the prompts above.\\n- Use each image to create ~6s Kling clips (or similar) and stitch with ffmpeg if you need a single file.\\n- Add short text overlays (Reusable / Stylish / Sustainable), brand logo, and a CTA (e.g., \"Join GreenLife.\") in post.\\n\\nIf you want, I can now:\\n- generate the three images (call generate_image per scene),\\n- or build the kling_generate_video_from_image commands to make clips,\\n- or produce a final edit sequence and ffmpeg stitch commands. Which do you want next?'}\n",
            "Storyboard: {\"scenes\": [{\"id\": \"beginning\", \"title\": \"Beginning\", \"description\": \"GreenLife EcoBottle ad for health-conscious young  ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: there are non-text parts in the response: ['inline_data'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image result: {\"images\": [], \"error\": \"No images in response\"}\n",
            "Kling result: {\"video_url\": null, \"logs\": [\"error: Path /v1 not found\"]}\n",
            "Scoring example video...\n",
            "{\"quality_score\": 5.67, \"breakdown\": {\"visual_quality\": 8, \"audio_quality\": 6, \"narrative_coherence\": 3}, \"feedback\": \"The technical metadata indicates a robust foundation with 1080p resolution at 60 frames per second, suggesting excellent potential for visual clarity and fluidity. However, a 'strict' evaluation reserves perfect scores for flawless execution beyond mere specifications. Without direct visual inspection, a score of 8 acknowledges the strong technical base but anticipates potential imperfections such as compression artifacts, suboptimal lighting, or minor focus issues that commonly prevent absolute visual perfection. Audio quality, without any provided metadata, is rated a provisional 6. This assumes an average performance, likely marred by common issues like inconsistent levels, ambient noise, or less-than-pristine recording conditions, which strict standards would readily identify. Most significantly, the narrative coherence receives a low score of 3 due to the complete absence of contextual information. Without a discernible plot, thematic intent, or explicit purpose, the video fails to communicate any coherent message or story from an evaluative standpoint, indicating a critical gap in its communicative function.\"}\n"
          ]
        }
      ],
      "source": [
        "# Example usage / smoke tests\n",
        "\n",
        "# 1) Create storyboard\n",
        "payload = {\n",
        "    \"product_name\": \"EcoBottle\",\n",
        "    \"brand\": \"GreenLife\",\n",
        "    \"target_audience\": \"health-conscious young adults\",\n",
        "    \"key_message\": \"Reusable, stylish, and sustainable\",\n",
        "    \"tone\": \"inspiring\",\n",
        "}\n",
        "resp = agent(user_message=(\n",
        "    \"Create a 3-scene product ad storyboard for EcoBottle by GreenLife aimed at \"\n",
        "    \"health-conscious young adults with an inspiring tone; key message: Reusable, stylish, sustainable.\"\n",
        "))\n",
        "print({\n",
        "    \"action\": getattr(resp, \"action\", \"\"),\n",
        "    \"answer\": getattr(resp, \"answer\", \"\"),\n",
        "})\n",
        "\n",
        "# 2) (Optional) Generate image for the first scene — direct tool call for demo\n",
        "storyboard = create_story_board(**payload)\n",
        "print(\"Storyboard:\", storyboard[:120], \"...\")\n",
        "\n",
        "img_result = generate_image(\n",
        "    prompt=\"Photorealistic water bottle with person at gym, cinematic lighting, brand aesthetic\", num_images=1\n",
        ")\n",
        "print(\"Image result:\", img_result)\n",
        "\n",
        "# 3) (Optional) Attempt Kling video generation (requires FAL_KEY/FAL_API_KEY)\n",
        "vid_result = kling_generate_video_from_image(\n",
        "    prompt=\"Dynamic pan of athlete lifting EcoBottle, energetic mood\",\n",
        "    image_path=\"\",  # optionally pass a saved image path from generate_image\n",
        "    image_url=\"\",   # or a public URL\n",
        "    duration_seconds=6.0,\n",
        ")\n",
        "print(\"Kling result:\", vid_result)\n",
        "\n",
        "# 4) (Optional) If a local video is available, score it\n",
        "# Example: score a sample video if present\n",
        "sample_path = \"example_video.mp4\"\n",
        "if os.path.exists(sample_path):\n",
        "    print(\"Scoring example video...\")\n",
        "    print(score_video(sample_path))\n",
        "else:\n",
        "    print(\"No local sample video found to score.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
