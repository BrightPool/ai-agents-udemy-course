{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79c65f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run once per environment)\n",
    "%pip install -q dspy faiss-cpu python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f639fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy configured. Ready to build RAG blog writer.\n"
     ]
    }
   ],
   "source": [
    "# Basic imports and environment setup\n",
    "import os\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env (OPENAI_API_KEY is expected, already set in your env)\n",
    "load_dotenv()\n",
    "\n",
    "# Choose models similar to other notebooks\n",
    "lm = dspy.LM(\"openai/gpt-5-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1, max_tokens=16000)\n",
    "embedder = dspy.Embedder(\"openai/text-embedding-3-large\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Configure DSPy default LM\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"DSPy configured. Ready to build RAG blog writer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796e1c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index ready. Example query:\n",
      "[{'id': 'email_nurture_1', 'text': 'Email nurture sequences should deliver value before pitching, segment by behavior, and align topics with buyer stage.', 'score': 0.5652014017105103}, {'id': 'distribution_1', 'text': 'Content distribution multiplies ROI. Repurpose flagship assets into shorts, carousels, and newsletters with channel-native hooks.', 'score': 0.2681694030761719}, {'id': 'product_marketing_1', 'text': 'Great product marketing connects features to outcomes, arms sales with crisp narratives, and maintains a feedback loop with customers.', 'score': 0.23627716302871704}]\n"
     ]
    }
   ],
   "source": [
    "# Build a small example marketing corpus (can be replaced with your own docs)\n",
    "# The idea: sections/snippets of prior posts the agent should consult via vector search\n",
    "example_docs = [\n",
    "    {\"id\": \"brand_strategy_1\", \"text\": \"Brand positioning clarifies who you serve, what you offer, and why you are different. Strong positioning guides messaging consistency across channels.\"},\n",
    "    {\"id\": \"seo_basics_1\", \"text\": \"Effective SEO content targets search intent, uses clear structure, and earns trust through expertise and internal links.\"},\n",
    "    {\"id\": \"email_nurture_1\", \"text\": \"Email nurture sequences should deliver value before pitching, segment by behavior, and align topics with buyer stage.\"},\n",
    "    {\"id\": \"product_marketing_1\", \"text\": \"Great product marketing connects features to outcomes, arms sales with crisp narratives, and maintains a feedback loop with customers.\"},\n",
    "    {\"id\": \"distribution_1\", \"text\": \"Content distribution multiplies ROI. Repurpose flagship assets into shorts, carousels, and newsletters with channel-native hooks.\"},\n",
    "]\n",
    "\n",
    "# Build FAISS index using DSPy Embeddings tool\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Embed all documents\n",
    "texts = [d[\"text\"] for d in example_docs]\n",
    "embeddings = embedder(texts)\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# Create FAISS index (L2)\n",
    "index = faiss.IndexFlatL2(X.shape[1])\n",
    "index.add(X)\n",
    "\n",
    "# Helper: search top-k docs by cosine-like distance (here L2 on normalized vectors)\n",
    "# For simplicity, we normalize embeddings so L2 approximates cosine ranking for nearest neighbors\n",
    "X_norm = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-12)\n",
    "index_cosine = faiss.IndexFlatL2(X_norm.shape[1])\n",
    "index_cosine.add(X_norm)\n",
    "\n",
    "id_lookup = {i: example_docs[i][\"id\"] for i in range(len(example_docs))}\n",
    "\n",
    "def faiss_search(query: str, k: int = 3) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Vector search helper that returns the top-k most similar prior snippets.\n",
    "    \"\"\"\n",
    "    q_emb = np.array(embedder([query])[0]).astype(\"float32\")\n",
    "    q_emb = q_emb / (np.linalg.norm(q_emb) + 1e-12)\n",
    "    distances, indices = index_cosine.search(q_emb.reshape(1, -1), k)\n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"id\": id_lookup[idx],\n",
    "            \"text\": example_docs[idx][\"text\"],\n",
    "            \"score\": float(1.0 - dist/2)  # rough similarity indicator\n",
    "        })\n",
    "    return results\n",
    "\n",
    "print(\"FAISS index ready. Example query:\")\n",
    "print(faiss_search(\"write an email nurture welcome series\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c58af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signatures and base modules ready.\n"
     ]
    }
   ],
   "source": [
    "# DSPy signatures for outline and section writing\n",
    "# Keep signatures simple for readability by interns\n",
    "class OutlineSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Create a clear, multi-level outline for a marketing blog post.\n",
    "    \"\"\"\n",
    "    topic: str = dspy.InputField(description=\"Blog topic\")\n",
    "    outline: list[str] = dspy.OutputField(description=\"Ordered list of section titles\")\n",
    "\n",
    "class SectionSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Write a focused section with context from prior company writing.\n",
    "    \"\"\"\n",
    "    topic: str = dspy.InputField(description=\"Blog topic\")\n",
    "    section_title: str = dspy.InputField(description=\"Which section to write\")\n",
    "    retrieved_context: list[str] = dspy.InputField(description=\"Relevant snippets from prior posts\")\n",
    "    draft: str = dspy.OutputField(description=\"Section draft (3â€“6 paragraphs, concise)\")\n",
    "\n",
    "# Simple modules\n",
    "outline_generator = dspy.Predict(OutlineSignature)\n",
    "section_writer = dspy.Predict(SectionSignature)\n",
    "\n",
    "print(\"Signatures and base modules ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b504f51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools ready: search_context, change_outline, write_section, edit_section\n"
     ]
    }
   ],
   "source": [
    "# ReAct-style tools encoded as simple Python callables the agent can invoke\n",
    "# Each tool returns a dict so the agent can keep state simple\n",
    "\n",
    "def tool_search_context(query: str, k: int = 4) -> dict:\n",
    "    \"\"\"\n",
    "    Tool: vector search in FAISS for prior snippets related to the query.\n",
    "    \"\"\"\n",
    "    hits = faiss_search(query, k=k)\n",
    "    return {\"tool\": \"search_context\", \"results\": hits}\n",
    "\n",
    "# In-memory working state for outline and sections\n",
    "blog_state = {\n",
    "    \"topic\": None,\n",
    "    \"outline\": [],\n",
    "    \"sections\": {},  # section_title -> draft text\n",
    "}\n",
    "\n",
    "\n",
    "def tool_change_outline(new_outline: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Tool: replace the current outline with a new one (single happy path).\n",
    "    \"\"\"\n",
    "    blog_state[\"outline\"] = list(new_outline)\n",
    "    return {\"tool\": \"change_outline\", \"outline\": blog_state[\"outline\"]}\n",
    "\n",
    "\n",
    "def tool_write_section(topic: str, section_title: str) -> dict:\n",
    "    \"\"\"\n",
    "    Tool: write a fresh section using retrieved context.\n",
    "    \"\"\"\n",
    "    ctx_hits = faiss_search(f\"{topic} {section_title}\")\n",
    "    ctx_texts = [h[\"text\"] for h in ctx_hits]\n",
    "    pred = section_writer(\n",
    "        topic=topic,\n",
    "        section_title=section_title,\n",
    "        retrieved_context=ctx_texts,\n",
    "    )\n",
    "    blog_state[\"sections\"][section_title] = pred.draft\n",
    "    return {\"tool\": \"write_section\", \"section_title\": section_title, \"draft\": pred.draft}\n",
    "\n",
    "\n",
    "def tool_edit_section(topic: str, section_title: str, instruction: str) -> dict:\n",
    "    \"\"\"\n",
    "    Tool: light edit of an existing section by re-prompting with current draft and context.\n",
    "    \"\"\"\n",
    "    existing = blog_state[\"sections\"].get(section_title, \"\")\n",
    "    ctx_hits = faiss_search(f\"{topic} {section_title} {instruction}\")\n",
    "    ctx_texts = [h[\"text\"] for h in ctx_hits] + [existing]\n",
    "    pred = section_writer(\n",
    "        topic=topic,\n",
    "        section_title=section_title,\n",
    "        retrieved_context=ctx_texts,\n",
    "    )\n",
    "    blog_state[\"sections\"][section_title] = pred.draft\n",
    "    return {\"tool\": \"edit_section\", \"section_title\": section_title, \"draft\": pred.draft}\n",
    "\n",
    "print(\"Tools ready: search_context, change_outline, write_section, edit_section\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91fe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent ready.\n"
     ]
    }
   ],
   "source": [
    "# ReAct agent using DSPy (preferred)\n",
    "# Tools must have clear docstrings and type hints\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def tool_assemble_blog() -> dict:\n",
    "    \"\"\"\n",
    "    Assemble the final blog post from the current outline and written sections.\n",
    "    Returns a dict with a single key \"final_blog\".\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for title in blog_state[\"outline\"]:\n",
    "        body = blog_state[\"sections\"].get(title, \"\")\n",
    "        parts.append(f\"# {title}\\n\\n{body}\")\n",
    "    final = \"\\n\\n\".join(parts).strip()\n",
    "    return {\"tool\": \"assemble_blog\", \"final_blog\": final}\n",
    "\n",
    "\n",
    "class BlogAgentSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a marketing blog writer. Given `topic`, create an outline, write each\n",
    "    section using prior company writing as context (via vector search), optionally\n",
    "    edit sections for continuity, and finish with a coherent draft.\n",
    "    Use only the available tools. When finished, return the complete blog draft\n",
    "    in `process_result`.\n",
    "    \"\"\"\n",
    "    topic: str = dspy.InputField(description=\"Blog topic to write about\")\n",
    "    reasoning: str = dspy.OutputField(description=\"High-level plan and justification of actions\")\n",
    "    process_result: str = dspy.OutputField(description=\"Final blog draft text\")\n",
    "\n",
    "# Create a ReAct agent that can call the tools\n",
    "react_agent = dspy.ReAct(\n",
    "    BlogAgentSignature,\n",
    "    tools=[\n",
    "        tool_search_context,\n",
    "        tool_change_outline,\n",
    "        tool_write_section,\n",
    "        tool_edit_section,\n",
    "        tool_assemble_blog,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"ReAct agent ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff9887",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ReAct._call_with_potential_trajectory_truncation() got multiple values for argument 'trajectory'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m blog_state[\u001b[33m\"\u001b[39m\u001b[33moutline\u001b[39m\u001b[33m\"\u001b[39m] = []\n\u001b[32m      6\u001b[39m blog_state[\u001b[33m\"\u001b[39m\u001b[33msections\u001b[39m\u001b[33m\"\u001b[39m] = {}\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m react_result = \u001b[43mreact_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow to create a buyer-journey aligned content strategy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mReasoning:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, react_result.reasoning)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOutline:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/ai-agents-udemy-course/.venv/lib/python3.13/site-packages/dspy/utils/callback.py:326\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    330\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/ai-agents-udemy-course/.venv/lib/python3.13/site-packages/dspy/primitives/module.py:78\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Codes/ai-agents-udemy-course/.venv/lib/python3.13/site-packages/dspy/predict/react.py:101\u001b[39m, in \u001b[36mReAct.forward\u001b[39m\u001b[34m(self, **input_args)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m         pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_potential_trajectory_truncation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    103\u001b[39m         logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEnding the trajectory: Agent failed to select a valid tool: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_fmt_exc(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: ReAct._call_with_potential_trajectory_truncation() got multiple values for argument 'trajectory'"
     ]
    }
   ],
   "source": [
    "# Demo: drive the DSPy ReAct agent end-to-end\n",
    "# The agent will choose tools and assemble the final blog in process_result\n",
    "\n",
    "# Reset state for a clean run\n",
    "blog_state[\"outline\"] = []\n",
    "blog_state[\"sections\"] = {}\n",
    "\n",
    "react_result = react_agent(topic=\"How to create a buyer-journey aligned content strategy\")\n",
    "\n",
    "print(\"Reasoning:\\n\", react_result.reasoning)\n",
    "print(\"\\nOutline:\")\n",
    "for i, s in enumerate(blog_state[\"outline\"], 1):\n",
    "    print(f\"{i}. {s}\")\n",
    "\n",
    "print(\"\\nFinal Blog Draft:\\n\")\n",
    "print(react_result.process_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
