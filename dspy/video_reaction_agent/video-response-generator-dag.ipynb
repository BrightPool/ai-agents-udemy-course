{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: restart the kernel if packages were freshly installed.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once per environment)\n",
        "%pip install -q dspy python-dotenv google-genai fal-client pillow ffmpeg-python\n",
        "print(\"Note: restart the kernel if packages were freshly installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy configured for Video Response Generator DAG.\n"
          ]
        }
      ],
      "source": [
        "# Basic imports and environment setup\n",
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from dspy import History\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Configure LM (Anthropic or OpenAI OK; using OpenAI mini for text-only here)\n",
        "lm = dspy.LM(\"openai/gpt-5-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1, max_tokens=16000)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"DSPy configured for Video Response Generator DAG.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pydantic models equivalent to LangGraph `models.py`\n",
        "from typing import Dict\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class BuyingSituation(BaseModel):\n",
        "    situation: str\n",
        "    location: str\n",
        "    trigger: str\n",
        "    evaluation: str\n",
        "    conclusion: str\n",
        "\n",
        "class BuyingSituationsOutput(BaseModel):\n",
        "    persona: str = Field(..., description=\"Name or identifier for the persona\")\n",
        "    buying_situations: Dict[str, BuyingSituation]\n",
        "\n",
        "class SceneDescription(BaseModel):\n",
        "    persona: str\n",
        "    appearance: str\n",
        "\n",
        "class PromptModel(BaseModel):\n",
        "    scene_description: SceneDescription\n",
        "    quote: str\n",
        "    prompt_string: str\n",
        "\n",
        "class PromptOutput(BaseModel):\n",
        "    prompt: PromptModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core tools ported from LangGraph DAG (plain Python functions)\n",
        "import time\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing import Any, List, Dict, Optional, cast\n",
        "\n",
        "import httpx\n",
        "\n",
        "# Phase 0: init and persona catalog\n",
        "\n",
        "def init_and_create_directory() -> Dict[str, str]:\n",
        "    execution_id = uuid.uuid4().hex\n",
        "    work_dir = Path(f\"/tmp/n8n/{execution_id}\")\n",
        "    work_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for f in [\"videos.txt\", \"final_output.mp4\"]:\n",
        "        try:\n",
        "            (work_dir / f).unlink(missing_ok=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {\"execution_id\": execution_id, \"work_dir\": str(work_dir)}\n",
        "\n",
        "\n",
        "def define_personas() -> Dict[str, Dict[str, Dict[str, str]]]:\n",
        "    personas: Dict[str, Dict[str, str]] = {\n",
        "        \"Omar US Developer\": {\n",
        "            \"name\": \"Omar Ali\",\n",
        "            \"age\": \"32\",\n",
        "            \"gender\": \"Male\",\n",
        "            \"location\": \"San Francisco\",\n",
        "            \"occupation\": \"Software Engineer\",\n",
        "            \"income\": \"$200,000\",\n",
        "            \"background\": (\n",
        "                \"This individual's life revolves around exploration and understanding. They are deeply curious about the world, people, and how things work, often delving into complex topics such as philosophy, history, and the human psyche. Their online presence is a reflection of their inner world - an active, thoughtful space where they seek to make connections, exchange ideas, and learn from others. They love the act of learning and self-improvement. They have a strong desire to make things better for themselves and the world around them, expressed through their writing and interactions. This person is committed to their craft, valuing beauty and truth, and finds joy in the small, everyday aspects of life. They are fascinated by the power of human connection and the potential for growth within communities. They are known for their inquisitive nature, often posing questions and seeking different perspectives to broaden their understanding of the world. They have an open mind and are constantly seeking a deeper understanding of complex concepts and human behavior. Their curiosity is a constant source of inspiration, driving them to explore new ideas, challenge their beliefs, and make meaningful connections with others.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Sarah UK Nurse\": {\n",
        "            \"name\": \"Sarah Thomspon\",\n",
        "            \"age\": \"55\",\n",
        "            \"gender\": \"Woman\",\n",
        "            \"location\": \"Manchester, UK\",\n",
        "            \"occupation\": \"Nurse\",\n",
        "            \"income\": \"GBP 55k\",\n",
        "            \"background\": (\n",
        "                \"Sarah is a dedicated Registered Nurse with over thirty years of experience in the NHS. Raised in a working-class family, she was inspired to pursue nursing by her strong desire to help others and provide compassionate care. She is married, owns her home, and is a devout Christian, finding strength in her faith and family. Sarah is a strong advocate for her patients and believes healthcare is a fundamental right. She enjoys reading, gardening, and spending time outdoors, which helps her manage the stress that comes with her demanding job. Throughout her career, she has consistently strived to improve her skills and provide the best possible care to her patients.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Emily US Foodie\": {\n",
        "            \"name\": \"Emily Carter\",\n",
        "            \"age\": \"21\",\n",
        "            \"gender\": \"Female\",\n",
        "            \"location\": \"Los Angeles, CA\",\n",
        "            \"occupation\": \"Student\",\n",
        "            \"income\": \"NA\",\n",
        "            \"background\": (\n",
        "                \"Emily Carter is a 21-year-old college student at UCLA, majoring in Digital Marketing. Originally from a small town in Oregon, she moved to Los Angeles to pursue her passion for marketing and content creation. She's an avid foodie, constantly exploring LA's diverse culinary landscape and documenting her experiences on TikTok and Instagram. Her content focuses on restaurant reviews, food trends, and lifestyle content, and she hopes to work in social media marketing after graduation.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Clara US Health Coach\": {\n",
        "            \"name\": \"Clara Johnson\",\n",
        "            \"age\": \"35\",\n",
        "            \"gender\": \"Female\",\n",
        "            \"location\": \"New York City, NY\",\n",
        "            \"occupation\": \"Health Coach\",\n",
        "            \"income\": \"$70k\",\n",
        "            \"background\": (\n",
        "                \"Clara, a certified holistic health coach, was raised in a culturally diverse household where natural wellness was a way of life. Inspired by her family's practices, she pursued a certification in holistic health and launched her coaching business in NYC. Through her work at NaturalHealth Inc., Clara focuses on promoting holistic beauty methods, integrating wellness with skincare, and educating others on the benefits of natural products. She is passionate about community workshops and uses her platform to share DIY beauty techniques, encouraging others to embrace natural wellness. She is a Buddhist who believes beauty comes from within and enjoys meditation, nature walks, and creating healthy meals.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Jordan US Tattoo Artist\": {\n",
        "            \"name\": \"Jordan McCulloch\",\n",
        "            \"age\": \"Age 5\",\n",
        "            \"gender\": \"Male\",\n",
        "            \"location\": \"Portland, OR, USA\",\n",
        "            \"occupation\": \"Tattoo Artist\",\n",
        "            \"income\": \"$48k\",\n",
        "            \"background\": (\n",
        "                \"Jordan grew up in a small coastal town in Oregon before moving to Portland to embrace the cityâ€™s alternative scene and vibrant art community. With a talent for visual storytelling and a welcoming demeanor, Jordan found a calling in tattoo artistry, channeling creativity into meaningful body art for friends and clients. Passionate about authentic self-expression and forging real connections, Jordan has built a loyal client base and a network of close friends who share a love of indie music, art shows, and late-night philosophical discussions. Jordan values openness in relationships and tends to express themselves candidly, both in art and conversation. When not at the tattoo studio, Jordan spends time volunteering for LGBTQ+ causes, making zines, and exploring the cityâ€™s eclectic food scene.\"\n",
        "            ),\n",
        "        },\n",
        "    }\n",
        "    return {\"personas\": personas}\n",
        "\n",
        "\n",
        "def set_persona(personas: Dict[str, Dict[str, str]], persona_selection: str) -> Dict[str, str]:\n",
        "    if not persona_selection or persona_selection not in personas:\n",
        "        raise ValueError(\"persona_selection is missing or invalid\")\n",
        "    return personas[persona_selection]\n",
        "\n",
        "\n",
        "# Phase 1: Buying situations via LM\n",
        "\n",
        "def _get_llm_predict():\n",
        "    return dspy.Predict(\"question -> answer\")\n",
        "\n",
        "\n",
        "def generate_buying_situations(persona: Dict[str, str]) -> Dict[str, Any]:\n",
        "    if not persona:\n",
        "        raise KeyError(\"persona missing; ensure set_persona ran first\")\n",
        "    system = (\n",
        "        \"Role play as {name}, a {age} {gender} from {location}, works as a {occupation} \"\n",
        "        \"earning {income}. {background}. You have been invited to review a new product \"\n",
        "        \"concept and reveal deep, personal insights into when you would buy this offer. \"\n",
        "        \"Return only valid JSON with fields persona (string) and buying_situations (object with exactly 3 keys).\"\n",
        "    ).format(**persona)\n",
        "    example = '{\"persona\":\"Rhys UK Entrepreneur\",\"buying_situations\":{\"celebrating_milestone\":{\"situation\":\"Celebrating a business milestone\",\"location\":\"Private members\\' club in London\",\"trigger\":\"Closed a major deal\",\"evaluation\":\"Considered champagne and cocktails, but wanted tradition\",\"conclusion\":\"Chose premium whisky\"},\"hosting_partners\":{\"situation\":\"Hosting international partners\",\"location\":\"Home office in Manchester\",\"trigger\":\"Inviting overseas investors\",\"evaluation\":\"Compared various spirits; whisky is distinctly British\",\"conclusion\":\"Bought respected Scottish whisky\"},\"relaxing_weekend\":{\"situation\":\"Relaxing after a long week\",\"location\":\"Apartment balcony overlooking the city\",\"trigger\":\"Needed a way to unwind\",\"evaluation\":\"Looked at beer, gin, wine; whisky appealed\",\"conclusion\":\"Chose whisky as a ritual drink\"}}}'\n",
        "    prompt = (\n",
        "        \"Respond only with raw JSON (no markdown). Use this schema and ensure 3 buying_situations. Example: \"\n",
        "        f\"{example}\"\n",
        "    )\n",
        "    predictor = _get_llm_predict()\n",
        "    raw = predictor(question=f\"{system}\\n\\n{prompt}\")\n",
        "    text = getattr(raw, \"answer\", \"\")\n",
        "    data = None\n",
        "    for _ in range(2):\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "            break\n",
        "        except Exception:\n",
        "            repair = predictor(question=\"Repair to valid JSON with the same schema: \" + text)\n",
        "            text = getattr(repair, \"answer\", \"\")\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to parse buying situations JSON\")\n",
        "    validated = BuyingSituationsOutput.model_validate(data)\n",
        "    situations_list = list(validated.buying_situations.values())\n",
        "    return {\n",
        "        \"buying_situations\": validated.buying_situations,\n",
        "        \"situations_list\": situations_list,\n",
        "        \"situation_index\": 0,\n",
        "        \"prompts_json\": [],\n",
        "        \"prompt_strings\": [],\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_prompt_for_current(persona: Dict[str, str], situations_list: List[BuyingSituation], situation_index: int) -> Dict[str, Any]:\n",
        "    if not (0 <= situation_index < len(situations_list)):\n",
        "        raise IndexError(\"situation_index out of range\")\n",
        "    situation = situations_list[situation_index]\n",
        "    template = (\n",
        "        \"You are a director of a qualitative research agency that specialises in creating realistic simulated testimonials that capture buying situations for new product concepts.\\n\\n\"\n",
        "        \"Your tasks are to: 1) Craft persona description, 2) scene appearance, 3) a short 6â€“8s quote, 4) assemble final prompt string.\\n\"\n",
        "        \"Return a structured object strictly matching this Pydantic schema: PromptOutput(prompt: PromptModel(scene_description: SceneDescription(persona, appearance), quote, prompt_string)). No markdown.\\n\"\n",
        "        \"Important: scene_description.persona MUST be a single short string with the persona's name only (e.g., 'Omar Ali'). Do NOT return an object for this field.\\n\"\n",
        "        \"Return exactly these keys: {\\\"prompt\\\": {\\\"scene_description\\\": {\\\"persona\\\": \\\"...\\\", \\\"appearance\\\": \\\"...\\\"}, \\\"quote\\\": \\\"...\\\", \\\"prompt_string\\\": \\\"...\\\"}}.\\n\\n\"\n",
        "        \"Persona\\n\"\n",
        "        f\"Name: {persona['name']}\\n\"\n",
        "        f\"Age: {persona['age']}\\n\"\n",
        "        f\"Gender: {persona['gender']}\\n\"\n",
        "        f\"Location: {persona['location']}\\n\"\n",
        "        f\"Occupation: {persona['occupation']}\\n\"\n",
        "        f\"Income: {persona['income']}\\n\"\n",
        "        f\"Background: {persona['background']}\\n\\n\"\n",
        "        \"Buying Situation\\n\"\n",
        "        f\"Situation: {situation.situation}\\n\"\n",
        "        f\"Location: {situation.location}\\n\"\n",
        "        f\"Trigger: {situation.trigger}\\n\"\n",
        "        f\"Evaluation: {situation.evaluation}\\n\"\n",
        "        f\"Conclusion: {situation.conclusion}\"\n",
        "    )\n",
        "    predictor = dspy.Predict(\"instruction -> json_text\")\n",
        "    raw = predictor(instruction=template)\n",
        "    text = getattr(raw, \"json_text\", \"\")\n",
        "    data = None\n",
        "    for _ in range(2):\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "            break\n",
        "        except Exception:\n",
        "            repair = dspy.Predict(\"text -> json_text\")(text=\"Repair to valid JSON only with the same schema. Ensure scene_description.persona is a single string (name only), not an object. Return exactly {\\\"prompt\\\": {\\\"scene_description\\\": {\\\"persona\\\": \\\"...\\\", \\\"appearance\\\": \\\"...\\\"}, \\\"quote\\\": \\\"...\\\", \\\"prompt_string\\\": \\\"...\\\"}}.\\n\\n\" + text)\n",
        "            text = getattr(repair, \"json_text\", \"\")\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to parse prompt JSON\")\n",
        "    validated = PromptOutput.model_validate(data)\n",
        "    return {\"prompt_json\": validated, \"prompt_string\": validated.prompt.prompt_string}\n",
        "\n",
        "\n",
        "# Phase 3: FAL queue and video merging\n",
        "\n",
        "def _fal_headers() -> Dict[str, str]:\n",
        "    name = os.getenv(\"FAL_AUTH_HEADER_NAME\", \"Authorization\")\n",
        "    value = os.getenv(\"FAL_AUTH_HEADER_VALUE\")\n",
        "    if not value:\n",
        "        api_key = os.getenv(\"FAL_API_KEY\") or os.getenv(\"FAL_KEY\")\n",
        "        if api_key:\n",
        "            value = f\"Key {api_key}\"\n",
        "    return {name: value} if value else {}\n",
        "\n",
        "\n",
        "def _normalize_fal_urls(status_url: Optional[str], response_url: Optional[str]) -> Dict[str, str]:\n",
        "    def base_from(url: str) -> str:\n",
        "        u = url.rstrip(\"/\")\n",
        "        if u.endswith(\"/status\"):\n",
        "            return u[:-7]\n",
        "        if u.endswith(\"/response\"):\n",
        "            return u[:-9]\n",
        "        # if already like /requests/{id}, return as base\n",
        "        return u\n",
        "    base = None\n",
        "    if status_url:\n",
        "        base = base_from(status_url)\n",
        "    elif response_url:\n",
        "        base = base_from(response_url)\n",
        "    else:\n",
        "        return {\"status_url\": status_url or \"\", \"response_url\": response_url or \"\"}\n",
        "    return {\"status_url\": f\"{base}/status\", \"response_url\": f\"{base}/response\"}\n",
        "\n",
        "\n",
        "def _extract_video_url_from_data(data: Dict[str, Any]) -> Optional[str]:\n",
        "    if not isinstance(data, dict):\n",
        "        return None\n",
        "    if isinstance(data.get(\"video\"), dict) and data.get(\"video\", {}).get(\"url\"):\n",
        "        return str(data[\"video\"][\"url\"])\n",
        "    if data.get(\"video_url\"):\n",
        "        return str(data[\"video_url\"])  # type: ignore\n",
        "    if data.get(\"url\") and str(data.get(\"url\")).endswith(\".mp4\"):\n",
        "        return str(data[\"url\"])  # type: ignore\n",
        "    return None\n",
        "\n",
        "\n",
        "def _collect_final_response(client: httpx.Client, headers: Dict[str, str], base_url: str, wait_seconds: int = 1, max_polls: int = 60) -> Dict[str, Any]:\n",
        "    urls = _normalize_fal_urls(status_url=None, response_url=base_url)\n",
        "    print(f\"[FAL] collect child: status={urls['status_url']} response={urls['response_url']}\")\n",
        "    # Poll child until completed\n",
        "    for attempt in range(max_polls):\n",
        "        try:\n",
        "            st = client.get(urls[\"status_url\"], headers=headers)\n",
        "            st.raise_for_status()\n",
        "        except httpx.HTTPStatusError as ex:\n",
        "            body = ex.response.text if ex.response is not None else \"\"\n",
        "            code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "            print(f\"[FAL] collect poll HTTP {code}; body={body[:300]}\")\n",
        "            raise\n",
        "        sdata = st.json()\n",
        "        s = str(sdata.get(\"status\", \"\")).upper()\n",
        "        print(f\"[FAL] collect poll attempt {attempt+1}/{max_polls}: status={s}\")\n",
        "        if s == \"COMPLETED\":\n",
        "            break\n",
        "        time.sleep(max(0, int(wait_seconds)))\n",
        "    # Fetch child response\n",
        "    try:\n",
        "        resp = client.post(urls[\"response_url\"], headers=headers, json={})\n",
        "        resp.raise_for_status()\n",
        "    except httpx.HTTPStatusError as ex:\n",
        "        body = ex.response.text if ex.response is not None else \"\"\n",
        "        code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "        allow = ex.response.headers.get(\"Allow\") if ex.response is not None else None\n",
        "        print(f\"[FAL] collect fetch HTTP {code}; allow={allow}; body={body[:300]}\")\n",
        "        raise\n",
        "    return resp.json()\n",
        "\n",
        "\n",
        "def submit_fal_requests(prompt_strings: List[str]) -> List[Dict[str, str]]:\n",
        "    base_url = os.getenv(\"FAL_QUEUE_URL\", \"https://queue.fal.run/fal-ai/veo3\")\n",
        "    headers = _fal_headers()\n",
        "    print(f\"[FAL] queue base={base_url}; auth headers={list(headers.keys())}\")\n",
        "    requests_info: List[Dict[str, str]] = []\n",
        "    with httpx.Client(timeout=60) as client:\n",
        "        for idx, prompt in enumerate(prompt_strings):\n",
        "            try:\n",
        "                resp = client.post(base_url, headers=headers, json={\"prompt\": prompt})\n",
        "                resp.raise_for_status()\n",
        "                data = resp.json()\n",
        "            except httpx.HTTPStatusError as ex:\n",
        "                body = ex.response.text if ex.response is not None else \"\"\n",
        "                code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "                print(f\"[FAL] submit({idx}) HTTP {code}; body={body[:500]}\")\n",
        "                raise\n",
        "            except Exception as ex:\n",
        "                print(f\"[FAL] submit({idx}) error: {ex}\")\n",
        "                raise\n",
        "            request_id = data.get(\"request_id\") or data.get(\"id\")\n",
        "            status_url_raw = data.get(\"status_url\") or data.get(\"status\")\n",
        "            response_url_raw = data.get(\"response_url\") or data.get(\"response\")\n",
        "            if not request_id or not (status_url_raw or response_url_raw):\n",
        "                print(f\"[FAL] submit({idx}) unexpected response keys={list(data.keys())}\")\n",
        "                raise ValueError(f\"Unexpected FAL response: {data}\")\n",
        "            urls = _normalize_fal_urls(status_url_raw, response_url_raw)\n",
        "            print(f\"[FAL] submit({idx}) ok: id={request_id} status_url={urls['status_url']} response_url={urls['response_url']}\")\n",
        "            requests_info.append({\n",
        "                \"request_id\": request_id,\n",
        "                \"status_url\": urls[\"status_url\"],\n",
        "                \"response_url\": urls[\"response_url\"],\n",
        "            })\n",
        "    return requests_info\n",
        "\n",
        "\n",
        "def poll_statuses(fal_requests: List[Dict[str, str]]) -> Dict[str, Any]:\n",
        "    headers = _fal_headers()\n",
        "    statuses: List[str] = []\n",
        "    with httpx.Client(timeout=30) as client:\n",
        "        for idx, req in enumerate(fal_requests):\n",
        "            url = req.get(\"status_url\")\n",
        "            print(f\"[FAL] poll({idx}) url={url}\")\n",
        "            try:\n",
        "                resp = client.get(url, headers=headers)\n",
        "                resp.raise_for_status()\n",
        "            except httpx.HTTPStatusError as ex:\n",
        "                body = ex.response.text if ex.response is not None else \"\"\n",
        "                code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "                print(f\"[FAL] poll({idx}) HTTP {code}; body={body[:500]}\")\n",
        "                raise\n",
        "            data = resp.json()\n",
        "            status_value = str(data.get(\"status\", \"\")).upper()\n",
        "            print(f\"[FAL] poll({idx}) status={status_value}\")\n",
        "            statuses.append(status_value)\n",
        "    all_complete = all(s == \"COMPLETED\" for s in statuses) if statuses else False\n",
        "    return {\"statuses\": statuses, \"all_complete\": all_complete}\n",
        "\n",
        "\n",
        "def fetch_video_urls(fal_requests: List[Dict[str, str]] , wait_seconds: int = 1, max_polls: int = 60) -> List[str]:\n",
        "    headers = _fal_headers()\n",
        "    video_urls: List[str] = []\n",
        "    with httpx.Client(timeout=60) as client:\n",
        "        for idx, req in enumerate(fal_requests):\n",
        "            response_url = req.get(\"response_url\")\n",
        "            if not response_url:\n",
        "                raise ValueError(f\"Missing response_url for request: {req}\")\n",
        "            print(f\"[FAL] fetch({idx}) url={response_url}\")\n",
        "            try:\n",
        "                resp = client.post(response_url, headers=headers, json={})\n",
        "                resp.raise_for_status()\n",
        "            except httpx.HTTPStatusError as ex:\n",
        "                body = ex.response.text if ex.response is not None else \"\"\n",
        "                code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "                allow = ex.response.headers.get(\"Allow\") if ex.response is not None else None\n",
        "                print(f\"[FAL] fetch({idx}) HTTP {code}; allow={allow}; body={body[:500]}\")\n",
        "                raise\n",
        "            data = resp.json()\n",
        "            print(f\"[FAL] fetch({idx}) keys={list(data.keys())}\")\n",
        "            # If there is no video payload yet, but a nested request is provided, collect it\n",
        "            url_candidate = _extract_video_url_from_data(data)\n",
        "            if not url_candidate and data.get(\"response_url\"):\n",
        "                nested = _collect_final_response(client, headers, base_url=str(data[\"response_url\"]), wait_seconds=wait_seconds, max_polls=max_polls)\n",
        "                print(f\"[FAL] fetch({idx}) nested keys={list(nested.keys())}\")\n",
        "                url_candidate = _extract_video_url_from_data(nested)\n",
        "            if not url_candidate:\n",
        "                raise ValueError(f\"No video URL in response: {data}\")\n",
        "            video_urls.append(url_candidate)\n",
        "    return video_urls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download + ffmpeg helpers\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def download_videos(video_urls: List[str], work_dir: str) -> List[str]:\n",
        "    Path(work_dir).mkdir(parents=True, exist_ok=True)\n",
        "    files: List[str] = []\n",
        "    with httpx.Client(timeout=None, follow_redirects=True) as client:\n",
        "        for i, url in enumerate(video_urls):\n",
        "            file_name = f\"{i:02d}.mp4\"\n",
        "            file_path = Path(work_dir) / file_name\n",
        "            with client.stream(\"GET\", url) as resp:\n",
        "                resp.raise_for_status()\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    for chunk in resp.iter_bytes():\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "            files.append(str(file_path))\n",
        "    return files\n",
        "\n",
        "\n",
        "def prepare_concat_file(work_dir: str) -> None:\n",
        "    list_path = Path(work_dir) / \"videos.txt\"\n",
        "    lines = []\n",
        "    for p in sorted(Path(work_dir).glob(\"*.mp4\")):\n",
        "        lines.append(f\"file '{p.name}'\\n\")\n",
        "    list_path.write_text(\"\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def _which(cmd: str) -> Optional[str]:\n",
        "    return shutil.which(cmd)\n",
        "\n",
        "\n",
        "def merge_videos_ffmpeg(work_dir: str) -> str:\n",
        "    if not _which(\"ffmpeg\"):\n",
        "        raise RuntimeError(\"ffmpeg not found in PATH. Please install ffmpeg.\")\n",
        "    videos_txt = Path(work_dir) / \"videos.txt\"\n",
        "    if not videos_txt.exists():\n",
        "        raise FileNotFoundError(f\"Missing {videos_txt}\")\n",
        "    final_path = Path(work_dir) / \"final_output.mp4\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", str(videos_txt), \"-c\", \"copy\", \"-y\", str(final_path)\n",
        "    ]\n",
        "    subprocess.run(cmd, cwd=str(work_dir), check=True, capture_output=True)\n",
        "    return str(final_path)\n",
        "\n",
        "\n",
        "def finalize_result(execution_id: str) -> Dict[str, str]:\n",
        "    video_url = f\"http://localhost:3001/video/{execution_id}/final_output.mp4\"\n",
        "    return {\n",
        "        \"videoUrl\": video_url,\n",
        "        \"executionId\": execution_id,\n",
        "        \"message\": \"Video processing complete\",\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sequential orchestrator that mirrors the LangGraph DAG happy path\n",
        "\n",
        "def run_video_response_agent(persona_selection: str, wait_seconds: int = 2, max_polls: int = 60) -> Dict[str, Any]:\n",
        "    # Phase 0: init + personas\n",
        "    init = init_and_create_directory()\n",
        "    execution_id = init[\"execution_id\"]\n",
        "    work_dir = init[\"work_dir\"]\n",
        "    personas = define_personas()[\"personas\"]\n",
        "    persona = set_persona(personas, persona_selection)\n",
        "\n",
        "    # Phase 1: generate buying situations\n",
        "    bs = generate_buying_situations(persona)\n",
        "    situations_list: List[BuyingSituation] = bs[\"situations_list\"]\n",
        "\n",
        "    # Phase 2: loop prompts for each situation\n",
        "    prompts_json: List[PromptOutput] = []\n",
        "    prompt_strings: List[str] = []\n",
        "    for idx in range(len(situations_list)):\n",
        "        out = generate_prompt_for_current(persona, situations_list, idx)\n",
        "        pj = cast(PromptOutput, out[\"prompt_json\"])  # type: ignore\n",
        "        prompts_json.append(pj)\n",
        "        prompt_strings.append(str(out[\"prompt_string\"]))\n",
        "\n",
        "    # Phase 3: FAL queue\n",
        "    fal_requests = submit_fal_requests(prompt_strings)\n",
        "\n",
        "    # Wait and poll until complete (strict)\n",
        "    print(f\"[FAL] polling up to {max_polls} times with interval={wait_seconds}s\")\n",
        "    all_complete = False\n",
        "    for attempt in range(max_polls):\n",
        "        status_info = poll_statuses(fal_requests)\n",
        "        print(f\"[FAL] poll attempt {attempt+1}/{max_polls}: statuses={status_info['statuses']}\")\n",
        "        if status_info[\"all_complete\"]:\n",
        "            all_complete = True\n",
        "            break\n",
        "        time.sleep(max(0, int(wait_seconds)))\n",
        "\n",
        "    if not all_complete:\n",
        "        raise TimeoutError(f\"FAL jobs not completed after {max_polls} polls\")\n",
        "\n",
        "    video_urls = fetch_video_urls(fal_requests)\n",
        "    print(f\"[FAL] fetched video URLs: {video_urls}\")\n",
        "\n",
        "    # Download and merge\n",
        "    _ = download_videos(video_urls, work_dir)\n",
        "    prepare_concat_file(work_dir)\n",
        "    final_path = merge_videos_ffmpeg(work_dir)\n",
        "\n",
        "    # Final payload\n",
        "    result = finalize_result(execution_id)\n",
        "    return {\n",
        "        \"execution_id\": execution_id,\n",
        "        \"work_dir\": work_dir,\n",
        "        \"prompts\": [p.model_dump() for p in prompts_json],\n",
        "        \"video_urls\": video_urls,\n",
        "        \"final_path\": final_path,\n",
        "        \"result\": result,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAL] queue base=https://queue.fal.run/fal-ai/veo3; auth headers=['Authorization']\n",
            "[FAL] submit(0) ok: id=c3d07f16-119c-4134-a1c9-0f84f24a06d8 status_url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status response_url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/response\n",
            "[FAL] submit(1) ok: id=b5aeb901-d737-44e6-9c62-79e680d54fd3 status_url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status response_url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/response\n",
            "[FAL] submit(2) ok: id=ed5bcb66-6106-4189-ae60-63a640035c7c status_url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status response_url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/response\n",
            "[FAL] polling up to 60 times with interval=1s\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 1/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 2/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 3/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 4/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 5/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 6/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 7/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 8/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 9/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 10/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 11/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 12/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 13/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 14/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 15/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 16/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 17/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 18/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 19/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 20/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 21/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 22/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 23/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 24/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 25/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 26/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 27/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 28/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 29/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 30/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 31/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 32/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 33/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 34/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 35/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 36/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 37/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 38/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 39/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 40/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 41/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 42/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 43/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=IN_PROGRESS\n",
            "[FAL] poll attempt 44/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'IN_PROGRESS']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 45/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 46/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 47/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 48/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 49/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 50/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 51/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 52/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=IN_PROGRESS\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 53/60: statuses=['IN_PROGRESS', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 54/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 55/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 56/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 57/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 58/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 59/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "[FAL] poll(0) url=https://queue.fal.run/fal-ai/veo3/requests/c3d07f16-119c-4134-a1c9-0f84f24a06d8/status\n",
            "[FAL] poll(0) status=COMPLETED\n",
            "[FAL] poll(1) url=https://queue.fal.run/fal-ai/veo3/requests/b5aeb901-d737-44e6-9c62-79e680d54fd3/status\n",
            "[FAL] poll(1) status=IN_PROGRESS\n",
            "[FAL] poll(2) url=https://queue.fal.run/fal-ai/veo3/requests/ed5bcb66-6106-4189-ae60-63a640035c7c/status\n",
            "[FAL] poll(2) status=COMPLETED\n",
            "[FAL] poll attempt 60/60: statuses=['COMPLETED', 'IN_PROGRESS', 'COMPLETED']\n",
            "{'error': 'FAL jobs not completed after 60 polls'}\n"
          ]
        }
      ],
      "source": [
        "# Example usage (smoke test)\n",
        "try:\n",
        "    demo = run_video_response_agent(persona_selection=\"Omar US Developer\", wait_seconds=1)\n",
        "    print({\n",
        "        \"execution_id\": demo.get(\"execution_id\"),\n",
        "        \"work_dir\": demo.get(\"work_dir\"),\n",
        "        \"video_urls_count\": len(demo.get(\"video_urls\", [])),\n",
        "        \"final_path\": demo.get(\"final_path\"),\n",
        "        \"result\": demo.get(\"result\"),\n",
        "    })\n",
        "except Exception as e:\n",
        "    print({\"error\": str(e)})\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
