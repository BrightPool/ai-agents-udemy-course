{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: restart the kernel if packages were freshly installed.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (run once per environment)\n",
        "%pip install -q dspy python-dotenv google-genai fal-client pillow ffmpeg-python\n",
        "print(\"Note: restart the kernel if packages were freshly installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy configured for Video Response Generator DAG.\n"
          ]
        }
      ],
      "source": [
        "# Basic imports and environment setup\n",
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from dotenv import load_dotenv\n",
        "from dspy import History\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Configure LM (Anthropic or OpenAI OK; using OpenAI mini for text-only here)\n",
        "lm = dspy.LM(\"openai/gpt-5-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1, max_tokens=16000)\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "print(\"DSPy configured for Video Response Generator DAG.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pydantic models equivalent to LangGraph `models.py`\n",
        "from typing import Dict\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class BuyingSituation(BaseModel):\n",
        "    situation: str\n",
        "    location: str\n",
        "    trigger: str\n",
        "    evaluation: str\n",
        "    conclusion: str\n",
        "\n",
        "class BuyingSituationsOutput(BaseModel):\n",
        "    persona: str = Field(..., description=\"Name or identifier for the persona\")\n",
        "    buying_situations: Dict[str, BuyingSituation]\n",
        "\n",
        "class SceneDescription(BaseModel):\n",
        "    persona: str\n",
        "    appearance: str\n",
        "\n",
        "class PromptModel(BaseModel):\n",
        "    scene_description: SceneDescription\n",
        "    quote: str\n",
        "    prompt_string: str\n",
        "\n",
        "class PromptOutput(BaseModel):\n",
        "    prompt: PromptModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core tools ported from LangGraph DAG (plain Python functions)\n",
        "import time\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing import Any, List, Dict, Optional, cast\n",
        "\n",
        "import httpx\n",
        "import fal_client\n",
        "\n",
        "# Phase 0: init and persona catalog\n",
        "\n",
        "def init_and_create_directory() -> Dict[str, str]:\n",
        "    execution_id = uuid.uuid4().hex\n",
        "    work_dir = Path(f\"/tmp/n8n/{execution_id}\")\n",
        "    work_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for f in [\"videos.txt\", \"final_output.mp4\"]:\n",
        "        try:\n",
        "            (work_dir / f).unlink(missing_ok=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {\"execution_id\": execution_id, \"work_dir\": str(work_dir)}\n",
        "\n",
        "\n",
        "def define_personas() -> Dict[str, Dict[str, Dict[str, str]]]:\n",
        "    personas: Dict[str, Dict[str, str]] = {\n",
        "        \"Omar US Developer\": {\n",
        "            \"name\": \"Omar Ali\",\n",
        "            \"age\": \"32\",\n",
        "            \"gender\": \"Male\",\n",
        "            \"location\": \"San Francisco\",\n",
        "            \"occupation\": \"Software Engineer\",\n",
        "            \"income\": \"$200,000\",\n",
        "            \"background\": (\n",
        "                \"This individual's life revolves around exploration and understanding. They are deeply curious about the world, people, and how things work, often delving into complex topics such as philosophy, history, and the human psyche. Their online presence is a reflection of their inner world - an active, thoughtful space where they seek to make connections, exchange ideas, and learn from others. They love the act of learning and self-improvement. They have a strong desire to make things better for themselves and the world around them, expressed through their writing and interactions. This person is committed to their craft, valuing beauty and truth, and finds joy in the small, everyday aspects of life. They are fascinated by the power of human connection and the potential for growth within communities. They are known for their inquisitive nature, often posing questions and seeking different perspectives to broaden their understanding of the world. They have an open mind and are constantly seeking a deeper understanding of complex concepts and human behavior. Their curiosity is a constant source of inspiration, driving them to explore new ideas, challenge their beliefs, and make meaningful connections with others.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Sarah UK Nurse\": {\n",
        "            \"name\": \"Sarah Thomspon\",\n",
        "            \"age\": \"55\",\n",
        "            \"gender\": \"Woman\",\n",
        "            \"location\": \"Manchester, UK\",\n",
        "            \"occupation\": \"Nurse\",\n",
        "            \"income\": \"GBP 55k\",\n",
        "            \"background\": (\n",
        "                \"Sarah is a dedicated Registered Nurse with over thirty years of experience in the NHS. Raised in a working-class family, she was inspired to pursue nursing by her strong desire to help others and provide compassionate care. She is married, owns her home, and is a devout Christian, finding strength in her faith and family. Sarah is a strong advocate for her patients and believes healthcare is a fundamental right. She enjoys reading, gardening, and spending time outdoors, which helps her manage the stress that comes with her demanding job. Throughout her career, she has consistently strived to improve her skills and provide the best possible care to her patients.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Emily US Foodie\": {\n",
        "            \"name\": \"Emily Carter\",\n",
        "            \"age\": \"21\",\n",
        "            \"gender\": \"Female\",\n",
        "            \"location\": \"Los Angeles, CA\",\n",
        "            \"occupation\": \"Student\",\n",
        "            \"income\": \"NA\",\n",
        "            \"background\": (\n",
        "                \"Emily Carter is a 21-year-old college student at UCLA, majoring in Digital Marketing. Originally from a small town in Oregon, she moved to Los Angeles to pursue her passion for marketing and content creation. She's an avid foodie, constantly exploring LA's diverse culinary landscape and documenting her experiences on TikTok and Instagram. Her content focuses on restaurant reviews, food trends, and lifestyle content, and she hopes to work in social media marketing after graduation.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Clara US Health Coach\": {\n",
        "            \"name\": \"Clara Johnson\",\n",
        "            \"age\": \"35\",\n",
        "            \"gender\": \"Female\",\n",
        "            \"location\": \"New York City, NY\",\n",
        "            \"occupation\": \"Health Coach\",\n",
        "            \"income\": \"$70k\",\n",
        "            \"background\": (\n",
        "                \"Clara, a certified holistic health coach, was raised in a culturally diverse household where natural wellness was a way of life. Inspired by her family's practices, she pursued a certification in holistic health and launched her coaching business in NYC. Through her work at NaturalHealth Inc., Clara focuses on promoting holistic beauty methods, integrating wellness with skincare, and educating others on the benefits of natural products. She is passionate about community workshops and uses her platform to share DIY beauty techniques, encouraging others to embrace natural wellness. She is a Buddhist who believes beauty comes from within and enjoys meditation, nature walks, and creating healthy meals.\"\n",
        "            ),\n",
        "        },\n",
        "        \"Jordan US Tattoo Artist\": {\n",
        "            \"name\": \"Jordan McCulloch\",\n",
        "            \"age\": \"Age 5\",\n",
        "            \"gender\": \"Male\",\n",
        "            \"location\": \"Portland, OR, USA\",\n",
        "            \"occupation\": \"Tattoo Artist\",\n",
        "            \"income\": \"$48k\",\n",
        "            \"background\": (\n",
        "                \"Jordan grew up in a small coastal town in Oregon before moving to Portland to embrace the city’s alternative scene and vibrant art community. With a talent for visual storytelling and a welcoming demeanor, Jordan found a calling in tattoo artistry, channeling creativity into meaningful body art for friends and clients. Passionate about authentic self-expression and forging real connections, Jordan has built a loyal client base and a network of close friends who share a love of indie music, art shows, and late-night philosophical discussions. Jordan values openness in relationships and tends to express themselves candidly, both in art and conversation. When not at the tattoo studio, Jordan spends time volunteering for LGBTQ+ causes, making zines, and exploring the city’s eclectic food scene.\"\n",
        "            ),\n",
        "        },\n",
        "    }\n",
        "    return {\"personas\": personas}\n",
        "\n",
        "\n",
        "def set_persona(personas: Dict[str, Dict[str, str]], persona_selection: str) -> Dict[str, str]:\n",
        "    if not persona_selection or persona_selection not in personas:\n",
        "        raise ValueError(\"persona_selection is missing or invalid\")\n",
        "    return personas[persona_selection]\n",
        "\n",
        "\n",
        "# Phase 1: Buying situations via LM\n",
        "\n",
        "def _get_llm_predict():\n",
        "    return dspy.Predict(\"question -> answer\")\n",
        "\n",
        "\n",
        "def generate_buying_situations(persona: Dict[str, str]) -> Dict[str, Any]:\n",
        "    if not persona:\n",
        "        raise KeyError(\"persona missing; ensure set_persona ran first\")\n",
        "    system = (\n",
        "        \"Role play as {name}, a {age} {gender} from {location}, works as a {occupation} \"\n",
        "        \"earning {income}. {background}. You have been invited to review a new product \"\n",
        "        \"concept and reveal deep, personal insights into when you would buy this offer. \"\n",
        "        \"Return only valid JSON with fields persona (string) and buying_situations (object with exactly 3 keys).\"\n",
        "    ).format(**persona)\n",
        "    example = '{\"persona\":\"Rhys UK Entrepreneur\",\"buying_situations\":{\"celebrating_milestone\":{\"situation\":\"Celebrating a business milestone\",\"location\":\"Private members\\' club in London\",\"trigger\":\"Closed a major deal\",\"evaluation\":\"Considered champagne and cocktails, but wanted tradition\",\"conclusion\":\"Chose premium whisky\"},\"hosting_partners\":{\"situation\":\"Hosting international partners\",\"location\":\"Home office in Manchester\",\"trigger\":\"Inviting overseas investors\",\"evaluation\":\"Compared various spirits; whisky is distinctly British\",\"conclusion\":\"Bought respected Scottish whisky\"},\"relaxing_weekend\":{\"situation\":\"Relaxing after a long week\",\"location\":\"Apartment balcony overlooking the city\",\"trigger\":\"Needed a way to unwind\",\"evaluation\":\"Looked at beer, gin, wine; whisky appealed\",\"conclusion\":\"Chose whisky as a ritual drink\"}}}'\n",
        "    prompt = (\n",
        "        \"Respond only with raw JSON (no markdown). Use this schema and ensure 3 buying_situations. Example: \"\n",
        "        f\"{example}\"\n",
        "    )\n",
        "    predictor = _get_llm_predict()\n",
        "    raw = predictor(question=f\"{system}\\n\\n{prompt}\")\n",
        "    text = getattr(raw, \"answer\", \"\")\n",
        "    data = None\n",
        "    for _ in range(2):\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "            break\n",
        "        except Exception:\n",
        "            repair = predictor(question=\"Repair to valid JSON with the same schema: \" + text)\n",
        "            text = getattr(repair, \"answer\", \"\")\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to parse buying situations JSON\")\n",
        "    validated = BuyingSituationsOutput.model_validate(data)\n",
        "    situations_list = list(validated.buying_situations.values())\n",
        "    return {\n",
        "        \"buying_situations\": validated.buying_situations,\n",
        "        \"situations_list\": situations_list,\n",
        "        \"situation_index\": 0,\n",
        "        \"prompts_json\": [],\n",
        "        \"prompt_strings\": [],\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_prompt_for_current(persona: Dict[str, str], situations_list: List[BuyingSituation], situation_index: int) -> Dict[str, Any]:\n",
        "    if not (0 <= situation_index < len(situations_list)):\n",
        "        raise IndexError(\"situation_index out of range\")\n",
        "    situation = situations_list[situation_index]\n",
        "    template = (\n",
        "        \"You are a director of a qualitative research agency that specialises in creating realistic simulated testimonials that capture buying situations for new product concepts.\\n\\n\"\n",
        "        \"Your tasks are to: 1) Craft persona description, 2) scene appearance, 3) a short 6–8s quote, 4) assemble final prompt string.\\n\"\n",
        "        \"Return a structured object strictly matching this Pydantic schema: PromptOutput(prompt: PromptModel(scene_description: SceneDescription(persona, appearance), quote, prompt_string)). No markdown.\\n\"\n",
        "        \"Important: scene_description.persona MUST be a single short string with the persona's name only (e.g., 'Omar Ali'). Do NOT return an object for this field.\\n\"\n",
        "        \"Return exactly these keys: {\\\"prompt\\\": {\\\"scene_description\\\": {\\\"persona\\\": \\\"...\\\", \\\"appearance\\\": \\\"...\\\"}, \\\"quote\\\": \\\"...\\\", \\\"prompt_string\\\": \\\"...\\\"}}.\\n\\n\"\n",
        "        \"Persona\\n\"\n",
        "        f\"Name: {persona['name']}\\n\"\n",
        "        f\"Age: {persona['age']}\\n\"\n",
        "        f\"Gender: {persona['gender']}\\n\"\n",
        "        f\"Location: {persona['location']}\\n\"\n",
        "        f\"Occupation: {persona['occupation']}\\n\"\n",
        "        f\"Income: {persona['income']}\\n\"\n",
        "        f\"Background: {persona['background']}\\n\\n\"\n",
        "        \"Buying Situation\\n\"\n",
        "        f\"Situation: {situation.situation}\\n\"\n",
        "        f\"Location: {situation.location}\\n\"\n",
        "        f\"Trigger: {situation.trigger}\\n\"\n",
        "        f\"Evaluation: {situation.evaluation}\\n\"\n",
        "        f\"Conclusion: {situation.conclusion}\"\n",
        "    )\n",
        "    predictor = dspy.Predict(\"instruction -> json_text\")\n",
        "    raw = predictor(instruction=template)\n",
        "    text = getattr(raw, \"json_text\", \"\")\n",
        "    data = None\n",
        "    for _ in range(2):\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "            break\n",
        "        except Exception:\n",
        "            repair = dspy.Predict(\"text -> json_text\")(text=\"Repair to valid JSON only with the same schema. Ensure scene_description.persona is a single string (name only), not an object. Return exactly {\\\"prompt\\\": {\\\"scene_description\\\": {\\\"persona\\\": \\\"...\\\", \\\"appearance\\\": \\\"...\\\"}, \\\"quote\\\": \\\"...\\\", \\\"prompt_string\\\": \\\"...\\\"}}.\\n\\n\" + text)\n",
        "            text = getattr(repair, \"json_text\", \"\")\n",
        "    if data is None:\n",
        "        raise ValueError(\"Failed to parse prompt JSON\")\n",
        "    validated = PromptOutput.model_validate(data)\n",
        "    return {\"prompt_json\": validated, \"prompt_string\": validated.prompt.prompt_string}\n",
        "\n",
        "\n",
        "# Phase 3: FAL queue and video merging\n",
        "\n",
        "def _fal_headers() -> Dict[str, str]:\n",
        "    name = os.getenv(\"FAL_AUTH_HEADER_NAME\", \"Authorization\")\n",
        "    value = os.getenv(\"FAL_AUTH_HEADER_VALUE\")\n",
        "    if not value:\n",
        "        api_key = os.getenv(\"FAL_API_KEY\") or os.getenv(\"FAL_KEY\")\n",
        "        if api_key:\n",
        "            value = f\"Key {api_key}\"\n",
        "    return {name: value} if value else {}\n",
        "\n",
        "\n",
        "def _normalize_fal_urls(status_url: Optional[str], response_url: Optional[str]) -> Dict[str, str]:\n",
        "    def base_from(url: str) -> str:\n",
        "        u = url.rstrip(\"/\")\n",
        "        if u.endswith(\"/status\"):\n",
        "            return u[:-7]\n",
        "        if u.endswith(\"/response\"):\n",
        "            return u[:-9]\n",
        "        # if already like /requests/{id}, return as base\n",
        "        return u\n",
        "    base = None\n",
        "    if status_url:\n",
        "        base = base_from(status_url)\n",
        "    elif response_url:\n",
        "        base = base_from(response_url)\n",
        "    else:\n",
        "        return {\"status_url\": status_url or \"\", \"response_url\": response_url or \"\"}\n",
        "    return {\"status_url\": f\"{base}/status\", \"response_url\": f\"{base}/response\"}\n",
        "\n",
        "\n",
        "def _extract_video_url_from_data(data: Dict[str, Any]) -> Optional[str]:\n",
        "    if not isinstance(data, dict):\n",
        "        return None\n",
        "    if isinstance(data.get(\"video\"), dict) and data.get(\"video\", {}).get(\"url\"):\n",
        "        return str(data[\"video\"][\"url\"])\n",
        "    if data.get(\"video_url\"):\n",
        "        return str(data[\"video_url\"])  # type: ignore\n",
        "    if data.get(\"url\") and str(data.get(\"url\")).endswith(\".mp4\"):\n",
        "        return str(data[\"url\"])  # type: ignore\n",
        "    return None\n",
        "\n",
        "\n",
        "def _collect_final_response(client: httpx.Client, headers: Dict[str, str], base_url: str, wait_seconds: int = 1, max_polls: int = 60) -> Dict[str, Any]:\n",
        "    urls = _normalize_fal_urls(status_url=None, response_url=base_url)\n",
        "    print(f\"[FAL] collect child: status={urls['status_url']} response={urls['response_url']}\")\n",
        "    # Poll child until completed\n",
        "    last_status = None\n",
        "    for attempt in range(max_polls):\n",
        "        try:\n",
        "            st = client.get(urls[\"status_url\"], headers=headers)\n",
        "            st.raise_for_status()\n",
        "        except httpx.HTTPStatusError as ex:\n",
        "            body = ex.response.text if ex.response is not None else \"\"\n",
        "            code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "            print(f\"[FAL] collect poll HTTP {code}; body={body[:300]}\")\n",
        "            raise\n",
        "        sdata = st.json()\n",
        "        s = str(sdata.get(\"status\", \"\")).upper()\n",
        "        if s != last_status:\n",
        "            print(f\"[FAL] collect poll attempt {attempt+1}/{max_polls}: status={s}\")\n",
        "            last_status = s\n",
        "        if s == \"COMPLETED\":\n",
        "            break\n",
        "        if s in (\"FAILED\", \"CANCELLED\", \"ERROR\"):\n",
        "            raise RuntimeError(f\"FAL child job failed: {sdata}\")\n",
        "        time.sleep(max(0, int(wait_seconds)))\n",
        "    else:\n",
        "        raise TimeoutError(f\"FAL child job did not complete after {max_polls} polls\")\n",
        "    # Fetch child response (prefer POST; some queue endpoints require POST to /response)\n",
        "    try:\n",
        "        resp = client.post(urls[\"response_url\"], headers=headers, json={})\n",
        "        if resp.status_code == 405:  # Method Not Allowed fallback\n",
        "            resp = client.get(urls[\"response_url\"], headers=headers)\n",
        "        resp.raise_for_status()\n",
        "    except httpx.HTTPStatusError as ex:\n",
        "        body = ex.response.text if ex.response is not None else \"\"\n",
        "        code = ex.response.status_code if ex.response is not None else \"?\"\n",
        "        allow = ex.response.headers.get(\"Allow\") if ex.response is not None else None\n",
        "        print(f\"[FAL] collect fetch HTTP {code}; allow={allow}; body={body[:300]}\")\n",
        "        raise\n",
        "    return resp.json()\n",
        "\n",
        "\n",
        "def resolve_video_url_follow_chain(client: httpx.Client, headers: Dict[str, str], base_url: str, wait_seconds: int = 1, max_polls: int = 60, max_chain: int = 6) -> Optional[str]:\n",
        "    \"\"\"Follow nested FAL response chains until a terminal payload exposes a video URL.\n",
        "    Starts from a queue request base or its /response URL and iterates up to max_chain.\n",
        "    \"\"\"\n",
        "    current = base_url\n",
        "    last_keys: Optional[List[str]] = None\n",
        "    for depth in range(max_chain):\n",
        "        # Ensure the current request (root or child) is completed and fetch its response payload\n",
        "        payload = _collect_final_response(\n",
        "            client=client,\n",
        "            headers=headers,\n",
        "            base_url=current,\n",
        "            wait_seconds=wait_seconds,\n",
        "            max_polls=max_polls,\n",
        "        )\n",
        "        last_keys = list(payload.keys()) if isinstance(payload, dict) else None\n",
        "        print(f\"[FAL] chain depth {depth} keys={last_keys}\")\n",
        "\n",
        "        # Try to extract a direct video URL\n",
        "        url_candidate = _extract_video_url_from_data(payload)\n",
        "        if url_candidate:\n",
        "            print(f\"[FAL] chain depth {depth} resolved video URL: {url_candidate}\")\n",
        "            return url_candidate\n",
        "\n",
        "        # Otherwise, if another response_url is provided, follow it on the next loop\n",
        "        next_url = None\n",
        "        if isinstance(payload, dict):\n",
        "            next_url = payload.get(\"response_url\") or payload.get(\"response\")\n",
        "        if next_url:\n",
        "            print(f\"[FAL] chain depth {depth} following nested response_url\")\n",
        "            current = str(next_url)\n",
        "            continue\n",
        "\n",
        "        # No further link to follow and no URL found\n",
        "        print(f\"[FAL] chain depth {depth} no video URL and no further response_url to follow\")\n",
        "        break\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def submit_fal_requests(prompt_strings: List[str]) -> List[Dict[str, str]]:\n",
        "    route = os.getenv(\"FAL_MODEL_ROUTE\", \"fal-ai/veo3\")\n",
        "    print(f\"[FAL] route={route}; using fal_client\")\n",
        "    requests_info: List[Dict[str, str]] = []\n",
        "    for idx, prompt in enumerate(prompt_strings):\n",
        "        try:\n",
        "            handler = fal_client.submit(route, arguments={\"prompt\": prompt})\n",
        "        except Exception as ex:\n",
        "            print(f\"[FAL] submit({idx}) error: {ex}\")\n",
        "            raise\n",
        "        request_id = getattr(handler, \"request_id\", None)\n",
        "        if request_id is None and isinstance(handler, dict):\n",
        "            request_id = handler.get(\"request_id\")\n",
        "        if not request_id:\n",
        "            print(f\"[FAL] submit({idx}) unexpected handler={handler}\")\n",
        "            raise ValueError(\"fal_client.submit did not return a request_id\")\n",
        "        print(f\"[FAL] submit({idx}) ok: id={request_id}\")\n",
        "        requests_info.append({\"request_id\": str(request_id)})\n",
        "    return requests_info\n",
        "\n",
        "\n",
        "def poll_statuses(fal_requests: List[Dict[str, str]]) -> Dict[str, Any]:\n",
        "    route = os.getenv(\"FAL_MODEL_ROUTE\", \"fal-ai/veo3\")\n",
        "    statuses: List[str] = []\n",
        "    for idx, req in enumerate(fal_requests):\n",
        "        request_id = req.get(\"request_id\")\n",
        "        if not request_id:\n",
        "            raise ValueError(f\"Missing request_id in request: {req}\")\n",
        "        print(f\"[FAL] poll({idx}) request_id={request_id}\")\n",
        "        try:\n",
        "            st = fal_client.status(route, request_id, with_logs=False)\n",
        "        except Exception as ex:\n",
        "            print(f\"[FAL] poll({idx}) error: {ex}\")\n",
        "            raise\n",
        "        # fal_client.status returns an object with .status or a dict with 'status'\n",
        "        status_value = getattr(st, \"status\", None)\n",
        "        if status_value is None and isinstance(st, dict):\n",
        "            status_value = st.get(\"status\")\n",
        "        status_value = str(status_value or \"\").upper()\n",
        "        print(f\"[FAL] poll({idx}) status={status_value}\")\n",
        "        statuses.append(status_value)\n",
        "    all_complete = all(s == \"COMPLETED\" for s in statuses) if statuses else False\n",
        "    return {\"statuses\": statuses, \"all_complete\": all_complete}\n",
        "\n",
        "\n",
        "def fetch_video_urls(fal_requests: List[Dict[str, str]] , wait_seconds: int = 1, max_polls: int = 60) -> List[str]:\n",
        "    route = os.getenv(\"FAL_MODEL_ROUTE\", \"fal-ai/veo3\")\n",
        "    video_urls: List[str] = []\n",
        "    for idx, req in enumerate(fal_requests):\n",
        "        request_id = req.get(\"request_id\")\n",
        "        if not request_id:\n",
        "            raise ValueError(f\"Missing request_id in request: {req}\")\n",
        "        print(f\"[FAL] fetch({idx}) request_id={request_id}\")\n",
        "        # Poll until completed (strict), mirroring previous behavior\n",
        "        last_status = None\n",
        "        for attempt in range(max_polls):\n",
        "            st = fal_client.status(route, request_id, with_logs=False)\n",
        "            status_value = getattr(st, \"status\", None)\n",
        "            if status_value is None and isinstance(st, dict):\n",
        "                status_value = st.get(\"status\")\n",
        "            s = str(status_value or \"\").upper()\n",
        "            if s != last_status:\n",
        "                print(f\"[FAL] fetch({idx}) poll {attempt+1}/{max_polls} status={s}\")\n",
        "                last_status = s\n",
        "            if s == \"COMPLETED\":\n",
        "                break\n",
        "            if s in (\"FAILED\", \"CANCELLED\", \"ERROR\"):\n",
        "                raise RuntimeError(f\"FAL job failed: {st}\")\n",
        "            time.sleep(max(0, int(wait_seconds)))\n",
        "        else:\n",
        "            raise TimeoutError(f\"FAL job did not complete after {max_polls} polls: {request_id}\")\n",
        "\n",
        "        # Get the result and extract the video URL\n",
        "        res = fal_client.result(route, request_id)\n",
        "        url_candidate = _extract_video_url_from_data(res)\n",
        "        print(f\"[FAL] fetch({idx}) result keys={list(res.keys()) if isinstance(res, dict) else type(res)}\")\n",
        "        if not url_candidate:\n",
        "            raise ValueError(f\"No video URL in result: {res}\")\n",
        "        video_urls.append(url_candidate)\n",
        "    return video_urls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FAL subscribe-based generation helper (preferred)\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "def generate_videos_via_subscribe(prompt_strings: List[str], with_logs: bool = True) -> List[str]:\n",
        "    route = os.getenv(\"FAL_MODEL_ROUTE\", \"fal-ai/veo3\")\n",
        "    print(f\"[FAL] using subscribe flow; route={route}\")\n",
        "\n",
        "    def on_queue_update(update):\n",
        "        if isinstance(update, fal_client.InProgress):\n",
        "            if getattr(update, \"logs\", None):\n",
        "                for log in update.logs:\n",
        "                    try:\n",
        "                        msg = log.get(\"message\") if isinstance(log, dict) else str(log)\n",
        "                        if msg:\n",
        "                            print(msg)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "    video_urls: List[str] = []\n",
        "    for idx, prompt in enumerate(prompt_strings):\n",
        "        print(f\"[FAL] subscribe({idx})\")\n",
        "        result = fal_client.subscribe(\n",
        "            route,\n",
        "            arguments={\"prompt\": prompt},\n",
        "            with_logs=with_logs,\n",
        "            on_queue_update=on_queue_update,\n",
        "        )\n",
        "        url_candidate = _extract_video_url_from_data(result)\n",
        "        if not url_candidate:\n",
        "            raise ValueError(f\"No video URL in subscribe result: {result}\")\n",
        "        video_urls.append(url_candidate)\n",
        "    return video_urls\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download + ffmpeg helpers\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def download_videos(video_urls: List[str], work_dir: str) -> List[str]:\n",
        "    Path(work_dir).mkdir(parents=True, exist_ok=True)\n",
        "    files: List[str] = []\n",
        "    with httpx.Client(timeout=None, follow_redirects=True) as client:\n",
        "        for i, url in enumerate(video_urls):\n",
        "            file_name = f\"{i:02d}.mp4\"\n",
        "            file_path = Path(work_dir) / file_name\n",
        "            with client.stream(\"GET\", url) as resp:\n",
        "                resp.raise_for_status()\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    for chunk in resp.iter_bytes():\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "            files.append(str(file_path))\n",
        "    return files\n",
        "\n",
        "\n",
        "def prepare_concat_file(work_dir: str) -> None:\n",
        "    list_path = Path(work_dir) / \"videos.txt\"\n",
        "    lines = []\n",
        "    for p in sorted(Path(work_dir).glob(\"*.mp4\")):\n",
        "        lines.append(f\"file '{p.name}'\\n\")\n",
        "    list_path.write_text(\"\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def _which(cmd: str) -> Optional[str]:\n",
        "    return shutil.which(cmd)\n",
        "\n",
        "\n",
        "def merge_videos_ffmpeg(work_dir: str) -> str:\n",
        "    if not _which(\"ffmpeg\"):\n",
        "        raise RuntimeError(\"ffmpeg not found in PATH. Please install ffmpeg.\")\n",
        "    videos_txt = Path(work_dir) / \"videos.txt\"\n",
        "    if not videos_txt.exists():\n",
        "        raise FileNotFoundError(f\"Missing {videos_txt}\")\n",
        "    final_path = Path(work_dir) / \"final_output.mp4\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", str(videos_txt), \"-c\", \"copy\", \"-y\", str(final_path)\n",
        "    ]\n",
        "    subprocess.run(cmd, cwd=str(work_dir), check=True, capture_output=True)\n",
        "    return str(final_path)\n",
        "\n",
        "\n",
        "def finalize_result(execution_id: str) -> Dict[str, str]:\n",
        "    video_url = f\"http://localhost:3001/video/{execution_id}/final_output.mp4\"\n",
        "    return {\n",
        "        \"videoUrl\": video_url,\n",
        "        \"executionId\": execution_id,\n",
        "        \"message\": \"Video processing complete\",\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sequential orchestrator that mirrors the LangGraph DAG happy path\n",
        "\n",
        "def run_video_response_agent(persona_selection: str, wait_seconds: int = 3, max_polls: int = 100) -> Dict[str, Any]:\n",
        "    # Phase 0: init + personas\n",
        "    init = init_and_create_directory()\n",
        "    execution_id = init[\"execution_id\"]\n",
        "    work_dir = init[\"work_dir\"]\n",
        "    personas = define_personas()[\"personas\"]\n",
        "    persona = set_persona(personas, persona_selection)\n",
        "\n",
        "    # Phase 1: generate buying situations\n",
        "    bs = generate_buying_situations(persona)\n",
        "    situations_list: List[BuyingSituation] = bs[\"situations_list\"]\n",
        "\n",
        "    # Phase 2: loop prompts for each situation\n",
        "    prompts_json: List[PromptOutput] = []\n",
        "    prompt_strings: List[str] = []\n",
        "    for idx in range(len(situations_list)):\n",
        "        out = generate_prompt_for_current(persona, situations_list, idx)\n",
        "        pj = cast(PromptOutput, out[\"prompt_json\"])  # type: ignore\n",
        "        prompts_json.append(pj)\n",
        "        prompt_strings.append(str(out[\"prompt_string\"]))\n",
        "\n",
        "    # Phase 3: FAL video generation via subscribe (streaming logs, waits for completion)\n",
        "    video_urls = generate_videos_via_subscribe(prompt_strings, with_logs=True)\n",
        "    print(f\"[FAL] fetched video URLs: {video_urls}\")\n",
        "\n",
        "    # Download and merge\n",
        "    _ = download_videos(video_urls, work_dir)\n",
        "    prepare_concat_file(work_dir)\n",
        "    final_path = merge_videos_ffmpeg(work_dir)\n",
        "\n",
        "    # Final payload\n",
        "    result = finalize_result(execution_id)\n",
        "    return {\n",
        "        \"execution_id\": execution_id,\n",
        "        \"work_dir\": work_dir,\n",
        "        \"prompts\": [p.model_dump() for p in prompts_json],\n",
        "        \"video_urls\": video_urls,\n",
        "        \"final_path\": final_path,\n",
        "        \"result\": result,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAL] using subscribe flow; route=fal-ai/veo3\n",
            "[FAL] subscribe(0)\n",
            "[FAL] subscribe(1)\n",
            "[FAL] subscribe(2)\n",
            "[FAL] fetched video URLs: ['https://v3b.fal.media/files/b/elephant/b5I8lLXwaGxDG536Lh7Ml_output.mp4', 'https://v3b.fal.media/files/b/penguin/qLqfvBhg_9nIhyHtqdG2i_output.mp4', 'https://v3b.fal.media/files/b/kangaroo/HphxNXOUiyVU1o3IbACA1_output.mp4']\n",
            "{'execution_id': '55b073a7f7fd408f8cfbd4b7f9b00919', 'work_dir': '/tmp/n8n/55b073a7f7fd408f8cfbd4b7f9b00919', 'video_urls_count': 3, 'final_path': '/tmp/n8n/55b073a7f7fd408f8cfbd4b7f9b00919/final_output.mp4', 'result': {'videoUrl': 'http://localhost:3001/video/55b073a7f7fd408f8cfbd4b7f9b00919/final_output.mp4', 'executionId': '55b073a7f7fd408f8cfbd4b7f9b00919', 'message': 'Video processing complete'}}\n"
          ]
        }
      ],
      "source": [
        "# Example usage (smoke test)\n",
        "try:\n",
        "    demo = run_video_response_agent(persona_selection=\"Omar US Developer\", wait_seconds=1)\n",
        "    print({\n",
        "        \"execution_id\": demo.get(\"execution_id\"),\n",
        "        \"work_dir\": demo.get(\"work_dir\"),\n",
        "        \"video_urls_count\": len(demo.get(\"video_urls\", [])),\n",
        "        \"final_path\": demo.get(\"final_path\"),\n",
        "        \"result\": demo.get(\"result\"),\n",
        "    })\n",
        "except Exception as e:\n",
        "    print({\"error\": str(e)})\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
